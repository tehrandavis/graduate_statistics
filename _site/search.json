[
  {
    "objectID": "walkthroughs.html",
    "href": "walkthroughs.html",
    "title": "PSYC 7014",
    "section": "",
    "text": "This is a landing page for the PSYC 7014 Walkthroughs. Individual weeks and sections can be found on the left sidebar."
  },
  {
    "objectID": "week06/6_1_t-test.html",
    "href": "week06/6_1_t-test.html",
    "title": "Testing differences in means / t-test",
    "section": "",
    "text": "This week we cover when and how to conduct a \\(t-test\\). We use a t-test to assess whether the observed difference between sample means is greater than would be predicted be chance. Both the Navarro text and Poldrack text do a wonderful job of explaining t-tests conceptually so I will defer to those experts on matters of the underlying their statistical basis. Instead my goal this week is to walk through some examples on performing, interpreting, and reporting t-tests using R.\nThis walkthough assumes that the following packages are installed and loaded on your computer:"
  },
  {
    "objectID": "week06/6_1_t-test.html#things-to-consider-before-running-the-t-test",
    "href": "week06/6_1_t-test.html#things-to-consider-before-running-the-t-test",
    "title": "Testing differences in means / t-test",
    "section": "Things to consider before running the t-test",
    "text": "Things to consider before running the t-test\nBefore running a t.test there are a few practical and statistical considerations that must be taken. In fact, these considerations extend to every type of analysis that we will encounter for the remainder of the semester (and indeed the rest of your career) so it would be good to get in the habit of running through your checks. In what proceeds here I will walk step by step with how I condunct a t.test (while also highlighting certain decision points as they come up).\nWhat is the nature of your sample data?\nIn other words where is the data coming from? Is it coming from a single sample of participants? Is it coming from multiple samples of the SAME participants? Is it coming from multiple groups of participants. This will not only determine what analysis you choose to run, but in also how you go about the business of preparing to run this analysis. Of course, truth be told this information should already be known before you even start collecting your data, which reinforces an important point, your central analyses should already be selected BEFORE you start collecting data! As you design your experiments you should do so in a way in which the statistics that you run are built into the design, not settled upon afterwards. This enables you to give the tests you perform the most power, as you are making predictions about the outcomes of your test a priori. This will become a major theme on the back half of the class, but best to introduce it now.\nFor this week, it will determine what test we will elect to perform. Let’s grab some sample data from an experiment by Hand, et al. (1994)\n\nHand, et al., 1994, reported on family therapy as a treatment for anorexia. There were 17 girls in this experiment, and they were weighed before and after treatment. The weights of the girls, in pounds, is provided in the data below:\n\n\nanorexia_data <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab7-3.dat\", \n                     \"\\t\", escape_double = FALSE, trim_ws = TRUE)\n\nRows: 17 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): ID\ndbl (2): Before, After\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nSo what is known: we have 17 total participants from (hypothetically) the same population that are measured twice (once Before treatment, and once After treatment). Based upon the experimental question we need to run a paired-sample (matched-sample) test. (Although I’ll use this data to provide an example of a one-sample test later on).\nWhat is the structure of your data file?\nBefore doing anything you should always take a look at your data:\n\nshow(anorexia_data)\n\n# A tibble: 17 × 3\n   ID    Before After\n   <chr>  <dbl> <dbl>\n 1 01      83.8  95.2\n 2 02      83.3  94.3\n 3 03      86    91.5\n 4 04      82.5  91.9\n 5 05      86.7 100. \n 6 06      79.6  76.7\n 7 07      76.9  76.7\n 8 08      94.2 102. \n 9 09      73.4  94.9\n10 10      80.5  75.2\n11 11      81.6  77.8\n12 12      82.1  95.5\n13 13      77.6  90.7\n14 14      83.5  92.6\n15 15      89.9  93.8\n16 16      86    91.7\n17 17      87.3  98  \n\n\nSo what do we have here, three columns:\n\n\nID: the participant number\n\nBefore: participants’ weights before treatment\n\nAfter: participants’ weights after treatment\n\nMost important for present purposes this data is in WIDE format—each line represents a participant. While this might be intuitive for tabluar visualization, many statistical softwares prefer when LONG format, where each line represents a single observation (or some mixed of WIDE and LONG like SPSS).\nI spoke a little bit about this issue in Week 2, Walkthrough 0.\nGetting data from WIDE to LONG\nSo the data are in WIDE format, each line has multiple observations of data that are being compared. Here both Before scores and After scores are on the same line. In order to make life easier for analysis and plotting in ggplot, we need to get the data into LONG format (Before scores and After scores are on different lines). This can be done using the pivot_longer() function from the tidyr package.\nBefore gathering, one thing to consider is whether or not you have a column that defines each subject. In this case we have ID. This tells R that these data are coming from the same subject and will allow R to connect these data when performing analysis. That said, for t.test() this is not crucially important—t.test() assumes that the order of lines represents the order of subjects, e.g., the first Before line is matched to the first After line. Later on when we are doing ANOVA, however, this participant column will be important an we will need to add if it is missing.\nUsing pivot_longer(): This function takes a number of arguments, but for us right now, the most important are data: your dataframe; cols: which columns to gather; names_to: what do you want the header of the collaped nonminal variables to be? Here, we might ask what title would encapsulate both Before and After. I’ll choose treatment ; values_to: what do the values represent, here I choose weight. I’m just going to overwrite the original data frame:\n\nanorexia_data <- pivot_longer(anorexia_data,cols = c(\"Before\",\"After\"),names_to = \"treatment\", values_to = \"weight\")\nanorexia_data\n\n# A tibble: 34 × 3\n   ID    treatment weight\n   <chr> <chr>      <dbl>\n 1 01    Before      83.8\n 2 01    After       95.2\n 3 02    Before      83.3\n 4 02    After       94.3\n 5 03    Before      86  \n 6 03    After       91.5\n 7 04    Before      82.5\n 8 04    After       91.9\n 9 05    Before      86.7\n10 05    After      100. \n# ℹ 24 more rows\n\n\nOk data is structured correctly, on to the next step.\nTesting assumptions\nRemember that you should always test to see if the data fit the assumptions of the test you intend to perform. In this case, we need to assess two things:\nIs the data normally distributed?\nKnowing the design of your experiment also has implications for testing your assumptions. For example, whether you have a paired (matched) sample design (e.g., two samples from the same participants) or an independent sample design (e.g., two groups) determines how you go about the business of testing the normality assumption. If you have an independent samples test, you test each sample separately, noting measures of skew, kurtosis, inspecting the qqPlot, and Shapiro-Wilkes test (though acknowledging that SW is very sensitive). However, if you are running a paired (matched) samples test, you need to be concerned with the distribution of the difference scores. In the present example we are comparing participants’ weights Before treatment to their weight After. This is a paired design, so I need to test the differences between each participant’s Before and After for normality.\nFirst, let me filter() my data accordingly for Before and After (essentially creating separate vectors for each condition):\n\nbeforeTreatment <- filter(anorexia_data, treatment==\"Before\") \nafterTreatment <- filter(anorexia_data, treatment==\"After\") \n\nAnd now compute the difference scores, and run my assumption tests:\n\ndiffWeights <- beforeTreatment$weight - afterTreatment$weight\n\npsych::describe(diffWeights)\n\n   vars  n  mean   sd median trimmed  mad   min max range skew kurtosis   se\nX1    1 17 -7.26 7.17   -9.1   -7.15 5.93 -21.5 5.3  26.8 0.18    -0.77 1.74\n\ncar::qqPlot(diffWeights)\n\n\n\n\n[1]  9 10\n\nshapiro.test(diffWeights)\n\n\n    Shapiro-Wilk normality test\n\ndata:  diffWeights\nW = 0.9528, p-value = 0.5023\n\n\nWhat conclusions might we draw about normality?\nGetting the descriptive stats and plotting the means.\nFinally, as we will be performing a test of difference in means, it would be a good idea to get descriptive measures of means and variability for each group. Indeed, these data were already obatined when we used psych::describe() to assess the normality of each sample. Here I’ll just do it again to get these values:\n\npsych::describeBy(anorexia_data$weight,group = anorexia_data$treatment)\n\n\n Descriptive statistics by group \ngroup: After\n   vars  n  mean   sd median trimmed  mad  min   max range  skew kurtosis   se\nX1    1 17 90.49 8.49   92.6   90.77 3.85 75.2 101.6  26.4 -0.74    -0.93 2.06\n------------------------------------------------------------ \ngroup: Before\n   vars  n  mean   sd median trimmed  mad  min  max range skew kurtosis   se\nX1    1 17 83.23 5.02   83.3   83.15 4.15 73.4 94.2  20.8 0.15    -0.29 1.22\n\n\nTypically along with the mean, you need to report a measure of variability of your sample. This can be either the SD, SEM, or if you choose the 95% CI, although this is more rare in the actual report. See the supplied HW example and APA examples for conventions on how to report these in your results section.\nPlotting in ggplot\nI’ve mentioned the limits and issues with plotting bar plots, but they remain a standard, so we will simply proceed using these plots. But I’ll note that boxplots, violin plots, bean plots, and pirate plots are all modern alternatives to bar plots and are easy to execute in ggplot(). Try a Google search.\nIn the meantime, to produce a bar plot in R we simply modify a few of the arguments that we are familiar width.\nHere is the code for plotting these two groups:\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\") + \n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot()\n\n\n\n\nBreaking this down line-by-line:\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)): standard fare for starting a ggplot.\nstat_summary(fun = \"mean\", geom = \"col\"): stat_summary() gets summary statistics and projects them onto the geom of your choice. In this case we are getting the mean values, fun = \"mean\" and using them to create a column plot geom = \"col\" .\nstat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) : here we are creating error bars, geom = \"errorbar\". Important to note here is that error bars require knowing three values: mean, upper limit, and lower limit. Whenever you are asking for a single value, like a mean, you use fun. When multiple values are needed you use fun.data. Here fun.data = \"mean_se\" requests Standard error bars. Other alternatives include 95% CI \"mean_cl_normal\" and Standard deviation \"mean_sdl\". The width argument adjusts the width of the error bars.\nscale_y_continuous(expand = c(0,0)): Typically R will do this strange thing where it places a gap bewteen the data and the x-axis. This line is a hack to remove this default. It says along the y-axis add 0 expansion (or gap).\ntheme_cowplot(): quick APA aesthetics.\n\nYou may also feel that the zooming factor is off. This may especially be true in cases where there is little visual discrepency between the bars. To “zoom in” on the data you can use coord_cartesian(). For example, you might want to only show the range between 70 lbs and 100 lbs. When doing this, be careful not to truncate the upper limits of your bars and importantly your error bars.\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\") + \n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,100))\n\n\n\n\nAdditionally, to get this into true APA format I would need to adjust my axis labels. Here capitalization is needed. Also, because the weight has a unit measure, I need to be specific about that:\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\") + \n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,100)) +\n  xlab(\"Treatment\") + \n  ylab(\"Weight (lbs)\")\n\n\n\n\nFinally, you may have notice that the order of Treatment on the plot is opposite of what we might like to logically present. In this case the “After” data comes prior to the “Before” data on the x-axis. This is because R defaults to alphabetical order when loading in data. To correct this I can use scale_x_discrete() and specify the order that I want in limits:\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\") + \n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,100)) +\n  xlab(\"Treatment\") + \n  ylab(\"Weight (lbs)\") + \n  scale_x_discrete(limits=c(\"Before\",\"After\"))\n\n\n\n\nAlternatively I can correct the order of the levels of a factor within the dataframe itself using fct_relevel() (this gets loaded with tidyverse). Note that here I am overwriting the original treatment column. If you do this proceed at your own risk! You could also just mutate a new column if you would rather not overwrite.\n\nanorexia_data$treatment <- fct_relevel(anorexia_data$treatment, \"Before\", \"After\")\n\nggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\", \n               fill = \"lightgray\", color = \"black\") + # adding some color mods here.\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,100)) +\n  xlab(\"Treatment\") + \n  ylab(\"Weight (lbs)\")\n\n\n\n# note that I don't have to do the `scale_x_discrete(limits=c(\"Before\",\"After\"))` correction\n\nAll good (well maybe check with Sierra first)! One other thing to consider (although please do not worry about it here) is the recent argument that when dealing with repeated measures data you need to adjust you error bars. See this pdf by Richard Morey (2005) for more information on this issue. We’ll revisit this issue when running Repeated Measures ANOVA.\nAn aside… other types of plots\nAs I mentioned barplots (especially those that use standard error bars) have more recently come under criticism for “hiding” the true name of the data. There is currently a movement to make data more transparent using other kinds of plots that convey more information about your sample. For example let’s contrast out barplot from above with a combination “pointrange” and violin plot. The pointrange simply provides the mean as a point with error bars extending as specified (here I choose standard error). The violin plot is essentially a histogram of the data turned on its side, centered on the mean, and then mirrored… it gives us info about the TRUE distribution of scores.\nLet’s take a look side by side\n\nbarplot <- ggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  stat_summary(fun = \"mean\", geom = \"col\", \n               fill = \"lightgray\", color = \"black\") + # adding some color mods here.\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,110)) +\n  xlab(\"Treatment\") + \n  ylab(\"Weight (lbs)\")\n\n# note that order matters. I need to do the violin before the pointrange or else the violin will \"paint over\" the pointrange.\n\npoint_violin_plot <- ggplot(data = anorexia_data, aes(x=treatment, y=weight)) +\n  geom_violin() +\n  stat_summary(fun.data = \"mean_se\", geom = \"pointrange\", color = \"black\") + # adding some color mods here.\n  scale_y_continuous(expand = c(0,0)) + \n  theme_cowplot() +\n  coord_cartesian(ylim = c(70,110)) +\n  xlab(\"Treatment\") + \n  ylab(\"Weight (lbs)\")\n\ncowplot::plot_grid(barplot, point_violin_plot)\n\n\n\n\nAs you can see the second plot gives me more information about what’s truly going on with my data."
  },
  {
    "objectID": "week06/6_1_t-test.html#performing-the-t-test-paired-sample-t-test",
    "href": "week06/6_1_t-test.html#performing-the-t-test-paired-sample-t-test",
    "title": "Testing differences in means / t-test",
    "section": "Performing the t-test (Paired sample t-test)",
    "text": "Performing the t-test (Paired sample t-test)\nOkay, now that we’ve done all of our preparation, we’re now ready to perform the test. We can do so using the t.test() function. In this case, the experimental question warrants a paired samples t-test. Given that our Levene’s test failed to reject the null, we will assume that our variances are equal.\nSince we’ve got long-format data we will use the formula syntax. This reads “predicting changes in weight as a function of treatment.\n\nt.test(weight~treatment,data=anorexia_data,paired=T, var.equal=T)\n\n\n    Paired t-test\n\ndata:  weight by treatment\nt = -4.1802, df = 16, p-value = 0.0007072\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -10.948840  -3.580571\nsample estimates:\nmean difference \n      -7.264706 \n\n\nThe output provides us with our \\(t\\) value, the \\(df\\) and the \\(p\\) value. It also includes a measure of the 95% CI, and the mean difference. Remember that the null hypothesis is that there is no difference between our two samples. In the case of repeated measures especially, it makes sense to think of this in terms of a difference score of change, where the null is 0. The resulting interpretation is that on average participants’ weight increased 7.26 pounds due to the treatment, with a 95% likelihood that the true mean change is between 3.58 lbs and 10.95 lbs. Important for us is that 0 is not in the 95% CI, reinforcing that there was indeed a non-zero change (rejecting the null)."
  },
  {
    "objectID": "week06/6_1_t-test.html#other-t-tests",
    "href": "week06/6_1_t-test.html#other-t-tests",
    "title": "Testing differences in means / t-test",
    "section": "Other \\(t\\) tests:",
    "text": "Other \\(t\\) tests:\nOne sample:\nThe data in our example warranted running a paired t-test. However, as noted we can run a t.test() to compare a single sample to a single value. For example it might be reasonable to ask whether or not the 17 adolescent girls that Hand, et al., 1994 treated were different from what would be considered the average weight of a teenaged girl. A quick Google search suggests that the average weight of girls 12-17 in 2002 was 130 lbs. How does this compare to Hand et al.’s participants Before treatment? We can run a one sample t-test to answer this question:\n\nbeforeTreatment <- filter(anorexia_data,treatment==\"Before\")\nt.test(beforeTreatment$weight, mu = 130)\n\n\n    One Sample t-test\n\ndata:  beforeTreatment$weight\nt = -38.44, df = 16, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 130\n95 percent confidence interval:\n 80.65007 85.80876\nsample estimates:\nmean of x \n 83.22941 \n\n\nYes, this group of girls was significantly underweight compared to the national average.\nIndependent samples example\nWe run an independent samples t-test when we have reason to believe that the data in the two samples is NOT meaningfully related in any fashion. Consider this example regarding Joshua Aronson’s work on stereotype threat:\n\nJoshua Aronson has done extensive work on what he refers to as “stereotype threat,” which refers to the fact that “members of stereotyped groups often feel extra pressure in situations where their behavior can confirm the negative reputation that their group lacks a valued ability” (Aronson, Lustina, Good, Keough, Steele, & Brown, 1998). This feeling of stereo- type threat is then hypothesized to affect performance, generally by lowering it from what it would have been had the individual not felt threatened. Considerable work has been done with ethnic groups who are stereotypically reputed to do poorly in some area, but Aronson et al. went a step further to ask if stereotype threat could actually lower the performance of white males—a group that is not normally associated with stereotype threat.\n\n\nAronson et al. (1998) used two independent groups of college students who were known to excel in mathematics, and for whom doing well in math was considered important. They assigned 11 students to a control group that was simply asked to complete a difficult mathematics exam. They assigned 12 students to a threat condition, in which they were told that Asian students typically did better than other students in math tests, and that the purpose of the exam was to help the experimenter to understand why this difference exists. Aronson reasoned that simply telling white students that Asians did better on math tests would arousal feelings of stereotype threat and diminish the students’ performance.\n\nHere we have two mutually exclusive groups of white men, those that are controls and those under induced threat. Importantly we have no reason to believe that any one control man’s score is more closely tied to any individual experimental group counterpart than any others (we’ll return to this idea in a bit).\nHere is the data:\n\nstereotype_data <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab7-7.dat\", delim = \"\\t\")\n\nRows: 23 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): ID\ndbl (2): Score, Group\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAs before, let’s take a look at the file structure:\n\nshow(stereotype_data)\n\n# A tibble: 23 × 3\n   ID    Score Group\n   <chr> <dbl> <dbl>\n 1 01        4     1\n 2 02        9     1\n 3 03       12     1\n 4 04        8     1\n 5 05        9     1\n 6 06       13     1\n 7 07       12     1\n 8 08       13     1\n 9 09       13     1\n10 10        7     1\n# ℹ 13 more rows\n\n\nI want to look at this example as it give is an opportunity to deal with another common issue in data cleaning. If you take a look at Group you see it’s either 1 or 2. In this case Group 1 are the control subjects and Group 2 are the threat subjects. Using numbers instead of names to identify levels of a factor is a convention from older methods and software. In more modern software you don’t need to do this sort of number coding (the software works this out in the background).\nIf you want to change this, you can use the recode_factor() function from dplyr package in the tidyverse (https://dplyr.tidyverse.org/reference/recode.html). For what it’s worth there are several other ways to do this including a recode() function in car. See http://rprogramming.net/recode-data-in-r/ for examples.\nHere I’m just going to mutate a new column, namedGroup column with the recoded names:\n\nstereotype_data <- stereotype_data %>% \n  mutate(\"namedGroup\" = dplyr::recode_factor(Group,\n                                            \"1\"=\"Control\", \n                                            \"2\"=\"Threat\")\n                            )\nstereotype_data\n\n# A tibble: 23 × 4\n   ID    Score Group namedGroup\n   <chr> <dbl> <dbl> <fct>     \n 1 01        4     1 Control   \n 2 02        9     1 Control   \n 3 03       12     1 Control   \n 4 04        8     1 Control   \n 5 05        9     1 Control   \n 6 06       13     1 Control   \n 7 07       12     1 Control   \n 8 08       13     1 Control   \n 9 09       13     1 Control   \n10 10        7     1 Control   \n# ℹ 13 more rows\n\n\nAn now to run the requisite assumption tests. Note that in this case I am running an Indepednent samples test, so I need to test the assumptions on each sample separately. Here I’m going be a little more critical about how I test for normality.\nUsing psych::describeBy:\n\npsych::describeBy(stereotype_data,group = stereotype_data$namedGroup)\n\n\n Descriptive statistics by group \ngroup: Control\n            vars  n mean   sd median trimmed  mad min max range  skew kurtosis\nID*            1 11 6.00 3.32      6    6.00 4.45   1  11    10  0.00    -1.53\nScore          2 11 9.64 3.17      9    9.89 4.45   4  13     9 -0.31    -1.48\nGroup          3 11 1.00 0.00      1    1.00 0.00   1   1     0   NaN      NaN\nnamedGroup*    4 11 1.00 0.00      1    1.00 0.00   1   1     0   NaN      NaN\n              se\nID*         1.00\nScore       0.96\nGroup       0.00\nnamedGroup* 0.00\n------------------------------------------------------------ \ngroup: Threat\n            vars  n mean   sd median trimmed  mad min max range  skew kurtosis\nID*            1 12 6.50 3.61    6.5     6.5 4.45   1  12    11  0.00    -1.50\nScore          2 12 6.58 3.03    7.0     6.9 2.22   0  10    10 -0.86    -0.39\nGroup          3 12 2.00 0.00    2.0     2.0 0.00   2   2     0   NaN      NaN\nnamedGroup*    4 12 2.00 0.00    2.0     2.0 0.00   2   2     0   NaN      NaN\n              se\nID*         1.04\nScore       0.87\nGroup       0.00\nnamedGroup* 0.00\n\n\nUsing DescTools:\ncontrol group\n\ncontrol_group <- stereotype_data %>% filter(namedGroup==\"Control\") \n\ncontrol_skew <- DescTools::Skew(x=control_group$Score,method = 2,conf.level = .95,ci.type = \"bca\",R = 1000)\ncontrol_skew_ses <- (control_skew[3] - control_skew[2])/3.92\ncontrol_skew[1]/control_skew_ses\n\n      skew \n-0.6060895 \n\ncontrol_kurt <- DescTools::Kurt(x=control_group$Score,method = 2,conf.level = .95,ci.type = \"bca\",R = 1000)\ncontrol_kurt_ses <- (control_kurt[3] - control_kurt[2])/3.92\ncontrol_kurt[1]/control_kurt_ses\n\n     kurt \n-1.094786 \n\n\nthreat group\n\nthreat_group <- stereotype_data %>% filter(namedGroup==\"Threat\") \n\nthreat_skew <- DescTools::Skew(x=threat_group$Score,method = 2,conf.level = .95,ci.type = \"bca\",R = 1000)\nthreat_skew_ses <- (threat_skew[3] - threat_skew[2])/3.92\nthreat_skew[1]/threat_skew_ses\n\n     skew \n-1.867989 \n\nthreat_kurt <- DescTools::Kurt(x=threat_group$Score,method = 2,conf.level = .95,ci.type = \"bca\",R = 1000)\nthreat_kurt_ses <- (threat_kurt[3] - threat_kurt[2])/3.92\nthreat_kurt[1]/threat_kurt_ses\n\n     kurt \n0.4176778 \n\n\nThis is a pain… can we make a function for this!!!!\nQQ-Plot\n\npacman::p_load(qqplotr)\n\nggplot(stereotype_data, aes(sample=Score, group=namedGroup, color=namedGroup)) + \n  geom_qq() + geom_qq_line()\n\n\n\n\nHomogeniety of Variance:\nWhile the paired samples test doesn’t make this assumption, the Independence samples test assumes the variability of scores for the two groups is roughly homogeneous.\nFor a t-test this can be tested by using the leveneTest() from the car package:\n\n# using long-format enter as a formula:\ncar::leveneTest(Score~namedGroup, data=stereotype_data, center=\"mean\")\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value Pr(>F)\ngroup  1  0.4306 0.5188\n      21               \n\n\nYou’ll note above I elected to mean center my samples. This is consistent with typical practice although “median” centering may be more robust.\n\ncar::leveneTest(data=stereotype_data, Score~namedGroup)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  0.4639 0.5033\n      21               \n\n\nT-test Given that my obtained Pr(>F), or p-value of Levene’s F-test, is greater than .05, I may elect to assume that my variances are equal. However, if you remained skeptical, there are adjustments that you may make. This includes adjusting the degrees of freedom according to Welch-Satterthwaite recommendation (see below). Recall later on that we are looking at our obtained \\(t\\) value with respect to the number of \\(df\\). This adjustment effectively reduces the \\(df\\) in turn making your test more conservative.\nThe Levene’s test failed to reject the null so I may proceed with my t.test assuming variances are equal. Note that paired=FALSE for independent sample tests:\n\nt.test(data=stereotype_data, Score~namedGroup, paired=FALSE, var.equal=T)\n\n\n    Two Sample t-test\n\ndata:  Score by namedGroup\nt = 2.3614, df = 21, p-value = 0.02795\nalternative hypothesis: true difference in means between group Control and group Threat is not equal to 0\n95 percent confidence interval:\n 0.3643033 5.7417573\nsample estimates:\nmean in group Control  mean in group Threat \n             9.636364              6.583333 \n\n\nThis output gives us the \\(t\\)-value, \\(df\\) and \\(p\\)-value. Based on this output I may conclude that the mean score in the Control group is significantly greater than the Threat group.\nJust as an example, let’s set var.equal to FALSE:\n\nt.test(data=stereotype_data, Score~namedGroup, paired=FALSE, var.equal=F)\n\n\n    Welch Two Sample t-test\n\ndata:  Score by namedGroup\nt = 2.3565, df = 20.614, p-value = 0.02843\nalternative hypothesis: true difference in means between group Control and group Threat is not equal to 0\n95 percent confidence interval:\n 0.3556143 5.7504463\nsample estimates:\nmean in group Control  mean in group Threat \n             9.636364              6.583333 \n\n\nComparing the outputs you see that in this case R has indicated that it has run the test with the Welsh correction. Note that this changes the \\(df\\) and consequently the resulting \\(p\\) value. That this change was negligible reinforces that the variances were very similar to one another. However in cases where they are not close to one another you may see dramatic changes in \\(df\\).\nIn R, the t.test() function sets var.equal=FALSE by default. Why you ask? Well, you can make the argument that the variances are ALWAYS unequal, its only a matter of degree. Assuming variances are unequal makes your test more conservative, meaning that if the test suggests that you should reject the null, you can be slightly more confident that you are not committing Type I error. At the same time, it could be argued that setting your var.equal=TRUE in this case (where the Levene test failed to reject the null) makes your test more powerful, and you should take advantage of that power to avoid Type II error."
  },
  {
    "objectID": "week06/6_1_t-test.html#independent-or-paired-sample",
    "href": "week06/6_1_t-test.html#independent-or-paired-sample",
    "title": "Testing differences in means / t-test",
    "section": "Independent or Paired Sample?",
    "text": "Independent or Paired Sample?\nIt is safe to assume that anytime that you are collecting data samples from the same person at two different points in time that you need to run a paired-samples test. However, it would not be safe to assume that if the samples are coming from different groups of people that you always run an independent samples test. Remember the important qualifier mentioned above: That there no reason to believe that any one participant in the first group is is more closely related to any single counterpart in the second group than the remaining of others. In our Independent test example we have no reason to assume this is the case, we assume that members of the Control and Threat groups were randomly selected. But what if we instead recruited brothers or twins? In this case, it may make sense to treat members of the two groups as paired; brothers have a shared history (education, socio-economic level, family dynamic, etc) that would make their scores more likely to be related to one another than by random chance."
  },
  {
    "objectID": "week09/9_1-posthocs.html",
    "href": "week09/9_1-posthocs.html",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "",
    "text": "This walkthrough requires the following to be installed / loaded in R\n\nBe sure that the column that contains your IV is indeed being treated as a factor. If it is levels(IV) will list your levels, also the column containing the IV will contain <fct>.\nbuild an ANOVA model using lm(), aov(), or afex() (output to lm)\nrun your post-hoc comparisions using the p.adjustment of your choice (tukey, holm, bonferroni)\n\nExample (I recommend running this line-by-line)\n\n# Preliminaries\n## load in data\ndataset <- read_table2(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab12-1.dat\")\n\nWarning: `read_table2()` was deprecated in readr 2.0.0.\nℹ Please use `read_table()` instead.\n\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  ID = col_character(),\n  Group = col_double(),\n  Time = col_double()\n)\n\n# Step 1\n## check data, identify columns\ndataset\n\n# A tibble: 40 × 3\n   ID    Group  Time\n   <chr> <dbl> <dbl>\n 1 01        1     3\n 2 02        1     5\n 3 03        1     1\n 4 04        1     8\n 5 05        1     1\n 6 06        1     1\n 7 07        1     4\n 8 08        1     9\n 9 09        2     2\n10 10        2    12\n# ℹ 30 more rows\n\n## Group is numerically coded. Fixing this and turning to a factor\ndataset$Group <- recode_factor(dataset$Group, \"1\"=\"MS\",\"2\"=\"MM\",\"3\"=\"SS\",\"4\"=\"SM\",\"5\"=\"McM\")\n\n# Step 2: Run the model\nmodel_aov <- lm(Time~Group, data = dataset)\n\n# Step 3: Test the model for significant F-value\nmodel_aov %>% sjstats::anova_stats()\n\nterm      | df |    sumsq |  meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------\nGroup     |  4 | 3497.600 | 874.400 |    27.325 |  < .001 | 0.757 |         0.757 |   0.725 |           0.725 |     0.730 |    1.767 |     1\nResiduals | 35 | 1120.000 |  32.000 |           |         |       |               |         |                 |           |          |      \n\n# Step 4: post-hoc analysis in this example \"tukey\", but could also be \"bonf\" or \"holm\"\nemmeans(object = model_aov,specs = ~Group, adjust=\"tukey\") %>% pairs()\n\n contrast estimate   SE df t.ratio p.value\n MS - MM        -6 2.83 35  -2.121  0.2340\n MS - SS        -7 2.83 35  -2.475  0.1198\n MS - SM       -20 2.83 35  -7.071  <.0001\n MS - McM      -25 2.83 35  -8.839  <.0001\n MM - SS        -1 2.83 35  -0.354  0.9965\n MM - SM       -14 2.83 35  -4.950  0.0002\n MM - McM      -19 2.83 35  -6.718  <.0001\n SS - SM       -13 2.83 35  -4.596  0.0005\n SS - McM      -18 2.83 35  -6.364  <.0001\n SM - McM       -5 2.83 35  -1.768  0.4078\n\nP value adjustment: tukey method for comparing a family of 5 estimates"
  },
  {
    "objectID": "week09/9_1-posthocs.html#comparing-means-in-the-anova-model",
    "href": "week09/9_1-posthocs.html#comparing-means-in-the-anova-model",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Comparing means in the ANOVA model",
    "text": "Comparing means in the ANOVA model\nIn AoV, part 1, introduced the One-Way ANOVA. ANOVA is useful when we are comparing 3 or more group means such that the null hypothesis is:\n\\[\\mu_1=\\mu_2=\\mu_3...=\\mu_n\\].\nIn this case, if a single mean is revealed to be significantly different from the others, then the null is rejected. However, rejecting the null only tells us that at least one mean was different from the others; it does not tell us which one or how many. For example with just three means, it could be the case that:\n\n\\(\\mu_1≠\\mu_2=\\mu_3\\)\n\\(\\mu_1=\\mu_2≠\\mu_3\\)\n\\(\\mu_1=\\mu_3≠\\mu_2\\)\n\\(\\mu_1≠\\mu_2≠\\mu_3\\)\n\nSimply getting a significant F-value does not tell us this at all. In order to suss out any differences in our groups we are going to need to make direct comparisons between them.\nEnter multiple contrasts. Multiple contrasts are a way of testing the potential inequalities between group means like those above. As always, both Navarro and Poldrack do wonderful jobs of laying out the mathematics and logic of multiple comparisons. As with Part 1 I focus on practical implementation and spend some time focusing a bit on potential landmines and theoretical concerns as I see them.\nThis vignette assumes that you have the following packages installed and loaded in R:\n\n# use pacman to check, install, and load necessary packages\npacman::p_load(agricolae,\n               cowplot, \n               tidyverse, \n               emmeans,\n               multcomp,\n               psych,\n               sjstats)"
  },
  {
    "objectID": "week09/9_1-posthocs.html#the-data-siegels-1975-study-on-the-effects-of-morphine",
    "href": "week09/9_1-posthocs.html#the-data-siegels-1975-study-on-the-effects-of-morphine",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "The data: Siegel’s 1975 study on the effects of morphine",
    "text": "The data: Siegel’s 1975 study on the effects of morphine\nTo start, lets download Siegel’s (1975) data set on Morphine Tolerance. This data set can be found on the web. Before diving into the data, check a description of the experiment in the Siegel_summary.pdf file in the walkthroughs folder. When you are done, come back a we’ll work on analyzing this data.\n\n# grab data from online location:\ndataset <- read_table2(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab12-1.dat\")\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  ID = col_character(),\n  Group = col_double(),\n  Time = col_double()\n)\n\n# convert dataset$Group number codes to named factor levels:\ndataset$Group <- recode_factor(dataset$Group, \"1\"=\"MS\",\"2\"=\"MM\",\"3\"=\"SS\",\"4\"=\"SM\",\"5\"=\"McM\")\n\n# get descriptive stats for this data by Group\npsych::describeBy(dataset$Time,dataset$Group)\n\n\n Descriptive statistics by group \ngroup: MS\n   vars n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 8    4 3.16    3.5       4 3.71   1   9     8 0.43    -1.59 1.12\n------------------------------------------------------------ \ngroup: MM\n   vars n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 8   10 5.13   10.5      10 4.45   2  19    17 0.15    -0.99 1.81\n------------------------------------------------------------ \ngroup: SS\n   vars n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 8   11 6.72   10.5      11 8.15   3  21    18 0.23    -1.69 2.38\n------------------------------------------------------------ \ngroup: SM\n   vars n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 8   24 6.37     23      24 5.93  17  36    19 0.59    -1.07 2.25\n------------------------------------------------------------ \ngroup: McM\n   vars n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 8   29 6.16   28.5      29 5.93  20  40    20 0.28    -1.07 2.18\n\n\nAnd a quick peek at this data:\n\nggplot(data = dataset,aes(x=Group,y=Time)) +\n  stat_summary(fun = mean, geom = \"bar\") +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", aes(width=.25)) +\n  scale_y_continuous(expand = c(0,0)) + expand_limits(y=c(0,35)) + theme_cowplot()"
  },
  {
    "objectID": "week09/9_1-posthocs.html#running-the-one-way-anova",
    "href": "week09/9_1-posthocs.html#running-the-one-way-anova",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Running the One-way ANOVA",
    "text": "Running the One-way ANOVA\nNow that our data is properly coded we can run our omnibus ANOVA. My own personal preference is to run the ANOVA using lm(). This makes like a lot easier when dealing with contrasts, especially if you decide to employ the method that Field suggests in his guide. FWIW, I typically use another method as seen below, but I’ll talk a little bit about why I prefer it to Fields method. That said, recall from Part 1 that using the aov() function gives you the same result. Depending on which you choose, you can use the summary(morphine_mdl) or anova(morphine_mdl) to switch back and forth to get the info that you desire:\n\n# running the ANOVA using lm:\nmorphine_mdl <- lm(formula = Time~Group,data = dataset)\n# using the anova() function to display as ANOVA table\nanova(morphine_mdl)\n\nAnalysis of Variance Table\n\nResponse: Time\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nGroup      4 3497.6   874.4  27.325 2.443e-10 ***\nResiduals 35 1120.0    32.0                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# full anova output (preferred)\nsjstats::anova_stats(morphine_mdl)\n\nterm      | df |    sumsq |  meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------\nGroup     |  4 | 3497.600 | 874.400 |    27.325 |  < .001 | 0.757 |         0.757 |   0.725 |           0.725 |     0.730 |    1.767 |     1\nResiduals | 35 | 1120.000 |  32.000 |           |         |       |               |         |                 |           |          |      \n\n\nSo we see here that we have: \\(F(4,35)=27.33,p<.001,\\eta_p^2=.75\\)\nRemember again that the only thing that the omnibus ANOVA tells us is that there is an inequality in our means. In this respect, the omnibus begs more questions than it answers—which means are different from which. In order to get this answer we need to run direct comparisons between our means. There are two ways of going about this, we can either (1) plan beforehand what differences in means are especially relevant for us and focus on those, or (2) take a look at all potential differences without any specified predictions. In Case 1, we are performing planned contrasts; in Case 2, we use post hoc tests. More often than not, you will see researchers analyzing differences in means using post hoc tests—that is they run the ANOVA, find that it is significant, and run a battery of pairwise comparisons. It is sometimes the case that of that battery of comparisons, only a select few are actually theoretically relevant. However, if there is a theory-driven case to be made that you are predicting differences between a few select means in your data, then there is an argument to be made that you should run your planned contrasts independent of your ANOVA. That is, you are technically only permitted to run post-hoc tests if your ANOVA is significant (you can only go looking for differences in means if your ANOVA tells you that they exist), whereas planned contrasts can be run regardless of the outcome of the omnibus ANOVA (indeed, some argue that they obviate the need to run the omnibus ANOVA altogether).\nMy guess is that most of you have experience with post-hoc tests. They are more commonly performed tend to be touched upon in introductory stats courses. So we will spend a little time on these first before proceeding to a more in depth treatment of planned contrasts."
  },
  {
    "objectID": "week09/9_1-posthocs.html#post-hoc-tests",
    "href": "week09/9_1-posthocs.html#post-hoc-tests",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Post-hoc tests",
    "text": "Post-hoc tests\nWe use a post-hoc test when we want to test for differences in means that we have not explicitly predicted prior to conducting our experiment. As a result, whenever we perform a post-hoc test, we need to adjust our critical p-values to correct for inflation of Type 1 error. Recall from earlier discussions that the odds of committing a Type 1 error (falsely rejecting the null) is \\(1-(1-\\alpha)^c\\) where \\(\\alpha\\) is you critical p-value and \\(c\\) is the number of comparisons that are to be performed. Typically we keep this at .05, so when conducting a single test, the likelihood of committing a Type 1 error is: \\(1-(1-.05)^1=1-0.95^1=0.05\\)\nHowever as we increase the number of comparisons, assuming an \\(\\alpha\\) of 0.05:\n\n2 comparisons = \\(1-.95^2=0.0975\\)\n\n3 comparisons = \\(1-.95^3=0.1426\\)\n\n4 comparisons = \\(1-.95^4=0.1855\\)\n\n5 comparisons = \\(1-.95^5=0.2262\\)\n\n\nObviously, we need to control for this. The post-hoc methods that were introduced this week are all similar in that they involve comparing two means (a la t-test) but differ in how the error is controlled. For example a Bonferroni-Dunn correction (which is often used as a post-hoc correction, although initially intended for correcting planned comparisons) adjusts for this by partitioning the significance (by diving your original alpha by the number of comparisons). A popular variant of this method, the Holm test, is a multistage test. It proceeds by ordering the obtained t-values from smallest to largest. We then evaluate the largest t according to the Bonferroni-Dunn correction \\(\\alpha/c\\). Each subsequent comparison t value, \\(n\\) is evaluated against the correction \\(\\alpha/(c-n)\\). Please note I mention the these two methods with post-hoc analyses, although in true they are intended for planned comparisons. However, in instances in which the number of comparisons is relatively small, I’ve often seen them employed as post-hocs.\nSo how many comparisons is relatively small? I’d suggest best form is to use the above methods when you have 5 or fewer comparisons, meaning that your critical \\(\\alpha\\) is .01. That said, with a post hoc test, you really do not have a choice in the number of comparisons you can make, you need to test for all possible comparisons on the IV. Why? well if not you are simply cherry picking your data. For example it would be poor form to take a look at our data like so:\nPlot:\n\nggplot(data = dataset,aes(x=Group,y=Time)) +\n  stat_summary(fun.y = mean, geom = \"bar\") +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", aes(width=.25)) +\n  scale_y_continuous(expand = c(0,0)) + expand_limits(y=c(0,35)) + \n  theme_cowplot()\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nand then decide that you only want to compare ‘McM’ to ‘MS’ because that’s where you see the greatest differences. Or that you simply want to take a look at “MM” and “SS” without considering the rest.\nSince you did not plan for or explicitly predict these differences from the outset, you are simply banking on what I like to say might be a “historical accident”, that you simply stumbled into these results. As such, it’s deemed as proper for to test all contingencies.\nIn the case above there are \\((5!)/(2!)(5-2)!\\) = 10 combinations. If we were to run a Bonferroni correction in this case or critical \\(p\\) would need to be \\(.05/10=.005\\) which is an extremely conservative value, and thus dramatically inflates the likelihood of Type II error. In cases like this, Tukey’s HSD is the traditionally preferred method, as it takes into account the characteristics of your data (in particular the standard error of the distribution) when calculating the critical \\(p\\) value. As such in cases where many post-hoc, pairwise comparisons are made, Tukey’s HSD is less conservative than a Bonferroni adjustment.\nOne final method that is becoming more en vogue is the Ryan, Einot, Gabriel, Welsch method (REGWQ). Whereas Tukey’s method holds the critical \\(p\\) constant for all comparisons (at the loss of power) the REGWQ allows for an adjustment for the number of comparisons. It is currently being promoted as the most desirable post-hoc method.\nBonferonni-Dunn and Holm tests\nIn R there are several ways in which we can call post hoc corrections. For example we can call the Bonferonni and Holm adjustments using pairwise.t.test() function from the base package (already installed). The pairwise.t.test() method asks you to input:\n\n\nx = your DV\n\ng = your grouping factor\n\np.adjust.method = the name of your desired correction in string format\n\nFirst let’s run the pairwise.t.tests with no adjustment (akin to uncorrected \\(p\\) values):\n\npairwise.t.test(x = dataset$Time, g = dataset$Group,p.adjust.method = \"none\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dataset$Time and dataset$Group \n\n    MS      MM      SS      SM   \nMM  0.041   -       -       -    \nSS  0.018   0.726   -       -    \nSM  3.1e-08 1.9e-05 5.4e-05 -    \nMcM 1.9e-10 8.9e-08 2.6e-07 0.086\n\nP value adjustment method: none \n\n\nYou see above that we get a cross-matrix containing the \\(p\\) values for each cross pair (row × column). Remember this is something we would never do in a post hoc (no corrections) but I wanted to first run this to illustrate a point. Now let’s run the the Bonferroni and Holm corrections:\nBonferroni example (pairwise.t.test())\n\npairwise.t.test(x = dataset$Time, g = dataset$Group,p.adjust.method = \"bonferroni\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dataset$Time and dataset$Group \n\n    MS      MM      SS      SM     \nMM  0.41051 -       -       -      \nSS  0.18319 1.00000 -       -      \nSM  3.1e-07 0.00019 0.00054 -      \nMcM 1.9e-09 8.9e-07 2.6e-06 0.85818\n\nP value adjustment method: bonferroni \n\n\nYou’ll note that the p-values displayed here are 10x the p-values from the uncorrected matrix. To demonstrate this:\n\nuncorrected <- pairwise.t.test(x = dataset$Time, g = dataset$Group,p.adjust.method = \"none\")\nbonf_corrected <- pairwise.t.test(x = dataset$Time, g = dataset$Group,p.adjust.method = \"bonferroni\")\n\nbonf_corrected$p.value/uncorrected$p.value\n\n    MS        MM SS SM\nMM  10        NA NA NA\nSS  10  1.377801 NA NA\nSM  10 10.000000 10 NA\nMcM 10 10.000000 10 10\n\n\n\nnote that the 1.378 value is the result of p being capped at \\(p=1\\) in the Bonferroni corrected comparison.\n\nRemember from a few paragraphs back that there are 10 possible combinations so the Bonferonni test would need to divide the critical alpha by 10. What this means is that anytime you perform a correction, R actually adjusts the \\(p\\) values for you; therefore you may interpret the output against your original (familywise) \\(\\alpha\\). So here, any values that are still less than .05 after the corrections are significant.\nMoving on…\nHolm example (pairwise.t.test())\n\npairwise.t.test(x = dataset$Time, g = dataset$Group,p.adjust.method = \"holm\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dataset$Time and dataset$Group \n\n    MS      MM      SS      SM     \nMM  0.12315 -       -       -      \nSS  0.07327 0.72579 -       -      \nSM  2.8e-07 0.00011 0.00027 -      \nMcM 1.9e-09 7.1e-07 1.8e-06 0.17164\n\nP value adjustment method: holm"
  },
  {
    "objectID": "week09/9_1-posthocs.html#tukey-hsd-and-regwq-tests",
    "href": "week09/9_1-posthocs.html#tukey-hsd-and-regwq-tests",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Tukey HSD and REGWQ tests",
    "text": "Tukey HSD and REGWQ tests\nIn order to run Tukey’s HSD and REGWQ methods we call upon the agricolae package. In this case, we need to input our lm() model into the function, as well as identify our “treatment” (in this case our “Group” factor). For example:\nTukey HSD example (agricolae)\n\nmorphine_mdl <- lm(Time~Group,data = dataset) # from above\nagricolae::HSD.test(morphine_mdl,trt = \"Group\",group = T,console = T) \n\n\nStudy: morphine_mdl ~ \"Group\"\n\nHSD Test for Time \n\nMean Square Error:  32 \n\nGroup,  means\n\n    Time      std r Min Max\nMcM   29 6.164414 8  20  40\nMM    10 5.126960 8   2  19\nMS     4 3.162278 8   1   9\nSM    24 6.369571 8  17  36\nSS    11 6.718843 8   3  21\n\nAlpha: 0.05 ; DF Error: 35 \nCritical Value of Studentized Range: 4.065949 \n\nMinimun Significant Difference: 8.131899 \n\nTreatments with the same letter are not significantly different.\n\n    Time groups\nMcM   29      a\nSM    24      a\nSS    11      b\nMM    10      b\nMS     4      b\n\n\nNote that the group and console arguments pertain to the output. You typically will want to keep console set to TRUE as that simply prints the output of your test. The group argument controls how the output is presented. Above we set it to TRUE. This results in an output that groups the treatment means into subsets where treatments with the same letter are not significantly different from one another, known as compact letter displays. For example, as are not significantly different from each other, bs are not significantly different from each other, but as are different from bs. Conversely if you wanted to see each comparison you can set this to FALSE:\n\nagricolae::HSD.test(morphine_mdl,trt = \"Group\",group = FALSE,console = TRUE) \n\n\nStudy: morphine_mdl ~ \"Group\"\n\nHSD Test for Time \n\nMean Square Error:  32 \n\nGroup,  means\n\n    Time      std r Min Max\nMcM   29 6.164414 8  20  40\nMM    10 5.126960 8   2  19\nMS     4 3.162278 8   1   9\nSM    24 6.369571 8  17  36\nSS    11 6.718843 8   3  21\n\nAlpha: 0.05 ; DF Error: 35 \nCritical Value of Studentized Range: 4.065949 \n\nComparison between treatments means\n\n         difference pvalue signif.        LCL        UCL\nMcM - MM         19 0.0000     ***  10.868101  27.131899\nMcM - MS         25 0.0000     ***  16.868101  33.131899\nMcM - SM          5 0.4078          -3.131899  13.131899\nMcM - SS         18 0.0000     ***   9.868101  26.131899\nMM - MS           6 0.2340          -2.131899  14.131899\nMM - SM         -14 0.0002     *** -22.131899  -5.868101\nMM - SS          -1 0.9965          -9.131899   7.131899\nMS - SM         -20 0.0000     *** -28.131899 -11.868101\nMS - SS          -7 0.1198         -15.131899   1.131899\nSM - SS          13 0.0005     ***   4.868101  21.131899\n\n\nFinally, if you do decide to group (group=TRUE), you can take the outcome of this function and use it to generate a nice group plot. This is useful for quick visual inspection.\n\nagricolae::HSD.test(morphine_mdl,trt = \"Group\",group = T,console = T) %>% plot()\n\n\nStudy: morphine_mdl ~ \"Group\"\n\nHSD Test for Time \n\nMean Square Error:  32 \n\nGroup,  means\n\n    Time      std r Min Max\nMcM   29 6.164414 8  20  40\nMM    10 5.126960 8   2  19\nMS     4 3.162278 8   1   9\nSM    24 6.369571 8  17  36\nSS    11 6.718843 8   3  21\n\nAlpha: 0.05 ; DF Error: 35 \nCritical Value of Studentized Range: 4.065949 \n\nMinimun Significant Difference: 8.131899 \n\nTreatments with the same letter are not significantly different.\n\n    Time groups\nMcM   29      a\nSM    24      a\nSS    11      b\nMM    10      b\nMS     4      b\n\n\n\n\n\nREGWQ example (agricolae)\nThe same applies to REGW, using the REGW.test() function (with group=F, I’m showing all of the comparisons):\n\nagricolae::REGW.test(morphine_mdl,trt = \"Group\",group = F,console = T) \n\n\nStudy: morphine_mdl ~ \"Group\"\n\nRyan, Einot and Gabriel and Welsch multiple range test\nfor Time \n\nMean Square Error:  32 \n\nGroup,  means\n\n    Time      std r Min Max\nMcM   29 6.164414 8  20  40\nMM    10 5.126960 8   2  19\nMS     4 3.162278 8   1   9\nSM    24 6.369571 8  17  36\nSS    11 6.718843 8   3  21\n\nComparison between treatments means\n\n         difference pvalue signif.         LCL        UCL\nMcM - MM         19 0.0000     ***  12.1234674  25.876533\nMcM - MS         25 0.0000     ***  17.4611210  32.538879\nMcM - SM          5 0.3056          -2.6279930  12.627993\nMcM - SS         18 0.0000     ***   9.8681013  26.131899\nMM - MS           6 0.0995       .  -0.8765326  12.876533\nMM - SM         -14 0.0001     *** -21.5388790  -6.461121\nMM - SS          -1 0.9846          -8.6279930   6.627993\nMS - SM         -20 0.0000     *** -26.8765326 -13.123467\nMS - SS          -7 0.0771       . -14.5388790   0.538879\nSM - SS          13 0.0001     ***   6.1234674  19.876533\n\n\nCompact letter displays are nice (SPSS generates them, too), but as seems to always be the case, there is some controversy as to whether we should use them. Taken from this vignette:\n\nCLD displays promote visually the idea that two means that are “not significantly different” are to be judged as being equal; and that is a very wrong interpretation. In addition, they draw an artificial “bright line” between P values on either side of alpha, even ones that are very close."
  },
  {
    "objectID": "week09/9_1-posthocs.html#alternative-to-cld",
    "href": "week09/9_1-posthocs.html#alternative-to-cld",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Alternative to CLD()",
    "text": "Alternative to CLD()\nOne thing to note, the curator of the emmeans() package is not a fan of cld (Compact Letter Displays) and instead has created pwpp as a visualization tool.\n\nemmeans(morphine_mdl, specs = ~Group) %>% pwpp()\n\n\n\n\nYou can visit this vignette to get a feel for what is at issue here."
  },
  {
    "objectID": "week09/9_1-posthocs.html#effect-sizes",
    "href": "week09/9_1-posthocs.html#effect-sizes",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Effect sizes",
    "text": "Effect sizes\nTypically when reporting the effect size of the difference between two means we use Cohen’s \\(d\\). However, calculating Cohen’s $d$ in a posthoc contrast is slightly more involved than the method used for a regular t-test. This is because with a regular t-test you only have 2 means from 2 samples that you have collected. In the case of pairwise contrasts in ANOVA, while you are only comparing two means, those means are nested within a larger group (e.g., when comparing MS and MM, we still need to account for the fact that we also collected samples from SS, SM, and McM). That is, you need to understand the difference between the two means in the context of the entire model.\nSimply put, in our calculations we need to account for the influence of all of our collected groups. This is done by placing the contrasted difference in the context of the Root Mean Square Error, or the square root of the Mean Square Error of the residuals in our ANOVA model. Recall that typically Cohen’s \\(d\\) is the difference between the two means divided by their pooled standard deviation. Here, \\(d\\) is the difference between the two means divided by sigma, or the estimated standard deviation of the errors of the linear model.\nTo do this we’re going to need two things from the original model. Let’s take a look at the model summary:\n\nmorphine_mdl %>% summary()\n\n\nCall:\nlm(formula = Time ~ Group, data = dataset)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -9.00  -3.25   0.00   3.00  12.00 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    4.000      2.000   2.000   0.0533 .  \nGroupMM        6.000      2.828   2.121   0.0411 *  \nGroupSS        7.000      2.828   2.475   0.0183 *  \nGroupSM       20.000      2.828   7.071 3.09e-08 ***\nGroupMcM      25.000      2.828   8.839 1.93e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.657 on 35 degrees of freedom\nMultiple R-squared:  0.7574,    Adjusted R-squared:  0.7297 \nF-statistic: 27.32 on 4 and 35 DF,  p-value: 2.443e-10\n\n\nThe values line that is important to us is the Residual standard error ___ on __ degrees of freedom—in this case the values 5.657 and 35 respectively.\nAssuming you have run your comparisons using emmeans() you can calculate your effect sizes for each comparison using emmeans::eff_size().\neff_size() takes three arguments:\n\nthe emmeans object\nthe estimated standard deviation of the errors of the linear model, sigma\n\nthe residual degrees of freedom from the model, df.residual\n\n\nThe functions sigma() and df.residual() allow us to get this information directly from the model. A typical call would look something like this\n\n# save your contrasts to an object\nmdl_contrasts <- emmeans(morphine_mdl, specs = ~Group)\n\n# use the saved object in the following function\neff_size(mdl_contrasts,sigma = sigma(morphine_mdl), df.residual(morphine_mdl))\n\n contrast effect.size    SE df lower.CL upper.CL\n MS - MM       -1.061 0.516 35    -2.11  -0.0135\n MS - SS       -1.237 0.521 35    -2.30  -0.1789\n MS - SM       -3.536 0.655 35    -4.86  -2.2065\n MS - McM      -4.419 0.727 35    -5.90  -2.9428\n MM - SS       -0.177 0.500 35    -1.19   0.8392\n MM - SM       -2.475 0.581 35    -3.65  -1.2955\n MM - McM      -3.359 0.641 35    -4.66  -2.0570\n SS - SM       -2.298 0.570 35    -3.46  -1.1400\n SS - McM      -3.182 0.628 35    -4.46  -1.9067\n SM - McM      -0.884 0.511 35    -1.92   0.1536\n\nsigma used for effect sizes: 5.657 \nConfidence level used: 0.95 \n\n\nThat said, there is some debate as to whether this is the most appropriate way to calculate posthoc effect sizes, or whether posthoc effect sizes are in general a proper thing to calculate. I’ve personally never had a reviewer ask for one, BUT if I had to provide on I would use this method.\nFWIW, this won’t be the last time that we need to call back to the original (omnibus) ANOVA when conducting posthoc tests. Things get a little messier next week!"
  },
  {
    "objectID": "week09/9_1-posthocs.html#reporting-and-anova-with-post-hoc-analyses.",
    "href": "week09/9_1-posthocs.html#reporting-and-anova-with-post-hoc-analyses.",
    "title": "Multiple comparisons in One-way ANOVA, pt. 1: post hoc tests",
    "section": "Reporting and ANOVA with post hoc analyses.",
    "text": "Reporting and ANOVA with post hoc analyses.\nIn your report, you need to include information for the main ANOVA as well as information related to\n\nthe omnibus ANOVA\na statement on what multiple comparisons were run and how corrected\nnote which comparisons were significant.\n\nIf we work off of our last example, you’ll note that there are quite a few comparisons that we could discuss (10 in fact). In cases like these you could either put this information into a formatted table, or simply highlight a few that are especially relevant. For example, looking at the emmeans() outcome as well as the CLD plot from agricolae::HSD.test we see that McM and SM (a’s) in the CLD plot are both significantly greater than the remain conditions (b’s). Based on this I would write something like:\n… Our ANOVA revealed a significant effect for Morphine treatment group, F(4, 35) = 27.325, p < .001. Tukey pairwise comparisons revealed that the mean tolerance times for the both the SM (\\(M±SD\\): 24.00 ± 6.37) and McM (29.00 ± 6.16) groups were greater than the remaining three groups (\\(ps\\) < .05), but not different from one another. The mean times for the remaining three conditions were not significantly different from one another, \\(ps > .05\\) (see Figure 1)\n\nassuming Figure 1 is a camera ready plot you’ve created in ggplot(). Any of the barplots in this walkthrough will suffice."
  },
  {
    "objectID": "week10/10_1-main_effects.html",
    "href": "week10/10_1-main_effects.html",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "",
    "text": "Note that this week’s vignette assumes you have the following packages:"
  },
  {
    "objectID": "week10/10_1-main_effects.html#tldr",
    "href": "week10/10_1-main_effects.html#tldr",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "TLDR;",
    "text": "TLDR;\nTo run a factorial ANOVA we can use the lm() method we are familiar with. In this walkthrough we only focus on what can be done with the omnibus ANOVA assuming no interactions:\nThe general steps for running a factorial ANOVA:\n\nconstruct your ANOVA model using lm\n\nuse the residuals of the model to test for normality and heteroscadicity\ntest the model, checking for the presence of an interaction, and any main effects.\nIf no interaction proceed with any necessary post hoc analyses on the main effects.\n\nThis week we will be focusing on Steps 1, 2, and 4, i.e., we won’t be formally looking at potential interaction effects. However, as we will see next week, analyzing and interpreting interaction effects is a critical part of factorial ANOVA.\nFor now, I want you focused on building intuitions about dealing with main effects.\nExample\n\n# Preliminaries\n## load in data\ndataset <- read_csv(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/factorial_ANOVA_dataset_no_interactions.csv\")\n\nRows: 36 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Lecture, Presentation\ndbl (2): Score, PartID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## in this case, fixing IV columns...\ndataset$Lecture <- recode_factor(dataset$Lecture, \"1\"=\"Phys\",\"2\"=\"Soc\",\"3\"=\"Hist\")\n\ndataset$Presentation <- recode_factor(dataset$Presentation, \"1\"=\"Comp\",\"2\"=\"Stand\")\n\n\n# Step 1: create the additive ANOVA model\n# note that this is not a full factorial model, but what we are focusing on this week:\naov_model <- lm(Score~Lecture + Presentation,data = dataset)\n\n# Step 2a: test normalty / heteroscadicity using model visually, best to run from your console:\nperformance::check_model(aov_model)\n\n\n\n# Step 2b: check normality and homogeneity assumptions using tests:\n\n# test residuals of model for normality:\naov_model %>% resid() %>% shapiro.test()\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.98464, p-value = 0.8873\n\n# test homogeneity:\n# note we are using a test from the performance package due to (somewhat) artificial limitations of the instruction method (see below)\naov_model %>% performance::check_homogeneity()\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.040).\n\n# Step 3: check the F-ratio for significance\n# note I'm only slecting columns from the anova table that are relevant to us:\n\naov_model %>% sjstats::anova_stats() %>%\n  dplyr::select(c(\"term\",\"df\",\"statistic\",\"p.value\",\"partial.etasq\"))\n\nterm         | df | statistic | p.value | partial.etasq\n-------------------------------------------------------\nLecture      |  2 |     3.779 |   0.034 |         0.191\nPresentation |  1 |    22.670 |  < .001 |         0.415\nResiduals    | 32 |           |         |              \n\n# Step 4: Post hoc analyses on main effects\nemmeans(aov_model, specs = pairwise~Lecture, adjust=\"tukey\")\n\n$emmeans\n Lecture emmean   SE df lower.CL upper.CL\n Phys      40.0 2.14 32     35.6     44.4\n Soc       31.8 2.14 32     27.5     36.2\n Hist      34.5 2.14 32     30.1     38.9\n\nResults are averaged over the levels of: Presentation \nConfidence level used: 0.95 \n\n$contrasts\n contrast    estimate   SE df t.ratio p.value\n Phys - Soc      8.17 3.03 32   2.696  0.0291\n Phys - Hist     5.50 3.03 32   1.815  0.1807\n Soc - Hist     -2.67 3.03 32  -0.880  0.6565\n\nResults are averaged over the levels of: Presentation \nP value adjustment: tukey method for comparing a family of 3 estimates \n\nemmeans(aov_model, specs = pairwise~Presentation, adjust=\"tukey\")\n\n$emmeans\n Presentation emmean   SE df lower.CL upper.CL\n Comp           41.3 1.75 32     37.8     44.9\n Stand          29.6 1.75 32     26.0     33.1\n\nResults are averaged over the levels of: Lecture \nConfidence level used: 0.95 \n\n$contrasts\n contrast     estimate   SE df t.ratio p.value\n Comp - Stand     11.8 2.47 32   4.761  <.0001\n\nResults are averaged over the levels of: Lecture"
  },
  {
    "objectID": "week10/10_1-main_effects.html#analysis-of-variance-factorial-anova",
    "href": "week10/10_1-main_effects.html#analysis-of-variance-factorial-anova",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Analysis of Variance: Factorial ANOVA",
    "text": "Analysis of Variance: Factorial ANOVA\nIn this week’s vignette we are simply building upon the previous two weeks coverage of One-way ANOVA and multiple comparisons. I’m assuming you’ve taken a look at all of the assigned material related to these topics. This week we up the ante by introducing more complex ANOVA models, aka factorial design. As we discussed in class, a factorial ANOVA design is required (well, for the purposes of this course) when your experimental design has more than one IV. Our examples this week focus on situations involving two IVs, however, what is said here applies for more complex designs involving 3, 4, 5, or however many IV’s you want to consider. Well, maybe not however many… as we we’ll see this week and the next, the more IVs you include in your analysis, the more difficult interpreting your results becomes. This is especially true if you have interaction effects running all over the place. But perhaps I’m getting a little bit ahead of myself. Let’s just way I wouldn’t recommend including more than 3 or 4 IVs in your ANOVA at a single time and for now leave it at that."
  },
  {
    "objectID": "week10/10_1-main_effects.html#main-effect-main-effect-and-interactions-oh-my",
    "href": "week10/10_1-main_effects.html#main-effect-main-effect-and-interactions-oh-my",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Main effect, main effect, and interactions… oh my!",
    "text": "Main effect, main effect, and interactions… oh my!\nWhen we are performing a factorial ANOVA we are performing a series of independent comparisons of means as a function of our IVs (this assumption of independence is one of the reasons that we don’t typically concern ourselves with adjusting our p-values in the omnibus factorial ANOVA). For any given number of IVs, or factors, we test for a main effect of that factor on the data—that is “do means grouped by levels within that factor differ from one another not taking into consideration the influence of any of the other IVs”. Our tests for interactions do consider the possibility that our factors influence one another—that is,”do the differences that are observed in one factor depend on the intersecting level of another?”\nFor the sake of simplicity, we will start with a 2 × 2 ANOVA and work our way up by extending the data set. Given our naming conventions, saying that we have a 2 × 2 ANOVA indicates that there are 2 IVs and each has 2 levels. A 2 × 3 ANOVA indicates that there are 2 IVs, and that the first IV has 2 levels and the second has 3 levels; a 2 × 3 × 4 ANOVA indicates that we have 3 IVs, the first has 2 levels, the second has 3 levels, and the third has 4 levels.\nOur example ANOVA comes from a study testing the effects of smoking on performance in different types of putatively (perhaps I’m showing my theoretical biases here) information processing tasks.\nThere were 3 types of cognitive tasks:\n\n1 = a pattern recognition task where participants had to locate a target on a screen;\n2 = a cognitive task where participants had to read a passage and recall bits of information from that passage later;\n3 = participants performed a driving simulation.\n\nAdditionally, 3 groups of smokers were recruited\n\n1 = those that were actively smoking prior to and during the experiment;\n2 = those that were smokers, but did not smoke 3 hours prior to the experiment;\n3 = non-smokers.\n\nAs this is a between design, each participants only completed one of the cognitive tasks."
  },
  {
    "objectID": "week10/10_1-main_effects.html#example-1-a-22-anova",
    "href": "week10/10_1-main_effects.html#example-1-a-22-anova",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Example 1: a 2×2 ANOVA",
    "text": "Example 1: a 2×2 ANOVA\nLet’s grab the data from from the web. Note that for now we are going to ignore the covar column.\n\ndataset <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Sec13-5.dat\", \"\\t\", escape_double = FALSE, trim_ws = TRUE)\n\nRows: 135 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (4): Task, Smkgrp, score, covar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndataset\n\n# A tibble: 135 × 4\n    Task Smkgrp score covar\n   <dbl>  <dbl> <dbl> <dbl>\n 1     1      1     9   107\n 2     1      1     8   133\n 3     1      1    12   123\n 4     1      1    10    94\n 5     1      1     7    83\n 6     1      1    10    86\n 7     1      1     9   112\n 8     1      1    11   117\n 9     1      1     8   130\n10     1      1    10   111\n# ℹ 125 more rows\n\n\nLooking at this data, the first think that we need to do is recode the factors. Recall that we can do this using recode_factor…\nNinja-up\nAs an alternative to mutate(), you can add a new column to a data frame by invoking dataframe$new_column. This saves us a bit of typing. Also, for weeks I’ve told you not to overwrite existing columns, and I maintain that is best practice for beginners. However, in this example we will overwrite.\n\ndataset$Task <- recode_factor(dataset$Task, \"1\" = \"Pattern Recognition\", \"2\" = \"Cognitive\", \"3\" = \"Driving Simulation\") \n\ndataset$Smkgrp <- recode_factor(dataset$Smkgrp, \"3\" = \"Nonsmoking\", \"2\" = \"Delayed\", \"1\" = \"Active\")\n\nTo get a quick view of our data structure we can use two kinds of calls:\nsummary() provides us with info related to each column in the data frame. If a column contains a factor it provides frequency counts of each level. It the column is numeric it provides summary stats:\n\nsummary(dataset)\n\n                  Task           Smkgrp       score           covar      \n Pattern Recognition:45   Nonsmoking:45   Min.   : 0.00   Min.   : 64.0  \n Cognitive          :45   Delayed   :45   1st Qu.: 6.00   1st Qu.: 99.0  \n Driving Simulation :45   Active    :45   Median :11.00   Median :111.0  \n                                          Mean   :18.26   Mean   :112.5  \n                                          3rd Qu.:26.00   3rd Qu.:128.0  \n                                          Max.   :75.00   Max.   :191.0  \n\n\nIn addition, I like to use the ezDesign() function from the ez package to get a feel for counts in each cell. This is useful for identifying conditions that may have missing data.\n\nez::ezDesign(data = dataset, \n             x=Task, # what do you want along the x-axis\n             y=Smkgrp, # what do you want along the y-axis\n             row = NULL, # are we doing any sub-divisions by row...\n             col = NULL) # or column\n\n\n\n\nThis provides us with a graphic representation of cell counts. In this case, every condition (cell) has 15 participants. As you can see right now this is a 3 x 3 ANOVA.\nTo start, let’s imagine that we are only comparing the active smokers to the nonsmokers, and that we are only concerned with the pattern recognition v driving simulation. In this circumstance we are running a 2 (smoking group: active v. passive) × 2 (task: pattern recognition v. driving simulation) ANOVA. We can do a quick subsetting of this data using the filter() command. For our sake, let’s create a new object with this data, dataset_2by2:\n\n# subsetting the data. Remember that \"!=\" means \"does not equal\"; \"&\" suggests that both cases must be met, so\ndataset_2by2 <- filter(dataset, Smkgrp!=\"Delayed\" & Task!=\"Cognitive\")\n\nTo get a quick impression of what this dataset looks like, we can use the summary() function, or ezDesign():\n\n# getting a summary of dataset_2by2:\nsummary(dataset_2by2)\n\n                  Task           Smkgrp       score           covar       \n Pattern Recognition:30   Nonsmoking:30   Min.   : 0.00   Min.   : 64.00  \n Cognitive          : 0   Delayed   : 0   1st Qu.: 2.75   1st Qu.: 98.75  \n Driving Simulation :30   Active    :30   Median : 8.00   Median :111.00  \n                                          Mean   : 7.90   Mean   :110.73  \n                                          3rd Qu.:11.00   3rd Qu.:123.00  \n                                          Max.   :22.00   Max.   :168.00  \n\nez::ezDesign(data = dataset_2by2, \n             x=Task, # what do you want along the x-axis\n             y=Smkgrp, # what do you want along the y-axis\n             row = NULL, # are we doing any sub-divisions by row...\n             col = NULL) # or column\n\n\n\n\nYou may notice from the summary above that the groups that were dropped “Delayed” smokers and “Cognitive” task still show up in the summary, albeit now with 0 instances (you’ll also notice that the remaining groups decreased in number, can you figure out why?). In most cases, R notices this an will automatically drop these factors in our subsequent analyses. However, if needed (i.e. it’s causing errors), these factors can be dropped by invoking the droplevels()function like so:\n\ndataset_2by2 <- dataset_2by2 %>% droplevels()\nsummary(dataset_2by2)\n\n                  Task           Smkgrp       score           covar       \n Pattern Recognition:30   Nonsmoking:30   Min.   : 0.00   Min.   : 64.00  \n Driving Simulation :30   Active    :30   1st Qu.: 2.75   1st Qu.: 98.75  \n                                          Median : 8.00   Median :111.00  \n                                          Mean   : 7.90   Mean   :110.73  \n                                          3rd Qu.:11.00   3rd Qu.:123.00  \n                                          Max.   :22.00   Max.   :168.00  \n\n\nAnd to see the cell counts:\n\nez::ezDesign(data = dataset_2by2, x=Task,y=Smkgrp,row = NULL,col = NULL)"
  },
  {
    "objectID": "week10/10_1-main_effects.html#making-sense-of-plots",
    "href": "week10/10_1-main_effects.html#making-sense-of-plots",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Making sense of plots",
    "text": "Making sense of plots\nLet’s go ahead and plot the data using a line plot with 95% CI error bars. Note that these plots (up until the last section) are not APA-complete!!!!\nInteraction plots\nInteraction plots take into consideration the influence of each of the IVs on one another—in this case the mean and CI of each smoking group (Active v. Nonsmoking) as a function of Task (Driving Simulation v. Pattern Recognition). There is an additional consideration when plotting multiple predictors. That said, all we are doing is extending the plotting methods that you have been using for the past few weeks. The important addition here is the addition of group= in the first line the ggplot. For example:\n\nggplot2::ggplot(data = dataset, mapping=aes(x=Smkgrp,y=score,group=Task))\n\nindicates that we are:\n\nusing the dataset data set\nputting first IV, Smkgrp, on the x-axis\nputting our dv, score on the y-axis\nand grouping our data by our other IV, Task\n\nThis last bit is important as it makes clear that the resulting mean plots should be of the cell means related to Smkgrp x Task\nFor example, a line plot might look like this. Note that I am assigning a different shape and linetype to each level of Task:\n\n# line plot\nggplot(data = dataset_2by2, mapping=aes(x=Smkgrp,\n                                        y=score,\n                                        group=Task,\n                                        shape = Task)) +\n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_se\") + \n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               aes(linetype = Task)) +\n  theme_cowplot()\n\n\n\n\nOne thing you may have noticed is that is very difficult to distinguish between my Task groups at the Non-smoking level, the points and error bars are overlapping one another. One way to fix this is to use the position_dodge() function. This effectively shifts the data points to the left and right to separate them from one another. You need to perform an identical position_dodge() for each element you intend to shift. In this case, we need to include it in both the pointrange and line parts of our both.\nRewriting the above (while also getting rid of color per APA format)\n\n# line plot with dodging\nggplot(data = dataset_2by2, \n       mapping=aes(x=Smkgrp,\n                   y=score,\n                   group=Task,\n                   shape = Task)\n       ) +\n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_se\",\n               position = position_dodge(0.25),\n) + \n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               aes(linetype = Task),\n               position = position_dodge(0.25)\n) +\n  theme_cowplot()\n\n\n\n\nA brief inspection of the plot can be quite informative. Let’s start with the interaction, in fact: you should always start with the interaction. Since this is an “interaction” plot, often a quick visual inspection will allow us to predict whether our subsequent ANOVA will likely yield an interaction effect (it’s good practice to plot your data before running your ANOVA). A simple rule of thumb is that if you see the lines converging or intersecting then more than likely an interaction is present. However, whether it’s statistically significant is another question. You might think that this rule of thumb is useful if you use a line plot, and well, you’d be right. What about a bar plot, you ask? * Note that when generating a grouped barplot, you may need to position dodge to ensure your bars don’t overlap. Typically selecting a value of 0.9 ensures they do not overlap, but also that your grouped bars are touching one another with no gap between. For practice try changing the position_dodge values in the plot below to see how that effects the plot.\n\n# barplot\nggplot(data = dataset_2by2, mapping=aes(x=Smkgrp,y=score,group=Task)) +\n  stat_summary(geom = \"bar\",\n               fun = \"mean\",\n               color=\"black\", \n               aes(fill=Task), \n               position=position_dodge(.9)) +\n    stat_summary(geom=\"errorbar\", \n                 width=.3, \n                 fun.data = \"mean_se\", \n                 position = position_dodge(.9)) +\n  theme(legend.position=\"none\") +\n  scale_fill_manual(values = c(\"light grey\", \"white\"))\n\n\n\n\nNote that the grey fills above are the “Driving Simulation” group and the white are the “Pattern Recognition”. Take a look at the means. If the relative difference between grouped means changes as you move from one category on the x-axis to the next, you likely have an interaction. Note that this is a general rule of thumb and applies to the line plots as well (the reason that the lines intersect is because of these sorts of changes). In this case, the bar (cell) means on the “Active” grouping are nearly identical, while the bar means in the “Nonsmoking” grouping are much further apart. So we likely have interaction.\nPlotting main effects\nIf we wanted we could also create separate plots related to our mean effects. Remember that a main effect takes a look at the difference in means for one IV independent of the other IV(s). For example, consider Smkgrp, we are looking at the means of Nonsmoking and Active indifferent to Task. These plots would look something like this:\n\nSmoke_main_effect_plot <- ggplot2::ggplot(data = dataset_2by2, mapping=aes(x=Smkgrp,y=score, group=1)) + \n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_se\", \n               position=position_dodge(0)) + \n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               position=position_dodge(0)) + \n  coord_cartesian(ylim=c(4,12)) +\n  theme_cowplot()\n\nshow(Smoke_main_effect_plot)\n\n\n\n\n\nTask_main_effect_plot <- ggplot2::ggplot(data = dataset_2by2, mapping=aes(x=Task,y=score, group=1)) + \n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_se\", \n               position=position_dodge(0)) + \n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               position=position_dodge(0)) + \n  coord_cartesian(ylim=c(4,12)) +\n  theme_cowplot()\n\nshow(Task_main_effect_plot)\n\n\n\n\nand would take a look at changes due to each IV without considering the other. Here we might infer that there is a main effect for both of our IVs.\nThat said, the original interaction plot is useful as well in assessing main effects as well. In this case, to infer whether there might be main effects we can imagine where the means would be if we collapsed our grouped plots (this is exactly what the main effects take a look at). To help with your imagination I’m going to plot our main effect means on the interaction plot. Here the grey-filled triangles represent the the collapsed Smoking Group means indifferent to task. To get these, just imagine finding the midpoint of the two circles in each level of Smoking group. The slope suggests the possibility a main effect.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nTo imagine the collapsed Task means, we can just find the y-values that intersect with the midpoints of each line (note the red line is the mean value of the Driving Simulation group):\n\n\n\n\n\nThe difference in y-intercepts suggests the possibility of a main effect.\nSo in summary, I’m guessing from plot I’ve got 2 main effects and an interaction. For this week, we are only going to focus on the main effects. In the future, you’ll see that we would need to test for the interaction as well, and if it was present we would need to “deal” with that first.\nFor now, let’s focus on testing the main effects."
  },
  {
    "objectID": "week10/10_1-main_effects.html#running-the-anova-lm-method",
    "href": "week10/10_1-main_effects.html#running-the-anova-lm-method",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Running the ANOVA lm() method",
    "text": "Running the ANOVA lm() method\nNow we can run the using the lm() method as we have previously done with the One-way ANOVA. The new wrinkle is simply adding our additional IV terms to the the formula equation:\n\\[y=IV_1+IV_2+...+IV_n\\]\nwhere the first and second terms capture our main effects and the third is our interaction.\nUsing our data in R this formula becomes:\n\naov_model <- lm(score~Smkgrp+Task,data = dataset_2by2)"
  },
  {
    "objectID": "week10/10_1-main_effects.html#assumption-testing",
    "href": "week10/10_1-main_effects.html#assumption-testing",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Assumption testing",
    "text": "Assumption testing\nvisual inspection\nLet’s quickly assess whether the prescribed model satisfies the assumptions for general linear models. Visually we may call upon the performance::check_model(). to get a series of visual inspection checks in a single plot. Note that you encounter errors in your .qmd, you may try to run this directly from your Console\n\naov_model %>% performance::check_model()\n\n\n\n\nAlternatively, running the above with panel = FALSE allows you to see each plot individually.\n\naov_model %>% performance::check_model(panel = FALSE)\n\nFor our purposes this semester, the Homogeneity of Variance and Normality of Residuals plots are most important. Visual inspection suggests that while normality may not be and issue, there is potentially something awry with the homogeneity of variance.\ntest for assessing normality\nIf we want to check the normality of residuals we may use the Shapiro-Wilkes Test. We can call it directly using shapiro.test() or from the performance library. I show both methods below (you only need to choose ONE. In week’s past you’ve been using the shapiro.test():\n\naov_model$residuals %>% shapiro.test()\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.98464, p-value = 0.8873\n\naov_model %>% performance::check_normality()\n\nOK: residuals appear as normally distributed (p = 0.887).\n\n\nKeep in mind that the Shapiro-Wilkes test for normality is notoriously conservative. In week’s past we discussed an alternative based on this method from Kim (2013) “Statistical notes for clinical researchers: assessing normal distribution using skewness and kurtosis”:\n\n# recommendation from Kim (2013)\nsource(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/custom_functions/skew_kurtosis_z.R\")\n\naov_model$residuals %>% skew_kurtosis_z()\n\n       upr.ci crit_vals\nskew_z   0.75      1.96\nkurt_z  -0.02      1.96\n\n\nBased on what you see what conclusions might you make?\ntest for assessing homogeneity of variance\nTypically, we can submit our aov_model to car::leveneTest to test for homogeneity. However, for this week only, this will produce an error. This is because the car::leveneTest() demands that the IVs in a factorial ANOVA be crossed. That is, the Levene’s test requires that we include the interaction term in our model. This week, we are NOT looking at interactions, nor am I asking you to include the terms in our model. Because of this, we will us an alternate method, the Bartlet test while noting that in future weeks, and under most practical circumstances this will not be an issue. FWIW, the performance method works as a reliable alternative to car::leveneTest in most circumstances, so you could elect to just use this instead using method = \"levene\".\n\naov_model %>% performance::check_homogeneity(method = \"bartlet\")\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.040).\n\n\nOur test says we have a violation (which is consistent with our visual inspection above. Let’s take a look at the 3x time rule. To do this we need to get a feel for the variance within each cell. While we are at it we might as well get the means too. Which leads to the next section (don’t worry we’ll come back to this)"
  },
  {
    "objectID": "week10/10_1-main_effects.html#getting-cell-means-and-sd",
    "href": "week10/10_1-main_effects.html#getting-cell-means-and-sd",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Getting cell means and sd",
    "text": "Getting cell means and sd\nUp until this point we’ve used psych::describeBy() to generate summary stats. This becomes a little more difficult as the designs become more complex. Alternatively you might elect to build a data table yourself. You learned how to do this a few weeks ago using the summarise function:\n\ndataset_2by2 %>% \n  group_by(Task, Smkgrp) %>%\n  summarise(mean = mean(score), # get group means\n            var = var(score)) # get group variances\n\n`summarise()` has grouped output by 'Task'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 4\n# Groups:   Task [2]\n  Task                Smkgrp      mean   var\n  <fct>               <fct>      <dbl> <dbl>\n1 Pattern Recognition Nonsmoking  9.93 42.5 \n2 Pattern Recognition Active      9.4   1.97\n3 Driving Simulation  Nonsmoking  9.93 36.1 \n4 Driving Simulation  Active      2.33  5.24\n\n\nAnother alternative, that I would recommend over the psych package is to use summarySE() from the Rmisc package:\n\nRmisc::summarySE(data = dataset_2by2, # your dataset\n                 measurevar = \"score\", # your dv\n                 groupvars = c(\"Task\",\"Smkgrp\")) # your between-groups IV(s)\n\n                 Task     Smkgrp  N    score       sd        se        ci\n1 Pattern Recognition Nonsmoking 15 9.933333 6.518837 1.6831565 3.6100117\n2 Pattern Recognition     Active 15 9.400000 1.404076 0.3625308 0.7775512\n3  Driving Simulation Nonsmoking 15 9.933333 6.005553 1.5506271 3.3257644\n4  Driving Simulation     Active 15 2.333333 2.288689 0.5909368 1.2674335\n\n\nRecalling that we had an issue with heteroscadicity, we can now use the obtained sd values to assess whether our violation is too great. Let’s save our summary table:\n\ncell_summary_table <- Rmisc::summarySE(data = dataset_2by2, # your dataset\n                                       measurevar = \"score\", # your dv\n                                       groupvars = c(\"Task\",\"Smkgrp\"))\n\nfrom this we can call the sd values and square them to get our variance:\n\n# varience is sd-squared:\ncell_summary_table$sd^2\n\n[1] 42.495238  1.971429 36.066667  5.238095\n\n\nHouston we have a problem! The largest variance there is definitely greater than 3x the smallest. What to do? For now nothing, I don’t want you to go down that rabbit hole just yet. But look for info on dealing with this later."
  },
  {
    "objectID": "week10/10_1-main_effects.html#getting-marginal-means-for-main-effects",
    "href": "week10/10_1-main_effects.html#getting-marginal-means-for-main-effects",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "getting marginal means for main effects",
    "text": "getting marginal means for main effects\nWe can also use this function to report the means related to the main effects (irrespective of interaction).\nFor example, Smoking effect I can re-write the call above, simply dropping Task from groupvars:\n\nRmisc::summarySE(data = dataset_2by2,measurevar = \"score\",groupvars = \"Smkgrp\")\n\n      Smkgrp  N    score       sd        se       ci\n1 Nonsmoking 30 9.933333 6.158444 1.1243730 2.299601\n2     Active 30 5.866667 4.049124 0.7392655 1.511968\n\n\nand for the Task effect:\n\nRmisc::summarySE(data = dataset_2by2,measurevar = \"score\",groupvars = \"Task\")\n\n                 Task  N    score       sd        se       ci\n1 Pattern Recognition 30 9.666667 4.641145 0.8473533 1.733032\n2  Driving Simulation 30 6.133333 5.905774 1.0782418 2.205252\n\n\nNote that If you are reporting means related to the main effects, you need to report these marginal means!\nHOWEVER… this data has an interaction, and remember what I said above, if the data has an interaction, you need to deal with that first. We’ll show how to work with data that has interactions next week."
  },
  {
    "objectID": "week10/10_1-main_effects.html#testing-the-anova",
    "href": "week10/10_1-main_effects.html#testing-the-anova",
    "title": "Factorial ANOVA - The omnibus ANOVA and Main effects",
    "section": "Testing the ANOVA",
    "text": "Testing the ANOVA\nOk. Now let’s look at our ANOVA table. Note that instead of the full print out, I’m asking sjstats to only give me the values I’m interested in: the term (effect), df, (F) statistic, p-value, and effect size, in this case partial.eta\n\nsjstats::anova_stats(aov_model) %>% select(\"term\",\"df\",\"statistic\",\"p.value\",\"partial.etasq\")\n\nterm         | df | statistic | p.value | partial.etasq\n-------------------------------------------------------\nLecture      |  2 |     3.779 |   0.034 |         0.191\nPresentation |  1 |    22.670 |  < .001 |         0.415\nResiduals    | 32 |           |         |              \n\n\nYou’ll note that both main effects are significant, meaning that we would need to perform pairwise, post-hoc comparisions for each effect. BUT you’ll also note that each of our factors ONLY HAD TWO LEVELS, meaning that the F-test in the ANOVA table IS a pairwise comparison. In cases like this, when the effect only has 2 levels, we are done (any post hoc analysis would be redundant).\nAssuming you feel comfortable with everything in this walkthrough, let’s proceed to the next, which includes cases where our factors have three (or more) levels."
  },
  {
    "objectID": "week02/2_1-structure_data.html",
    "href": "week02/2_1-structure_data.html",
    "title": "The structure of your data",
    "section": "",
    "text": "Last week we covered how to import data from file into an R data frame. Before taking any next steps with your analysis, you first should take a moment to understand the structure of your data. Every statical software wants the data to have a particular format, R included. One thing that you will need to be sensitive of is that not every bit of software (or even atype of analysis) wants the data in the same format. In order to perform the appropriate analyses, you need to have the data in the right formatting structure. One crucial issue that confronts many first time users coming from SPSS is whether the data is in WIDE or LONG format.\nLet’s load some example data and assign it to the object reading_data:\n\n# loading in the packages, see \"Week 1: Leveling up\npacman::p_load(tidyverse) \nreading_data <- read_table(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/reading.txt\", col_names = T)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  id = col_double(),\n  group = col_character(),\n  pretest1 = col_double(),\n  pretest2 = col_double(),\n  posttest1 = col_double(),\n  posttest2 = col_double(),\n  posttest3 = col_double()\n)\n\n\nAnd now look at the data:\n\nreading_data\n\n# A tibble: 66 × 7\n      id group   pretest1 pretest2 posttest1 posttest2 posttest3\n   <dbl> <chr>      <dbl>    <dbl>     <dbl>     <dbl>     <dbl>\n 1     1 Control        4        3         5         4        41\n 2     2 Control        6        5         9         5        41\n 3     3 Control        9        4         5         3        43\n 4     4 Control       12        6         8         5        46\n 5     5 Control       16        5        10         9        46\n 6     6 Control       15       13         9         8        45\n 7     7 Control       14        8        12         5        45\n 8     8 Control       12        7         5         5        32\n 9     9 Control       12        3         8         7        33\n10    10 Control        8        8         7         7        39\n# ℹ 56 more rows\n\n\nPausing a moment, typing out reading_data alone give us a print out of the entire data frame. This is a good way to get a sense of what the data look like. However, if you have a large data frame, this can be a bit overwhelming. Instead, we can use the head() function to look at the first 6 rows of the data frame:\n\nhead(reading_data)\n\n# A tibble: 6 × 7\n     id group   pretest1 pretest2 posttest1 posttest2 posttest3\n  <dbl> <chr>      <dbl>    <dbl>     <dbl>     <dbl>     <dbl>\n1     1 Control        4        3         5         4        41\n2     2 Control        6        5         9         5        41\n3     3 Control        9        4         5         3        43\n4     4 Control       12        6         8         5        46\n5     5 Control       16        5        10         9        46\n6     6 Control       15       13         9         8        45\n\n\nAlternatively, if we want to get a listing of all of the column names, and their data types, we can use the str() function, or if using tidyverse, the glimpse() function. Since we’ll almost always be loading in the tidyverse, we’ll use glimpse():\n\nglimpse(reading_data) #tidyverse\n\nRows: 66\nColumns: 7\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ group     <chr> \"Control\", \"Control\", \"Control\", \"Control\", \"Control\", \"Cont…\n$ pretest1  <dbl> 4, 6, 9, 12, 16, 15, 14, 12, 12, 8, 13, 9, 12, 12, 12, 10, 8…\n$ pretest2  <dbl> 3, 5, 4, 6, 5, 13, 8, 7, 3, 8, 7, 2, 5, 2, 2, 10, 5, 5, 3, 4…\n$ posttest1 <dbl> 5, 9, 5, 8, 10, 9, 12, 5, 8, 7, 12, 4, 4, 8, 6, 9, 3, 5, 4, …\n$ posttest2 <dbl> 4, 5, 3, 5, 9, 8, 5, 5, 7, 7, 4, 4, 6, 8, 4, 10, 3, 5, 5, 3,…\n$ posttest3 <dbl> 41, 41, 43, 46, 46, 45, 45, 32, 33, 39, 42, 45, 39, 44, 36, …\n\n\nOkay, with that out of the way, on to the data! These are data taken from a study by Baumann, Seifert-Kessell, and Jones (1992). Sixty-six students in Grade 4 were randomly assigned to receive one of three interventions designed to improve reading comprehension. The participants were evenly distributed (n = 22 per intervention group) among an ‘instructional control’ group, a ‘Directed Reading-Thinking Activity’ (DRTA) group, and a ‘Think Aloud’ (TA) group. After each group received its respective intervention, the participants completed an error-detection test designed to evaluate their reading comprehension. The 2 pretest scores represent the number of errors prior to intervention, while the 3 posttest scores were taking post-intervention.\nFor the purposes of this example, let’s trim the 7 columns in the original set to four: id, group, pretest1, and posttest1. To do this we use the select function from the tidyverse. The select function allows us to select columns from a dataframe. The first argument is the dataframe, followed by the names of the columns we want to select., in this case id, group, pretest1, and posttest1.\n\n# pull out my columns of interest\nreading_data_select <- select(reading_data, \"id\", \"group\", \"pretest1\", \"posttest1\")\n\nOkay, now let’s take a moment to reflect on the structure of the data. First, this is a repeated measurement. Both columns pretest1 and posttest1 contain the same measure, test score, and every participant went through both pre and post tests. Most important for present purposes this data is in WIDE format—each line represents a participant, and columns represent scores taken from participants at different trials or times. The same measure, test scores, is spread out amount two columns depending on the time the test was measured, pre and post.\nHowever, while this might be intuitve for tabluar visualization, many statistical softwares prefer when LONG format, where each line represents a single observation, e.g. a participant-trial or participant-time (FWIW SPSS likes some mix of WIDE and LONG).\n** [See this page for a run down of WIDE v. LONG format] (https://www.theanalysisfactor.com/wide-and-long-data/)\n** More, for those that are interested I suggest taking a look at these two wonderful courses on DataCamp:\n\nWorking with Data in the Tidyverse\nCleaning Data in R"
  },
  {
    "objectID": "week02/2_1-structure_data.html#getting-data-from-wide-to-long",
    "href": "week02/2_1-structure_data.html#getting-data-from-wide-to-long",
    "title": "The structure of your data",
    "section": "Getting data from WIDE to LONG",
    "text": "Getting data from WIDE to LONG\nSo the data are in WIDE format, each line has multiple observations of data that are being compared. Here both pretest1 scores and posttest1 scores are on the same line. In order to make life easier for analysis and plotting in ggplot, we need to get the data into LONG format (pretest1 scores and posttest1 scores are on different lines). This can be done using the pivot_longer function from the tidyr package.\nBefore pivoting your data, one thing to consider is whether or not you have a column that defines each subject. In this case we have id. This tells R that these data are coming from the same subject and will allow R to connect these data when performing analysis. This watching will be crucially important later on when we perform t-tests and ANOVAs.\nUsing pivot_longer(): This function takes a number of arguments, but for us right now, the most important are data: your dataframe; cols: which columns to gather; names_to: what do you want the header of the collaped nonminal variables to be? Here, we might ask what title would subsume both pretest1 and posttest1. I’ll choose time ; values_to: what do the values represent, here I choose reading_score:\n\npivot_longer(reading_data_select,cols = c(\"pretest1\",\"posttest1\"),names_to = \"time\", values_to = \"reading_score\")\n\n# A tibble: 132 × 4\n      id group   time      reading_score\n   <dbl> <chr>   <chr>             <dbl>\n 1     1 Control pretest1              4\n 2     1 Control posttest1             5\n 3     2 Control pretest1              6\n 4     2 Control posttest1             9\n 5     3 Control pretest1              9\n 6     3 Control posttest1             5\n 7     4 Control pretest1             12\n 8     4 Control posttest1             8\n 9     5 Control pretest1             16\n10     5 Control posttest1            10\n# ℹ 122 more rows\n\n\nIn terms of how we transformed our data, this webpage has a good representation of going from wide to long and back again.\nA good visual representation of what pivot_longer() can be found here: https://www.garrickadenbuie.com/project/tidyexplain/#pivot-wider-and-longer. The site also has some nice visualizations for other data wrangling functions, like joining data frames and filtering.\nFor most of your analyses you are going to need to put your data in long format. Most of the datasets that I provide for homework will already be in this format, but some data that you pull from the web, or your own lab data may not. If that’s the case, right after you import your data you will need to put it in the correct format (of if you prefer, do this in Excel)."
  },
  {
    "objectID": "week02/2_3-summary_tables.html",
    "href": "week02/2_3-summary_tables.html",
    "title": "Creating summary tables",
    "section": "",
    "text": "This walkthrough assumes you have taken a look at the previous walkthrough. In the last walkthrough we discussed an easy way of getting descriptive stats using the psych package. Here we’ll talk about how toput those values in a APA-esque format. FWIW, I personally am not a big fan of presenting / publishing data in tables. My feeling is that all things being equal, a good plot is typically the most effective way to present data. BUT, I recognize that there are times that call for us to present our data in tables."
  },
  {
    "objectID": "week02/2_3-summary_tables.html#preparing-the-data",
    "href": "week02/2_3-summary_tables.html#preparing-the-data",
    "title": "Creating summary tables",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst let’s load in the packages we’ll need for this:\n\npacman::p_load(psych, tidyverse, pander)\n\nand then recreate the aggression data summary table from the previous walkthrough (alternatively, if you’ve already done so just pull up the aggression_data_summary object). Here I recreate our steps from the previous walkthrough:\n\nload in the data\n\n\nlibrary(readr)\naggression_data <- read_table(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/aggression.dat\", col_names = FALSE)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  X1 = col_double(),\n  X2 = col_double(),\n  X3 = col_double(),\n  X4 = col_double(),\n  X5 = col_double(),\n  X6 = col_double(),\n  X7 = col_double(),\n  X8 = col_double()\n)\n\n\n\n\n\n\nwrangle the data (in this case we only need to add names, and change gender to a category)\n\n\n# add headers:\nnames(aggression_data) <- c('age', 'BPAQ', 'AISS', 'alcohol', 'BIS', 'NEOc', 'gender', 'NEOo')\n\naggression_data <- aggression_data %>% mutate(fctr_Gender = factor(gender)) \naggression_data$fctr_Gender <- recode_factor(aggression_data$fctr_Gender, \"0\" = \"Man\", \"1\" = \"Woman\")\n# \n\n\nget summary stats using psych_describe():\n\n\npsych::describe(aggression_data)\n\n             vars   n  mean    sd median trimmed   mad   min   max range  skew\nage             1 275 20.21  4.96  18.00   19.01  1.48 17.00 50.00 33.00  3.70\nBPAQ            2 275  2.61  0.52   2.62    2.61  0.56  1.34  4.03  2.69  0.01\nAISS            3 275  2.56  0.37   2.55    2.56  0.37  1.45  3.70  2.25  0.01\nalcohol         4 270 16.00 15.87  12.00   13.69 14.83  0.00 96.00 96.00  1.50\nBIS             5 275  2.28  0.35   2.27    2.27  0.40  1.42  3.15  1.73  0.36\nNEOc            6 275  3.55  0.59   3.58    3.55  0.62  1.83  4.92  3.08 -0.16\ngender          7 275  0.79  0.41   1.00    0.86  0.00  0.00  1.00  1.00 -1.44\nNEOo            8 275  3.36  0.52   3.42    3.37  0.49  1.67  4.67  3.00 -0.25\nfctr_Gender*    9 275  1.79  0.41   2.00    1.86  0.00  1.00  2.00  1.00 -1.44\n             kurtosis   se\nage             15.43 0.30\nBPAQ            -0.41 0.03\nAISS             0.23 0.02\nalcohol          3.09 0.97\nBIS             -0.22 0.02\nNEOc            -0.11 0.04\ngender           0.06 0.02\nNEOo            -0.09 0.03\nfctr_Gender*     0.06 0.02"
  },
  {
    "objectID": "week02/2_3-summary_tables.html#generating-summary-statistics-using-tidy-functions.",
    "href": "week02/2_3-summary_tables.html#generating-summary-statistics-using-tidy-functions.",
    "title": "Creating summary tables",
    "section": "Generating summary statistics using tidy functions.",
    "text": "Generating summary statistics using tidy functions.\nOne downside is that by default, psych::describe() doesn’t give us nice pretty (APA-esque) tables, and putting this output into a cleaner format requires a little work. In order to do so, we can leverage some of the functions from the tidyverse. How you go about constructing a cleaner table depends in large part on the content. For example, if you just wanted to convey the number of observations, mean, and std. dev, then it might be best to construct a summary table using dplyr::summarize(). For example a summary of BPAQ:\n\naggression_data_table <- dplyr::summarise(aggression_data,\n                                          \"count\" = n(),\n                                          \"mean\" = mean(BPAQ),\n                                          \"sd\" = sd(BPAQ)\n                                          ) \npander(aggression_data_table,\n       caption = \"Table 1. Summary statistics of BPAQ Scores\")\n\n\nTable 1. Summary statistics of BPAQ Scores\n\n\n\n\n\n\ncount\nmean\nsd\n\n\n275\n2.613\n0.524\n\n\n\n\npander() allows us to put the table in a neat (publication friendly) format, including adding a caption or title.\nUsing the pipe operator we can simplify the code above:\n\ndplyr::summarise(aggression_data,\n                 \"count\" = n(),\n                 \"mean\" = mean(BPAQ),\n                 \"sd\" = sd(BPAQ)\n                 ) %>% # tying these two together with a pipe\n  pander(caption = \"Table 1. Summary statistics of BPAQ Scores\")\n\n\nTable 1. Summary statistics of BPAQ Scores\n\n\n\n\n\n\ncount\nmean\nsd\n\n\n275\n2.613\n0.524\n\n\n\n\nWe can also create a simple table by fctr_Gender by using dplyr::group_by()\n\naggression_data %>% \n  dplyr::group_by(fctr_Gender) %>% \n  dplyr::summarise(\"count\" = n(),\n                   \"mean\" = mean(BPAQ),\n                   \"sd\" = sd(BPAQ)\n                   ) %>% \n  pander(caption = \"Table X. Summary statistics of BPAQ Scores by group\")\n\n\nTable X. Summary statistics of BPAQ Scores by group\n\n\n\n\n\n\n\nfctr_Gender\ncount\nmean\nsd\n\n\n\nMan\n57\n2.662\n0.5096\n\n\nWoman\n218\n2.6\n0.5281\n\n\n\n\n\nThere is still some work to be done if you were sending a table like this to publication. For most of our purposes in class, however, this will do."
  },
  {
    "objectID": "week02/2_3-summary_tables.html#better-apa-using-a-custom-function",
    "href": "week02/2_3-summary_tables.html#better-apa-using-a-custom-function",
    "title": "Creating summary tables",
    "section": "Better APA, using a custom function",
    "text": "Better APA, using a custom function\nFor an alternative, check out this link: https://www.anthonyschmidt.co/post/2020-06-03-making-apa-tables-with-gt/. The author, using the gt package build his own function, apa() to approximate APA formatted tables. This would be an alternative to using pander.\nThe code chunks below leverages his work.\nFirst, his custom function:\n\n# create apa function\n\npacman::p_load(gt)\n\napa <- function(x, title = \" \") {\n  gt(x) %>%\n  tab_options(\n    table.border.top.color = \"white\",\n    heading.title.font.size = px(16),\n    column_labels.border.top.width = 3,\n    column_labels.border.top.color = \"black\",\n    column_labels.border.bottom.width = 3,\n    column_labels.border.bottom.color = \"black\",\n    table_body.border.bottom.color = \"black\",\n    table.border.bottom.color = \"white\",\n    table.width = pct(100),\n    table.background.color = \"white\"\n  ) %>%\n  cols_align(align=\"center\") %>%\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"),\n        color = \"white\",\n        weight = px(1)\n      ),\n      cell_text(\n        align=\"center\"\n      ),\n      cell_fill(color = \"white\", alpha = NULL)\n      ),\n    locations = cells_body(\n      columns = everything(),\n      rows = everything()\n    )\n  ) %>%\n    #title setup\n    tab_header(\n    title = html(\"<i>\", title, \"</i>\")\n  ) %>%\n  opt_align_table_header(align = \"left\")\n}\n\nAnd now applying it to our own data:\n\naggression_data %>%\n  dplyr::group_by(fctr_Gender) %>% \n  dplyr::summarise(\"count\" = n(),\n                   \"mean\" = mean(BPAQ),\n                   \"sd\" = sd(BPAQ)\n                   ) %>%\n  apa(\"Table X. Summary statistics of BPAQ Scores by group\")\n\n\n\n\n\n\n\n Table X. Summary statistics of BPAQ Scores by group \n    \n\nfctr_Gender\n      count\n      mean\n      sd\n    \n\n\n\nMan\n57\n2.661827\n0.509567\n\n\nWoman\n218\n2.599652\n0.528107\n\n\n\n\n\n\nNote that the formatting occurs when you Render."
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html",
    "href": "week10/10_2-factorial_w_post_hocs.html",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "",
    "text": "In the last walkthrough, analyzed a 2×2 ANOVA focusing on our main effects. Because each of our factors only had two levels, there was no need to follow up on significant main effects with pairwise post hoc analysis. In this walkthough we will take a look at examples where our main effects have 3 or more levels, and demand a post-hoc analysis. For now, let’s try another example. First let’s bring in the necessary packages:"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#example-a-2-3-anova",
    "href": "week10/10_2-factorial_w_post_hocs.html#example-a-2-3-anova",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "Example: A 2 × 3 ANOVA",
    "text": "Example: A 2 × 3 ANOVA\nThirty-six college students were randomly assigned to 3 groups (N=12). Students in each group were asked to watch and take notes on a 50 min lecture. One week later all students were tested on the content of their lectures, and their scores were compared. Groups differed by the lecture’s subject matter, where:\n\n\n1 = Physics lecture\n\n2 = Social Science lecture\n\n3 = History lecture\n\nThe lectures were presented in two manners\n\n1 = via computer\n2 = standard method, lecturer in a lecture hall\n\nThe researchers hypothesized that students that learned the material in the standard lecture would perform better than those that learned via computer.\n\ndataset_no_inter <- read_csv(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/factorial_ANOVA_dataset_no_interactions.csv\")\n\nRows: 36 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Lecture, Presentation\ndbl (2): Score, PartID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndataset_no_inter$Lecture <- recode_factor(dataset_no_inter$Lecture, \"1\"=\"Phys\",\"2\"=\"Soc\",\"3\"=\"Hist\")\n\ndataset_no_inter$Presentation <- recode_factor(dataset_no_inter$Presentation, \"1\"=\"Comp\",\"2\"=\"Stand\")\n\nsummary(dataset_no_inter)\n\n Lecture   Presentation     Score           PartID     \n Phys:12   Comp :18     Min.   :18.00   Min.   : 1.00  \n Soc :12   Stand:18     1st Qu.:26.75   1st Qu.: 9.75  \n Hist:12                Median :35.50   Median :18.50  \n                        Mean   :35.44   Mean   :18.50  \n                        3rd Qu.:42.50   3rd Qu.:27.25  \n                        Max.   :53.00   Max.   :36.00  \n\n\nBuilding the ANOVA model\nI’m going to use lm().\n\naov_model <- lm(Score~Presentation + Lecture, data = dataset_no_inter)\n\nTesting assumptions\nvisual\n\naov_model %>% performance::check_model(panel=FALSE)\n\n\naov_model %>% performance::check_normality()\n\nOK: residuals appear as normally distributed (p = 0.887).\n\naov_model %>% performance::check_homogeneity()\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.040).\n\n\nThe model checks both for normality of residuals but fails homogeneity of variance. Following upon given the robustness of ANOVA (3x rule):\n\ndataset_no_inter %>% \n  group_by(Lecture, Presentation) %>%\n  summarise(mean = mean(Score),\n            var = var(Score))\n\n`summarise()` has grouped output by 'Lecture'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 4\n# Groups:   Lecture [3]\n  Lecture Presentation  mean    var\n  <fct>   <fct>        <dbl>  <dbl>\n1 Phys    Comp          46    48.8 \n2 Phys    Stand         34   121.  \n3 Soc     Comp          40    23.2 \n4 Soc     Stand         23.7   7.47\n5 Hist    Comp          38    19.2 \n6 Hist    Stand         31   106.  \n\n\nPotential issues, but moving on.\nInteraction plot\nLet’s plot the data. You’ll note in this plot I’m adding some code to get it into better APA shape. More on this in the next walkthrough. For now just focus on content.\n\n# setting original parameters\np <- ggplot2::ggplot(data = dataset_no_inter, mapping=aes(x=Lecture,y=Score,group=Presentation))\n\n# making a basic line plot\nline_p <- p + stat_summary(geom=\"pointrange\",fun.data = \"mean_se\", size=0.75, position=position_dodge(.25), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun = \"mean\", position=position_dodge(.25), aes(linetype=Presentation))\n\n# adding APA elements\nline_p <- line_p + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.75,.9)) +\n  xlab(\"Lecture type\") + \n  ylab (\"Performance score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  theme_cowplot()\n\nshow(line_p)\n\n\n\n\nTesting the ANOVA\n\naov_model %>% sjstats::anova_stats() %>% \n  select(\"term\",\"df\",\"statistic\",\"p.value\",\"partial.etasq\")\n\nterm         | df | statistic | p.value | partial.etasq\n-------------------------------------------------------\nPresentation |  1 |    22.670 |  < .001 |         0.415\nLecture      |  2 |     3.779 |   0.034 |         0.191\nResiduals    | 32 |           |         |"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#post-hoc-analysis",
    "href": "week10/10_2-factorial_w_post_hocs.html#post-hoc-analysis",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "post hoc analysis",
    "text": "post hoc analysis\nAdmittedly, moving on to this step will ultimately be qualified by the presence of interactions (next week). For now, note that if you don’t have an interaction, you may simply proceed to run post-hoc analyses on any significant main effects in the manner you would with a One-way ANOVA. Easy, peasy, right. One thing to note, you need to make the appropriate multiple comparison corrections. For example, returning to our data with no interaction, we need to test for differences in both the Lecture and Presentation main effects.\n\nPresentation: This one is easy. We only have two levels of Presentation, so the omnibus \\(F\\) test tells us that our two groups are different. Nothing else to do here other than note which mean (Computer v. Standard) is greater than the other.\nLecture: We have three levels of lecture, so were are going to need to run a post-hoc analysis. In this case, we may call upon our old standbys, Tukey and Bonferroni.\n\nJust as last week, we can use emmeans() to run our post-hoc tests.\nFor example, to run a Tukey, you need call your ANOVA model. For the sake of clarity let’s rebuild the ANOVA model and save it to aov_model and then run emmeans()\nHere I’m saving it to the object aov_model:\n\naov_model <- lm(Score~Presentation + Lecture, data = dataset_no_inter)\n\nFrom here you may call upon the emmeans() function to derive your posthocs. By itself, emmeans produces the means by levels of the IV(s) listed in its spec= argument. It takes the lm() model as a first argument, and the IVs of interest as the second.\n\n# input your model into the emmeans,\n# interested in Lecture\n\nemmeans(aov_model,specs = ~Lecture)\n\n Lecture emmean   SE df lower.CL upper.CL\n Phys      40.0 2.14 32     35.6     44.4\n Soc       31.8 2.14 32     27.5     36.2\n Hist      34.5 2.14 32     30.1     38.9\n\nResults are averaged over the levels of: Presentation \nConfidence level used: 0.95 \n\n\nemmeans() alone gives us the estimated marginal means for each of our levels, to run a post-hoc comparison we then pipe it into pairs() and include the p value adjustment that we would like to make. allows another method for making contrasts (planned and posthoc). If you want to perform a Tukey test follow this procedure you can simply pipe the previous (or save to an object and submit) to pairs():\n\nemmeans(aov_model,specs = ~Lecture) %>% pairs(adjust=\"tukey\") \n\n contrast    estimate   SE df t.ratio p.value\n Phys - Soc      8.17 3.03 32   2.696  0.0291\n Phys - Hist     5.50 3.03 32   1.815  0.1807\n Soc - Hist     -2.67 3.03 32  -0.880  0.6565\n\nResults are averaged over the levels of: Presentation \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nIn this case it appears that our Tukey does reveal differences between means, when performance of those getting Physical Science Lectures is greater than both History and Social, but Social and History are not difference from one another.\nNote that you may call other p-value adjustments using these methods:\n\nemmeans(aov_model,specs = ~Lecture) %>% pairs(adjust=\"bonferroni\")\n\n contrast    estimate   SE df t.ratio p.value\n Phys - Soc      8.17 3.03 32   2.696  0.0333\n Phys - Hist     5.50 3.03 32   1.815  0.2365\n Soc - Hist     -2.67 3.03 32  -0.880  1.0000\n\nResults are averaged over the levels of: Presentation \nP value adjustment: bonferroni method for 3 tests"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#what-about-planned-contrasts",
    "href": "week10/10_2-factorial_w_post_hocs.html#what-about-planned-contrasts",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "What about planned contrasts?",
    "text": "What about planned contrasts?\nYou need to be careful when running planned contrasts in factorial ANOVA. In general I would recommend only running planned contrasts on a single main effect, or a planned contrast on the effects of one of your factors at a single level of your other (though you still need to proceed with caution here).\nFor example, using the data from the last section, I would only run a planned contrast related to the main effect of Lecture Type, or a contrast of Lecture Type means only in Computer presentation conditions (or Standard presentation). DO NOT, I repeat DO NOT run contrasts that go across levels of your other factors. Well, truthfully, you can do whatever you want, but you may find that your ability to meaningfully interpret your results in such cases is extremely limited.\nWe can run planned contrasts using emmeans() as well. In this case, we need to specify the contrasts.\nFirst we need to obtain the emmeans() of the model including all cells (all factors). Using aov.model from the previous example:\n\nemmeans(aov_model, specs = ~Lecture+Presentation)\n\n Lecture Presentation emmean   SE df lower.CL upper.CL\n Phys    Comp           45.9 2.47 32     40.9     50.9\n Soc     Comp           37.7 2.47 32     32.7     42.8\n Hist    Comp           40.4 2.47 32     35.4     45.4\n Phys    Stand          34.1 2.47 32     29.1     39.1\n Soc     Stand          25.9 2.47 32     20.9     31.0\n Hist    Stand          28.6 2.47 32     23.6     33.6\n\nConfidence level used: 0.95 \n\n\nOK. From here let’s build two custom contrasts. First, let’s do the Lecture contrast on the main effect. In this case let’s assume I want to contrast Phys with the combined other two conditions. Using the output above, I identify which rows contain Phys and I ensure that the summation of those rows is 1. In this case there are two rows, the first and the fourth, and each gets 0.5. My remaining conditions must also equal -1. In this case there are four, so each is -0.25. Following the output above, then my contrast matrix is:\n\nlecture_contrast <- list( \"Phys v. Soc + Hist\" = c(.5,-.25,-.25,.5,-.25,-.25))\n\nFrom here I simply call contrast() with my contrast matrix as an argument. So the entire pipe goes from:\n\nemmeans(aov_model, specs = ~Lecture + Presentation) %>% contrast(lecture_contrast)\n\n contrast           estimate   SE df t.ratio p.value\n Phys v. Soc + Hist     6.83 2.62 32   2.604  0.0138\n\n\nAssuming I wanted to perform a set of orthogonal contrasts:\n\nPhys v. Soc and Hist and\nSoc v Hist\n\n\n# build the contrast matrix\ncontrast_matrix <- list(\"Phys v. Soc + Hist\" = c(.5,-.25,-.25,.5,-.25,-.25),\n                        \"Soc v Hist\" = c(0, -.5, .5, 0, -.5, .5)\n                        )\n\n# run the contrasts\nemmeans(aov_model, specs = ~Lecture + Presentation) %>% contrast(contrast_matrix)\n\n contrast           estimate   SE df t.ratio p.value\n Phys v. Soc + Hist     6.83 2.62 32   2.604  0.0138\n Soc v Hist             2.67 3.03 32   0.880  0.3853\n\n\nIn both cases, my p-values are unadjusted. I can add an adjustment to the contrast() argument like so:\n\n# tukey is most common\nemmeans(aov_model, specs = ~Lecture + Presentation) %>% contrast(contrast_matrix, adjust = \"tukey\")\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\n\n contrast           estimate   SE df t.ratio p.value\n Phys v. Soc + Hist     6.83 2.62 32   2.604  0.0275\n Soc v Hist             2.67 3.03 32   0.880  0.6222\n\nP value adjustment: sidak method for 2 tests \n\n# or bonferroni is most conservative\nemmeans(aov_model, specs = ~Lecture + Presentation) %>% contrast(contrast_matrix, adjust = \"bonferroni\")\n\n contrast           estimate   SE df t.ratio p.value\n Phys v. Soc + Hist     6.83 2.62 32   2.604  0.0277\n Soc v Hist             2.67 3.03 32   0.880  0.7706\n\nP value adjustment: bonferroni method for 2 tests \n\n# or holm is more liberal\nemmeans(aov_model, specs = ~Lecture + Presentation) %>% contrast(contrast_matrix, adjust = \"holm\")\n\n contrast           estimate   SE df t.ratio p.value\n Phys v. Soc + Hist     6.83 2.62 32   2.604  0.0277\n Soc v Hist             2.67 3.03 32   0.880  0.3853\n\nP value adjustment: holm method for 2 tests"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#more-examples-a-3-3-anova",
    "href": "week10/10_2-factorial_w_post_hocs.html#more-examples-a-3-3-anova",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "More examples: a 3 × 3 ANOVA",
    "text": "More examples: a 3 × 3 ANOVA\nIn the previous example we focused in the 2 × 3 scenario for ease. Let’s look at how we might deal with a 3 × 3 example. Let’s use our dataset from the previous walkthrough involving a 3 (Smoking group) by 3 (Task) design. Let’s run another example using this data. Let’s use this as a chance to brush up on creating APA visualizations:\n\ndataset <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Sec13-5.dat\", \n                      \"\\t\", escape_double = FALSE, \n                      trim_ws = TRUE)\n\nRows: 135 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (4): Task, Smkgrp, score, covar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndataset$PartID <- seq_along(dataset$score)\ndataset$Task <- recode_factor(dataset$Task, \n                              \"1\" = \"Pattern Recognition\", \n                              \"2\" = \"Cognitive\", \n                              \"3\" = \"Driving Simulation\") \ndataset$Smkgrp <- recode_factor(dataset$Smkgrp, \n                                \"3\" = \"Nonsmoking\", \n                                \"2\" = \"Delayed\", \n                                \"1\" = \"Active\")\n\ndataset\n\n# A tibble: 135 × 5\n   Task                Smkgrp score covar PartID\n   <fct>               <fct>  <dbl> <dbl>  <int>\n 1 Pattern Recognition Active     9   107      1\n 2 Pattern Recognition Active     8   133      2\n 3 Pattern Recognition Active    12   123      3\n 4 Pattern Recognition Active    10    94      4\n 5 Pattern Recognition Active     7    83      5\n 6 Pattern Recognition Active    10    86      6\n 7 Pattern Recognition Active     9   112      7\n 8 Pattern Recognition Active    11   117      8\n 9 Pattern Recognition Active     8   130      9\n10 Pattern Recognition Active    10   111     10\n# ℹ 125 more rows\n\n\nInteraction plot\n\n# line plot\nggplot(data = dataset, mapping=aes(x=Smkgrp,y=score,group=Task)) +\n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_cl_normal\", \n               position=position_dodge(.5)) + \n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               position=position_dodge(.5), \n               aes(linetype=Task)) +\n  theme_cowplot()\n\n\n\n\nBefore continuing it might be useful to get a feel for whats going on in the dataset. In this case, both the performance on the Cognitive and Driving simulation tasks seems to be impacted by the degree of smoking. However the Pattern recognition task does not appear to be affected.\nAnother way of viewing this is that scores on the Cognitive task tended to be greater than the other two Task conditions. Let’s hold onto our impressions of the data and move on.\nANOVA model\nAs before we can build our ANOVA model and test it against the requisite assumptions:\n\naov_model <- lm(score~Smkgrp+Task,data = dataset)\n\n\naov_model %>% performance::check_model(panel=F)\n\n\naov_model %>% performance::check_normality()\n\nWarning: Non-normality of residuals detected (p < .001).\n\naov_model %>% performance::check_homogeneity()\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.000).\n\n\nAs in the last walkthrough we’ll ignore the issues with our assumption checks\n\naov_model %>% sjstats::anova_stats() %>%\n  dplyr::select(c(\"term\",\"df\",\"statistic\",\"p.value\",\"partial.etasq\"))\n\nterm      |  df | statistic | p.value | partial.etasq\n-----------------------------------------------------\nSmkgrp    |   2 |     7.935 |   0.001 |         0.109\nTask      |   2 |   125.398 |  < .001 |         0.659\nResiduals | 130 |           |         |              \n\n\nHere we have significant main effects for Smkgrp and Task. We’ll need to run seperate post-hoc analyses for each of our observed effects (given that both factors have 3 levels). Before moving on, I would recommend writing out the main points of this table to refer to later in your write up.\n\n\nmain effect for Task, \\(F\\) (2, 130) = 125.40, \\(p\\) < .001, \\(n_p^2\\) = .66.\nmain effect for Smoking Group, \\(F\\) (2, 130) = 7.94, \\(p\\) = .001, \\(n_p^2\\) = .11"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#post-hoc-analysis-1",
    "href": "week10/10_2-factorial_w_post_hocs.html#post-hoc-analysis-1",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "Post-hoc analysis",
    "text": "Post-hoc analysis\nTask\n\nmain_effect_Task <- emmeans(aov_model, ~Task) %>% pairs(adjust=\"tukey\")\n\nmain_effect_Task\n\n contrast                                 estimate   SE  df t.ratio p.value\n Pattern Recognition - Cognitive            -29.13 2.25 130 -12.927  <.0001\n Pattern Recognition - Driving Simulation     3.29 2.25 130   1.459  0.3139\n Cognitive - Driving Simulation              32.42 2.25 130  14.386  <.0001\n\nResults are averaged over the levels of: Smkgrp \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nThe results confirm that overall, Cognitive task performance was greater than the other two conditions. To get the descriptive stats for these contrasts, we can use summarySE, only specifying Task as our grouping viariable:\n\nRmisc::summarySE(data = dataset, measurevar = \"score\", groupvars = \"Task\")\n\n                 Task  N     score        sd        se       ci\n1 Pattern Recognition 45  9.644444  4.513392 0.6728168 1.355973\n2           Cognitive 45 38.777778 18.055330 2.6915297 5.424422\n3  Driving Simulation 45  6.355556  5.701497 0.8499290 1.712919\n\n\nSmkgrp\n\nmain_effect_Smkgrp <- emmeans(aov_model, ~Smkgrp) %>% pairs(adjust=\"tukey\")\n\nmain_effect_Smkgrp\n\n contrast             estimate   SE  df t.ratio p.value\n Nonsmoking - Delayed     3.69 2.25 130   1.637  0.2339\n Nonsmoking - Active      8.93 2.25 130   3.964  0.0004\n Delayed - Active         5.24 2.25 130   2.327  0.0556\n\nResults are averaged over the levels of: Task \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nand to get these descriptive stats, we run summarySE using only Smkgrp as our grouping variable:\n\nRmisc::summarySE(data = dataset, measurevar = \"score\", groupvars = \"Smkgrp\")\n\n      Smkgrp  N    score       sd       se       ci\n1 Nonsmoking 45 22.46667 20.36218 3.035414 6.117475\n2    Delayed 45 18.77778 19.35892 2.885857 5.816063\n3     Active 45 13.53333 14.13024 2.106412 4.245194"
  },
  {
    "objectID": "week10/10_2-factorial_w_post_hocs.html#example-write-up",
    "href": "week10/10_2-factorial_w_post_hocs.html#example-write-up",
    "title": "Factorial ANOVA - Post hoc analysis of Main effects",
    "section": "Example write up",
    "text": "Example write up\nLet’s use this space to provide an example write-up for our factorial ANOVA. To do this I need to refer back to values I generated in my ANOVA table, my post-hoc tests, and my descriptive statistics above.\n\nTo test our hypothesis we ran a 3 (Task) × 3 (Smoking Group) ANOVA on cognitive performance scores. Our ANOVA revealed a significant main effect for Task, \\(F\\) (2, 130) = 125.40, \\(p\\) < .001, \\(n_p^2\\) = .66. Post hoc analysis of Task revealed that participants scored higher in the Cognitive group (\\(M±SE\\) = 38.78 ± 2.69) than the Pattern Recognition (9.64 ± 0.67 ) and Driving Simulator (6.36 ± 0.84) groups (\\(ps\\) < .05).\nOur analysis also revealed a main effect for Smoking Group, \\(F\\) (2, 130) = 7.94, \\(p\\) = .001, \\(n_p^2\\) = .11. Post hoc analysis of Smoking Group revealed participants scored higher in the Nonsmoking group than the Active group (\\(p\\) < .05). No other statistically significant group differences were observed."
  },
  {
    "objectID": "week10/10_2-interactions.html",
    "href": "week10/10_2-interactions.html",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "",
    "text": "This walkthrough is a continuation of our focus on Factorial ANOVA. Here we’re asking the question “what to do if you have an interaction”. As we have discussed when running a factorial ANOVA, your first question should be “do I have an interaction”. If you do have an interaction then you need to examine that interaction in detail. How do we do this? Well, let’s think about what that interaction means. As an example, let’s revisit some of the data (or situations) from the previous walkthrough. We’ll also progressively ramp-up the complexity of our designs.\nThis write-up requires the following packages:"
  },
  {
    "objectID": "week10/10_2-interactions.html#example-1-a-22-anova",
    "href": "week10/10_2-interactions.html#example-1-a-22-anova",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Example 1: a 2×2 ANOVA",
    "text": "Example 1: a 2×2 ANOVA\nTo start let’s look at the first example from our previous walkthrough. To remind ourselves of the particulars, our example ANOVA comes from a study testing the effects of smoking on performance in different types of putatively (perhaps I’m showing my theoretical biases here) information processing tasks.\nThere were 3 types of cognitive tasks:\n\n1 = a pattern recognition task where participants had to locate a target on a screen;\n2 = a cognitive task where participants had to read a passage and recall bits of information from that passage later;\n3 = participants performed a driving simulation.\n\nAdditionally, 3 groups of smokers were recruited\n\n1 = those that were actively smoking prior to and during the experiment;\n2 = those that were smokers, but did not smoke 3 hours prior to the experiment;\n3 = non-smokers.\n\nAs this is a between design, each participant only completed one of the cognitive tasks. For this first example we are going to drop the second levels of each IV (Cognitive and Delayed groups respectively).\nLet’s build the data frame (see previous walkthrough for more detail)\n\ndataset <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Sec13-5.dat\", \"\\t\", escape_double = FALSE, trim_ws = TRUE)\n\nRows: 135 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (4): Task, Smkgrp, score, covar\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndataset$PartID <- seq_along(dataset$score)\ndataset$Task <- recode_factor(dataset$Task, \"1\" = \"Pattern Recognition\", \"2\" = \"Cognitive\", \"3\" = \"Driving Simulation\") \ndataset$Smkgrp <- recode_factor(dataset$Smkgrp, \"3\" = \"Nonsmoking\", \"2\" = \"Delayed\", \"1\" = \"Active\")\n\ndataset_2by2 <- filter(dataset, Smkgrp!=\"Delayed\" & Task!=\"Cognitive\")\n\ndataset_2by2\n\n# A tibble: 60 × 5\n   Task                Smkgrp score covar PartID\n   <fct>               <fct>  <dbl> <dbl>  <int>\n 1 Pattern Recognition Active     9   107      1\n 2 Pattern Recognition Active     8   133      2\n 3 Pattern Recognition Active    12   123      3\n 4 Pattern Recognition Active    10    94      4\n 5 Pattern Recognition Active     7    83      5\n 6 Pattern Recognition Active    10    86      6\n 7 Pattern Recognition Active     9   112      7\n 8 Pattern Recognition Active    11   117      8\n 9 Pattern Recognition Active     8   130      9\n10 Pattern Recognition Active    10   111     10\n# ℹ 50 more rows\n\n\nAnd let’s take a look at our cells to ensure that they have similar numbers:\n\nsummary(dataset_2by2)\n\n                  Task           Smkgrp       score           covar       \n Pattern Recognition:30   Nonsmoking:30   Min.   : 0.00   Min.   : 64.00  \n Cognitive          : 0   Delayed   : 0   1st Qu.: 2.75   1st Qu.: 98.75  \n Driving Simulation :30   Active    :30   Median : 8.00   Median :111.00  \n                                          Mean   : 7.90   Mean   :110.73  \n                                          3rd Qu.:11.00   3rd Qu.:123.00  \n                                          Max.   :22.00   Max.   :168.00  \n     PartID   \n Min.   :  1  \n 1st Qu.: 27  \n Median : 68  \n Mean   : 68  \n 3rd Qu.:109  \n Max.   :135  \n\nez::ezDesign(data = dataset_2by2, \n             x=Task, # what do you want along the x-axis\n             y=Smkgrp, # what do you want along the y-axis\n             row = NULL, # are we doing any sub-divisions by row...\n             col = NULL) # or column\n\n\n\n\nInteraction plots\nInteraction plots take into consideration the influence of each of the IVs on one another—in this case the mean and CI of each smoking group (Active v. Nonsmoking) as a function of Task (Driving Simulation v. Pattern Recognition). For example, a line plot might look like this:\n\n# line plot\nggplot(data = dataset_2by2, mapping=aes(x=Smkgrp,\n                                        y=score,\n                                        group=Task)) + # grouping the data by levels of Task\n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_cl_normal\", \n               position=position_dodge(.5)) + # dodging position so points do not overlap with one another\n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               position=position_dodge(.5), \n               aes(linetype=Task)) + # each level of Task gets its own linetype\n  theme_cowplot()\n\n\n\n\nANOVA model\nAs before we can build our ANOVA model and test it against the requisite assumptions\n\naov_model <- lm(score~Smkgrp*Task,data = dataset_2by2)\n\naov_model$residuals %>% car::qqPlot()\n\n\n\n\n[1] 26 51\n\naov_model %>% car::leveneTest()\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value   Pr(>F)   \ngroup  3     6.1 0.001149 **\n      56                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs in the last walkthrough we’ll ignore the issues with homogeneity. Let’s run our ANOVA:\n\naov_model %>% sjstats::anova_stats()\n\nterm        | df |    sumsq |  meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n----------------------------------------------------------------------------------------------------------------------------------------------\nSmkgrp      |  1 |  248.067 | 248.067 |    11.569 |   0.001 | 0.136 |         0.171 |   0.123 |           0.150 |     0.124 |    0.455 | 0.925\nTask        |  1 |  187.267 | 187.267 |     8.733 |   0.005 | 0.103 |         0.135 |   0.090 |           0.114 |     0.091 |    0.395 | 0.840\nSmkgrp:Task |  1 |  187.267 | 187.267 |     8.733 |   0.005 | 0.103 |         0.135 |   0.090 |           0.114 |     0.091 |    0.395 | 0.840\nResiduals   | 56 | 1200.800 |  21.443 |           |         |       |               |         |                 |           |          |      \n\n\nAdressing the interaction\nThis model yields a Smoking group by task interaction! Looking at our interaction plot above, we shouldn’t have been too surprised by this. We see that for Non smokers, there is minimal difference between the two cognitive tasks, whereas with the smoking group, the scores of the Driving Simulation group were much lower than the Pattern recognition group. Another, equally valid way of interpreting the data is that while Pattern recognition scores were unaffected by smoking condition, Driving simulation scores were drastically decreased for smokers compared to non-smokers. While both interpretations are equally valid in the neutral sense, one may be more interesting to you the researcher (this is where your a priori hypotheses would come into play). Is it more interesting that Non smokers performed equivalently on both types of cognitive tasks while active smokes performed better on the pattern recognition task than the driving task OR is it more interesting that Pattern recognition scores where unaffected by smoking whereas driving simulation scores were?\nI bring this up, as while it may be appropriate to mention both trends, you typically only TEST for one or the other. Remember, there is a cost for every test that your run—you need to adjust for familywise error.\nIn this case I’m going test the second variant, testing how performance on each cognitive task changes by virtue of smoking group. To run a post-hoc ANOVA. This can be accomplished sending our model to emmeans(). Below, the | operator can be understood as “nested within”. So the model is saying take a look at how smoking group scores change on each level of task.\n\naov_model %>% emmeans(spec=~Smkgrp|Task)\n\nTask = Pattern Recognition:\n Smkgrp     emmean  SE df lower.CL upper.CL\n Nonsmoking   9.93 1.2 56   7.5382    12.33\n Active       9.40 1.2 56   7.0049    11.80\n\nTask = Driving Simulation:\n Smkgrp     emmean  SE df lower.CL upper.CL\n Nonsmoking   9.93 1.2 56   7.5382    12.33\n Active       2.33 1.2 56  -0.0618     4.73\n\nConfidence level used: 0.95 \n\n\nFWIW, if it helps, the following is equivalent:\n\naov_model %>% emmeans(spec= \"Smkgrp\", by = \"Task\")\n\nTask = Pattern Recognition:\n Smkgrp     emmean  SE df lower.CL upper.CL\n Nonsmoking   9.93 1.2 56   7.5382    12.33\n Active       9.40 1.2 56   7.0049    11.80\n\nTask = Driving Simulation:\n Smkgrp     emmean  SE df lower.CL upper.CL\n Nonsmoking   9.93 1.2 56   7.5382    12.33\n Active       2.33 1.2 56  -0.0618     4.73\n\nConfidence level used: 0.95 \n\n\nIn either case, Smoking Group only has 2-levels I can send this to a pairwise test:\n\naov_model %>% \n  emmeans(spec= \"Smkgrp\", by = \"Task\") %>%\n  pairs(adjust=\"tukey\")\n\nTask = Pattern Recognition:\n contrast            estimate   SE df t.ratio p.value\n Nonsmoking - Active    0.533 1.69 56   0.315  0.7536\n\nTask = Driving Simulation:\n contrast            estimate   SE df t.ratio p.value\n Nonsmoking - Active    7.600 1.69 56   4.495  <.0001\n\n\nThe output above shows what we expect, that for Pattern recognition groups, scores are indifferent to whether participants are smokers or not, where with the Driving simulation groups, Nonsmokers performed much better."
  },
  {
    "objectID": "week10/10_2-interactions.html#anova",
    "href": "week10/10_2-interactions.html#anova",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "2 × 3 ANOVA",
    "text": "2 × 3 ANOVA\nThings become slightly more complex when on of our factors has 3 or more levels. To see this let’s revisit the second example from the previous walkthrough:\n\nBackground: Given the ease of access for new technologies and increasing enrollment demands, many university are advocating that departments switch over to E-courses, where students view an online, pre-recorded lecture on the course topic in lieu of sitting in a classroom in a live lecture. Given this push, a critical question remains regarding the impact of E-courses on student outcomes. More it may be the case that certain subject content more readily lends itself to E-course presentations than other subjects. To address this question we tested students performance on a test one week after participating in the related lecture. Lectures were either experienced via online (Computer) or in a live classroom (Standard). In addition, the lecture content varied in topic (Physical science, Social science, History)\n\nHere’s the data, where Score represents performance:\n\n\nRows: 36 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Lecture, Presentation\ndbl (2): subID, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPlotting the data and descriptive stats\nHere’s what our results look like. I’ll revisit the particulars on constructing this sort of plot in the next walkthrough. For now, all we are doing is extending the plotting methods that you have been using for the past few weeks. The important addition here is the addition of group = in the first line the ggplot.\nFor example:\n\nggplot(data = dataset, mapping=aes(x=Lecture,\n                                   y=Score,\n                                   group=Presentation))\n\nindicates that we are:\n\nusing the dataset data set\nputting first IV, Lecture, on the x-axis\nputting our dv, Score on the y-axis\nand grouping our data by our other IV, Presentation\n\nThis last bit is important as it makes clear that the resulting mean plots should be of the cell means related to Lecture x Presentation. Note that in the plot below, I am also adjusting the shape of the data points by Presentation (done in stat_summary .\n\nggplot(dataset,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = \"mean_se\",\n               position = position_dodge(.25), # dodge to prevent overlap\n               aes(shape=Presentation)) + # each level of presentation gets a shape\n  stat_summary(geom = \"line\", fun.y=\"mean\", position = position_dodge(.25)) +\n  theme_cowplot() +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\"))\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nAnd now getting the cell means and marginal means. Remember that analysis of the marginal means is what is tested in the main effects. The test for an interaction focuses on the cell means. Here we are using the summarySE function from the Rmisc package. I find it to be more efficient than psych::describeBy() and its useful next week when we do Repeated Measures ANOVA\n\n# cell means:\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = c(\"Presentation\",\"Lecture\"))\n\n  Presentation  Lecture N Score        sd       se        ci\n1     Computer  History 6    38  4.381780 1.788854  4.598397\n2     Computer Physical 6    46  6.985700 2.851900  7.331042\n3     Computer   Social 6    40  4.816638 1.966384  5.054751\n4     Standard  History 6    31 10.315038 4.211096 10.824968\n5     Standard Physical 6    34 11.009087 4.494441 11.553328\n6     Standard   Social 6    12  3.847077 1.570563  4.037260\n\n# marginal means\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = \"Lecture\")\n\n   Lecture  N Score        sd       se       ci\n1  History 12  34.5  8.393721 2.423058 5.333116\n2 Physical 12  40.0 10.795622 3.116428 6.859211\n3   Social 12  26.0 15.201675 4.388345 9.658683\n\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = \"Presentation\")\n\n  Presentation  N    Score        sd       se       ci\n1     Computer 18 41.33333  6.249706 1.473070 3.107906\n2     Standard 18 25.66667 13.105903 3.089091 6.517412\n\n\nthe Omnibus ANOVA (and assumption tests)\nThe very first ANOVA model that we build crosses all of our independent variables. This is the omnibus ANOVA. Let’s build this model and run our assumption checks\n\nomnibus_aov <- lm(Score~Lecture*Presentation, dataset)\n\n# check the normality assumption of the residuals:\nomnibus_aov$residuals %>% car::qqPlot()\n\n\n\n\n[1] 10 31\n\nomnibus_aov %>% car::leveneTest()\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  5  1.6132 0.1868\n      30               \n\n\nGood to go, let’s check our results:\n\nsjstats::anova_stats(omnibus_aov)[1:8]\n\nterm                 | df | sumsq |   meansq | statistic | p.value | etasq | partial.etasq\n------------------------------------------------------------------------------------------\nLecture              |  2 |  1194 |  597.000 |    10.737 |  < .001 | 0.206 |         0.417\nPresentation         |  1 |  2209 | 2209.000 |    39.730 |  < .001 | 0.381 |         0.570\nLecture:Presentation |  2 |   722 |  361.000 |     6.493 |   0.005 | 0.125 |         0.302\nResiduals            | 30 |  1668 |   55.600 |           |         |       |              \n\n\nLooking at the ANOVA: Our assumptions tests check out, and our ANOVA reveals two main effects and in interaction. Looking back at the plot (always, always plot before you think about doing any sort of follow-ups!!) it is fairly apparent what is happening—when moving from one lecture to the next, we see a much more dramatic decrease in score for the Social group in the Standard presentation group compared to the Computer presentation. That is, moving from left to right the pattern of change is different for the Standard group, compared to the Computer group. This is what our eyeball test is telling us—we need to confirm it with some stats! There are two ways to address this interaction, each involves sub-setting the data for further analysis.\nAs mentioned above, when you have an interaction, you proceed by testing for differences between means for one condition, on each individual level of the other. For example, we can test for and effect of Lecture Type when the Presentation is Computer, and effect of Lecture Type when the Presentation is Standard. In this case you would run two separate simple effects ANOVAs, each taking a look at changes for each line in the plot above.\n–OR–\nYou could check for difference between Presentations on each Lecture type. Here you would be comparing Computer v Standard in each of the Lecture conditions. This would involve running three ANOVAs each checking for the Presentation differences (circle v. triangle) present at History, Physical, and Social.\nWhich you choose, ultimately depends on which narrative you are trying to convey in your data. Here it may make sense to do the former. That is eyeballing the data it looks like the means in the Computer presentation level are not as different from one another as the Standard presentation."
  },
  {
    "objectID": "week10/10_2-interactions.html#running-the-simple-effects-anova-in-6-steps",
    "href": "week10/10_2-interactions.html#running-the-simple-effects-anova-in-6-steps",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Running the simple effects ANOVA in 6 steps:",
    "text": "Running the simple effects ANOVA in 6 steps:\nGiven that we have elected to take a look at Lecture on each level of Presentation, we would need to run 2 simple effects ANOVAs. This is because breaking the omnibus in this way still leaves in each subsequent analysis a comparison of the 3 levels of Lecture. Basically we are running 2 separate One-way ANOVAs:\n\nthe first looks at Scores~Lecture when Presentation = Computer and\nthe second looks at Scores~Lecture when Presentation = Standard\n\nThere is, however, one major caveat. When you run the follow-up ANOVA you need to use the error terms from your omnibus ANOVA. That is your simple effects ANOVA calls for the omnibus ANOVA errors: Sum of Squares, Mean Square Error, and denominator degrees of freedom.\nWhat this means is that if you were to actually run this data as two distinct One-Way ANOVAs, the F-value (and subsequent p-values) that you get would be WRONG. For example simply running a filter and then ANOVA like this will not work:\n\n# this is wrong... don't do this!!!\nlm(Score~Lecture, dataset %>% filter(Presentation==\"Computer\")) %>%\n  sjstats::anova_stats() %>% dplyr::select(1:8) %>% pander\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n\n \nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\netasq\n\n\n\nLecture\nLecture\n2\n208\n104\n3.421\n0.06\n0.313\n\n\n…2\nResiduals\n15\n456\n30.4\nNA\nNA\nNA\n\n\n\n\n\n\n\n\n\n \npartial.etasq\n\n\n\nLecture\n0.313\n\n\n…2\nNA\n\n\n\n\n\nA quick glance at the table above reveals the error. You’ll notice that the denominator df are 15 where in the omnibus ANOVA they were 30. Fixing this isn’t as simple as adjusting the denominator df and looking it up on the F-table. This involves a series of calculations that results in a different F-ratio as well. For the sake of clarity I’m going to show you how to do this “by hand” and then show you how you’ll never need to do it “by hand”\nThere are several steps that need to be run for each simple effects ANOVA:\nstep 1: get the omnibus ANOVA:\nAssuming you haven’t already we need to run the omnibus ANOVA. Let’s get this again\n\nomnibus_aov <- lm(Score~Lecture*Presentation, dataset)\n\nstep 2: get the MSError, Error df, and Error SS from omnibus ANOVA\nWe can pull these values directly from the sjstats::anova_stats() output. It easier to just save this output to an object first. We can then check its attributes()\n\nomnibus_values <- sjstats::anova_stats(omnibus_aov)\nattributes(omnibus_values)\n\n$names\n [1] \"term\"            \"df\"              \"sumsq\"           \"meansq\"         \n [5] \"statistic\"       \"p.value\"         \"etasq\"           \"partial.etasq\"  \n [9] \"omegasq\"         \"partial.omegasq\" \"epsilonsq\"       \"cohens.f\"       \n[13] \"power\"          \n\n$class\n[1] \"sj_anova_stat\" \"data.frame\"   \n\n$row.names\n[1] \"Lecture\"              \"Presentation\"         \"Lecture:Presentation\"\n[4] \"...4\"                \n\n\nIn the above list, we are interested in sumsq and df. We need to index each by number. In this case residuals are on the 4th line:\n\nomnibus_df <- omnibus_values$df[4]\nomnibus_mse <- omnibus_values$meansq[4]\nomnibus_ss_error <- omnibus_values$sumsq[4]\n\nstep 3: subset your data accordingly\nIn order to do this we will need to subset the data. For example I am interested in running my follow-ups on Computer data and Standard data separately, so my first move is to perform this subset:\n\ncomputer_data <- filter(dataset, Presentation==\"Computer\")\nstandard_data <- filter(dataset, Presentation==\"Standard\")\n\n(FWIW you could also do the subsetting in the lm() call)\nstep 4: run your One-way simple effects ANOVA(s)\nHere I’m focusing on the computer_data for my example. You can return to the standard_data later.\n\ncomputer_aov_values <- lm(Score~Lecture, dataset %>% filter(Presentation==\"Computer\")) %>%\n  sjstats::anova_stats()\ncomputer_aov_values\n\nterm      | df | sumsq |  meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n-----------------------------------------------------------------------------------------------------------------------------------------\nLecture   |  2 |   208 | 104.000 |     3.421 |   0.060 | 0.313 |         0.313 |   0.212 |           0.212 |     0.222 |    0.675 | 0.635\nResiduals | 15 |   456 |  30.400 |           |         |       |               |         |                 |           |          |      \n\n\nstep 5: get the treatment MS, df, SS, and F-value from your simple ANOVA\nAs before, this can be done by calling attributes from our simple ANOVA, computer_aov. We need to grab the following values related to the treatment:\n\n# treatment df\nsimple_df <- computer_aov_values$df[1]\n# treatment MS\nsimple_ms <- computer_aov_values$meansq[1]\n# and the simple treatment SS:\nsimple_ss <- computer_aov_values$sumsq[1]\n\nstep 6: make our corrections\nAs I noted above the F-value, p-value, and effect size (pes, \\(\\eta_p^2\\)) that you originally obtained in the simple effects computer_aov are not correct. We need to make the appropriate corrections. This can be done my hand, using the values we’ve extracted and calculated above:\n\n# calculate F using simple treatment  MS and omnibus MSE\ncorrected_f <- simple_ms/omnibus_mse\n\n# the pf function calculates the cummulative p.value using the corrected_f and appropriate degrees of freedom. Since its cumulative we subtract this result from 1:\n\ncorrected_p <- (1-pf(corrected_f,df1 = simple_df,df2 = omnibus_df))\n\n# calculate the pes by using simple treatment SS and omnibus MSE:\ncorrected_pes <- (simple_ss/(simple_ss+omnibus_ss_error))\n\nCongrats!! You have made the appropriate corrections! Taking a look at your corrected result it appears that we should accept the null hypothesis of no difference in means on the computer data. As with posthoc comparisons, effect sizes for simple effects ANOVA are somewhat debatable, but this might be the most appropriate way to do this.\n\ntibble(corrected_f, corrected_p, corrected_pes)\n\n# A tibble: 1 × 3\n  corrected_f corrected_p corrected_pes\n        <dbl>       <dbl>         <dbl>\n1        1.87       0.172         0.111"
  },
  {
    "objectID": "week10/10_2-interactions.html#the-emmeans-way",
    "href": "week10/10_2-interactions.html#the-emmeans-way",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "the emmeans() way",
    "text": "the emmeans() way\nthe simple effects ANOVA\nIn years past, I would have shown you how to create your own function to do this, but instead we can also use emmeans() to conduct simple effects follow-ups. In this case we need to tell emmeans() how to parse our omnibus.aov model. Here we are telling it to look at the effects of Lecture on each level of Presentation.\n\nsimple_effects_by_presentation <- emmeans(omnibus_aov, ~Lecture|Presentation)\n\nWe can then pipe our simple effects emmeans into this call to run BOTH simple effects ANOVA\n\nsimple_effects_by_presentation %>% \n  pairs() %>% \n  test(joint=T)\n\n Presentation df1 df2 F.ratio p.value note\n Computer       2  30   1.871  0.1716  d  \n Standard       2  30  15.360  <.0001  d  \n\nd: df1 reduced due to linear dependence \n\n\nBased on this output we have a simple effect for standard but not computer.\neffects size (partial eta sq) for the ANOVA\nInstead of calculating partial eta squared for the simple effects ANOVA by hand, we can use the F_to_eta2 function from the effectsize package. FWIW the effectsize package has a host of other functions for calculating effect sizes. Here, F_to_eta2 takes three arguments, the f value of the (simple effects) ANOVA, and its numerator (treatment) and denominator (error) dfs. Looking at the output from the last section, these values are f = 15.36, df = 2, df_error = 30:\n\npacman::p_load(effectsize)\nF_to_eta2(f = 15.36, df = 2, df_error = 30)\n\nEta2 (partial) |       95% CI\n-----------------------------\n0.51           | [0.27, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\npost-hoc analyses on the simple effects ANOVA\nGiven that we have a simple effect for standard, we need to run pairwise posthoc analyses. Given that our joint test suggested no simple effect on Computer, we can just ignore that part of the output.\n\nsimple_effects_by_presentation %>% pairs()\n\nPresentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical       -8 4.31 30  -1.858  0.1684\n History - Social         -2 4.31 30  -0.465  0.8883\n Physical - Social         6 4.31 30   1.394  0.3568\n\nPresentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical       -3 4.31 30  -0.697  0.7671\n History - Social         19 4.31 30   4.413  0.0003\n Physical - Social        22 4.31 30   5.110  <.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nGiven our latter result above we see that in the Standard presentation, scores based on Social lectures were significantly less than the other two.\nIf we wanted to calculate any effect sizes for the parwise comparisons (corrected Cohen’s D) we could use the function we learned last week. Again, ignore Computer as it was non-significant.\n\neff_size(object = simple_effects_by_presentation,\n         sigma = sigma(omnibus_aov),\n         edf = df.residual(omnibus_aov))\n\nPresentation = Computer:\n contrast           effect.size    SE df lower.CL upper.CL\n History - Physical      -1.073 0.594 30   -2.285    0.140\n History - Social        -0.268 0.578 30   -1.449    0.913\n Physical - Social        0.805 0.587 30   -0.393    2.003\n\nPresentation = Standard:\n contrast           effect.size    SE df lower.CL upper.CL\n History - Physical      -0.402 0.580 30   -1.586    0.782\n History - Social         2.548 0.664 30    1.191    3.905\n Physical - Social        2.950 0.692 30    1.538    4.363\n\nsigma used for effect sizes: 7.457 \nConfidence level used: 0.95"
  },
  {
    "objectID": "week10/10_2-interactions.html#interpreting-these-results",
    "href": "week10/10_2-interactions.html#interpreting-these-results",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Interpreting these results:",
    "text": "Interpreting these results:\nGiven everything above, there are several things that this data are telling us:\n\n\nMain effect for computer: on average people tended to perform better in the Computer presentation\n\nMain effect for Lecture: this main effect is not as clear. Overall, people may have performed worst on the Social lecture content, it’s quite apparent that the presence of this effect is muddled by presentation type. This is what the presence of our interaction is telling us.\n\nSimple effect of lecture type via computer: No differences in means suggests that people perform equally well on all lecture content types when administered via computer\n\nSimple effect of lecture type via standard lecture: significant simple effect and subsequent posthocs demonstrate that while students perform equally as well on Physical Science and History content via standard lectures, they perform worse on tests of Social science content.\n\nGiven this pattern of results two major conclusions become apparent:\n\nFirst, students overall perform better via Computer. This was the case for all three lecture types. True, how much better varies by condition, but in all cases scores were higher.\nSecond, while performance via Computer was indifferent to Lecture type (all lecture content scores were nearly equal) there was an attrition for Social science content when provided via standard lecture.\n\nFrom this one might conclude that administering content via E-course is better for student outcomes, especially if the subject content is in the Social Sciences! Also, I think that one of the lessons of 2020 is that this result is demonstrably FALSE ;)."
  },
  {
    "objectID": "week10/10_2-interactions.html#example-write-up",
    "href": "week10/10_2-interactions.html#example-write-up",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Example write-up:",
    "text": "Example write-up:\n\nTo test for the effects of Presentation style (Standard, Computer) and Lecture Type (Physics, History, Social) we ran a 2 × 3 factorial ANOVA. This ANOVA revealed main effects for both Presentation style, \\(F(1,30)=39.73, p<.001, \\eta_p^2=.57\\), and Lecture type, \\(F(2,30)=10.74, p<.001, \\eta_p^2=.42\\).\nAs shown in Figure 1, these effects we qualified by a Presentation style × Lecture type interaction, \\(F(2,30)=6.49, p=.005, \\eta_p^2=.30\\). Differences in Lecture type were only observed when material was presented in the Standard presentation, \\(F(2,30)=15.36, p<.001, \\eta_p^2=.51\\), where scores from the Social lecture were significantly different from the remaining two (Tukey HSD, p< .05). No differences were observed when the material was presented via computer (p>.05). Overall, participants performed better when the material was presented via computer (M±SD: 41.33 ± 6.25) compared to standard presentations (25.67 ± 13.11).\n\nOne thing you may notice is that I still stressed the main effect. This is to stress to the reader that presentation type did make a difference."
  },
  {
    "objectID": "week10/10_2-interactions.html#performing-this-in-spss-video",
    "href": "week10/10_2-interactions.html#performing-this-in-spss-video",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Performing this in SPSS (video)",
    "text": "Performing this in SPSS (video)\nAs I mentioned in class, given that we are doing our analyses via programming, we have the luxury of have a function in emmeans()that can make all of our simple effects adjustments for us. If you are using the GUI method in SPSS, you don’t have this luxury (although you can certainly create a similar function in SPSS!). Fear not, here I walk you through how to do this in SPSS, assuming you have Microsoft Excel. Check out this vid on youtube: https://youtu.be/0Y-dVv-UCz4."
  },
  {
    "objectID": "week10/10_4-higher_order_anova.html",
    "href": "week10/10_4-higher_order_anova.html",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "",
    "text": "This walk-through is a continuation of our previous work with factorial ANOVA. If you haven’t already, please check the factorial ANOVA and Interaction vignettes. In truth, nothing terribly new is being introduced here; we are just ramping up the complexity of our ANOVA models. Whereas before we considered a scenario with just 2 factors, here we will consider a 3 factor ANOVA. For all practical purposes you typically do not want to go higher than a 3 or 4 factor ANOVA, simply because of the exponential increase in complexity. For example, consider below where each letter is an IV and the resulting tests in the full factorial omnibus ANOVA:\nIncreasing the number of factors not only increases the practical difficulty of analysis, but more importantly, makes it more difficult to interpret your results. The primary culprit here is the potential presence of multiple interactions.\nWhen dealing with interactions in a higher order factorial design you always start off with the highest order interaction. For example in the 3 factor case, if you have a 3-way interaction, that supersedes any other effects and interactions, and must be dealt with first. If there is no three-way interaction, then you can co about the business of addressing any two way interactions that are present."
  },
  {
    "objectID": "week10/10_4-higher_order_anova.html#packages-and-data",
    "href": "week10/10_4-higher_order_anova.html#packages-and-data",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "Packages and data",
    "text": "Packages and data\nLet’s load in our necessary packages, scripts and some data and try some examples. This write-up requires the following packages:\n\n# required packages:\npacman::p_load(tidyverse, \n               cowplot, \n               emmeans)\n\nAnd now let’s re-acquaint ourselves with our familar example dataset, but with one new twist…\n\nBackground: Given the ease of access for new technologies and increasing enrollment demands, many grade schools are advocating that teachers switch over to E-courses, where students view an online, pre-recorded lecture on the course topic in lieu of sitting in a classroom in a live lecture. Given this push, a critical question remains regarding the impact of E-courses on primary school student outcomes. More it may be the case that certain subject content more readily lends itself to E-course presentations than other subjects. To address this question we tested students performance on a test one week after listening to the related lecture. Lectures were either experienced via online (Computer) or in a live classroom (Standard). In addition, the lecture content varied in topic (Physical science, Social science, History). Finally, to assess whether age had an impact on expected outcomes we assessed students in 5th and 8th grades.\n\nLooking at the above we have a 2 (Grade: 5th, 8th) × 2 (Presentation: Computer, Standard) × 3 (Lecture: Physical, Social, History) design. Our omnibus ANOVA therefore will test for the following effects:\n\nMain Effects: Grade, Presentation, Lecture\n2-way interactions: Grade × Presentation, Grade × Lecture, Lecture × Presentation\n3-way interaction: Grade × Presentation × Lecture"
  },
  {
    "objectID": "week10/10_4-higher_order_anova.html#example-1-no-three-way-interaction-single-two-way-interaction",
    "href": "week10/10_4-higher_order_anova.html#example-1-no-three-way-interaction-single-two-way-interaction",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 1: no three-way interaction, single two way interaction",
    "text": "EXAMPLE 1: no three-way interaction, single two way interaction\nLet’s load in this data:\n\nhigherEx1 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx1.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nshow(higherEx1)\n\n# A tibble: 72 × 5\n   Subject Grade Lecture  Presentation Score\n     <dbl> <chr> <chr>    <chr>        <dbl>\n 1       1 5th   Physical Computer        53\n 2       2 5th   Physical Computer        49\n 3       3 5th   Physical Computer        47\n 4       4 5th   Physical Computer        42\n 5       5 5th   Physical Computer        51\n 6       6 5th   Physical Computer        34\n 7       7 5th   Physical Standard        44\n 8       8 5th   Physical Standard        48\n 9       9 5th   Physical Standard        35\n10      10 5th   Physical Standard        18\n# ℹ 62 more rows\n\n\nIt’s already in long format, but I should tell R that Grade, Lecture, and Presentation are factors:\n\nhigherEx1$Grade <- factor(higherEx1$Grade)\nhigherEx1$Lecture <- factor(higherEx1$Lecture)\nhigherEx1$Presentation <- factor(higherEx1$Presentation)\n\nFirst plot: 3 way interaction plot\nOne thing you may notice is since we have a more complex ANOVA, we have a more complex design with three factors we also have to construct a more complex plot. Whereas in the 2 factor case we could place one factor on the x-axis and group the other factor by line or shape or color; in the three factor case things become slightly more tricky.\nOne thing to consider is the logic of what we are doing with our plots. When we have two factors, say A & B, we are distinguishing between each level of B (by lines, shapes, colors) at each level of A (on the x-axis). In the 3 factor case where we have A,B, & C, we are distinguishing the B×C interaction (through the combination of shapes, lines, colors) on each level of A.\nIn the following plot, let’s place Lecture type along the x-axis. From here, we can create 2 groups of lines (each with 2 levels) representing the Grade × Presentation interaction. We note this by specifying the interaction in group of our baseline ggplot call:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade)))\n\nFrom here, we can proceed as before. Note, however, depending on the complexity of your plot you may also need to specify the interaction in each stat_summary::aes() as necessary.\nBelow I am changing the shape by Presentation and the linetype by Grade. The entire call, including the line above is:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  # adjusting the legend\n  theme(\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.1,.25))\n\n\n\n\nOK, not exactly the best plot. Let’s see if we can create some more space to work with by forcing the y-axis to go to 0, instead of cutting off at 10. There’s also a trick that we can use to stack our legend keys horizontally, rather than vertically\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  \n  # new additions / changes\n  coord_cartesian(ylim=c(0,50)) + \n  \n  # direction to stack legend keys\n  theme(legend.direction = \"horizontal\", \n        legend.position = c(.1,.25))\n\n\n\n\nalternatively, we could also just stack the legend boxes side by side:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  \n  # new additions / changes\n  coord_cartesian(ylim=c(0,50)) + \n  \n  # direction to stack legend boxes instead of keys\n  theme(legend.box = \"horizontal\", \n        legend.position = c(.1,.25))\n\n\n\n\nNOTE: For what its work, we could also obviate the need for this complex of a plot, and just facet_wrap() by our third factor. For practice try taking the code above and faceting by ~Grade.\nrunning the ANOVA:\nFrom here we run the omnibus as usual:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx1)\n\nomnibus_aov %>% sjstats::anova_stats()\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\nLecture                    |  2 | 2330.361 | 1165.181 |    21.333 |  < .001 | 0.204 |         0.416 |   0.193 |           0.361 |     0.194 |    0.843 | 1.000\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.382 |         0.572 |   0.376 |           0.523 |     0.377 |    1.155 | 1.000\nGrade                      |  1 |    0.347 |    0.347 |     0.006 |   0.937 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.010 | 0.051\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.128 |         0.308 |   0.118 |           0.256 |     0.118 |    0.667 | 0.998\nLecture:Grade              |  2 |    0.361 |    0.181 |     0.003 |   0.997 | 0.000 |         0.000 |  -0.009 |          -0.028 |    -0.010 |    0.010 | 0.050\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.006 | 0.050\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000 |  -0.009 |          -0.029 |    -0.010 |    0.005 | 0.050\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |               |         |                 |           |          |      \n\n\nIn this case we only have Main effects for Lecture and Presentation, and a Lecture × Presentation interaction. Given this we can disregard Grade as its not contributing to any effects.\nReplotting the 2-way interaction\nIn some cases it is advisable to re-plot the data factoring out Grade by removing Grade from baseline group= as well as any summary_stat::aes(), (essentially treating this if it was a 2 factorial design like last week). For the sake of your sanity, and your readers’ sanity) I would also suggest being consistent with how you present your conditions. For example, in the original plot, Presentation was differentiated by shape. To be consistent, we need to do the same here).\n(You’ll note in the example below I’m also customing font size and weight ourely for personal aesthetics):\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(shape=Presentation)) + theme_cowplot() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,50)) + \n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\nWarning in stat_summary(geom = \"line\", fun = \"mean\", position =\nposition_dodge(0.15), : Ignoring unknown aesthetics: shape\n\n\n\n\n\nFrom here I would deal with the follow-ups as we did in our 2×3 example from the last write-up: Run the simple effects and any necessary posthocs, being sure to correct using the error terms from the omnibus ANOVA."
  },
  {
    "objectID": "week10/10_4-higher_order_anova.html#example-2-no-three-way-interaction-multiple-main-effects-multiple-2-way-interactions",
    "href": "week10/10_4-higher_order_anova.html#example-2-no-three-way-interaction-multiple-main-effects-multiple-2-way-interactions",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 2: No three-way interaction, multiple main effects, multiple 2 way interactions:",
    "text": "EXAMPLE 2: No three-way interaction, multiple main effects, multiple 2 way interactions:\nLet’s load in a data set that is a little more complicated:\n\nhigherEx2 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx2.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nplotting the data\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nLooking at this plot its quite apparent that the pattern of results is different from Example 1. Perhaps most simply, there is a general shared pattern of effects for each of the shapes (Presentation) with the exception of the 8th Grade-Computer condition. For the remainder there is a dip for Social lectures, but in this one condition Social actually increases. Let’s run our ANOVA.\nrunning the omnibus ANOVA:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx2)\n\nomnibus_aov %>% sjstats::anova_stats()\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\nLecture                    |  2 |  774.361 |  387.181 |     7.089 |   0.002 | 0.072 |         0.191 |   0.061 |           0.145 |     0.062 |    0.486 | 0.931\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.405 |         0.572 |   0.398 |           0.523 |     0.400 |    1.155 | 1.000\nGrade                      |  1 |  308.347 |  308.347 |     5.645 |   0.021 | 0.029 |         0.086 |   0.023 |           0.061 |     0.024 |    0.307 | 0.661\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.135 |         0.308 |   0.124 |           0.256 |     0.125 |    0.667 | 0.998\nLecture:Grade              |  2 |  604.361 |  302.181 |     5.532 |   0.006 | 0.056 |         0.156 |   0.046 |           0.112 |     0.046 |    0.429 | 0.854\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.006 | 0.050\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000 |  -0.010 |          -0.029 |    -0.010 |    0.005 | 0.050\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |               |         |                 |           |          |      \n\n\nOur ANOVA reveals an abundance of results. There are main effects for each of our IVs. In addition there are two interaction effects: Lecture:Presentation and Lecture:Grade. Unless there is a strong theoretical reason not to (which I see none) we will need to examine each of these interactions in further detail.\ntesting the Lecture:Presentation interaction:\n2-way interaction plot\nWe can begin by recreating our interaction plot, this time only focusing on the IVs that are of interest (those that are interacting). In this first case, they are Lecture and Presentation.\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_cl_normal\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(shape=Presentation)) + theme_cowplot() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\nWarning in stat_summary(geom = \"line\", fun = \"mean\", position =\nposition_dodge(0.15), : Ignoring unknown aesthetics: shape\n\n\n\n\n\nsimple effect ANOVAs:\nProvided what we see on this plot, it may make sense to first run a simple effects ANOVA for each Presentation and then run the appropriate follow-ups. I say this because the more obvious, and potentially easily interpret-able effects occur moving across the line series (i.e., lines trend up or down).\nWhen testing for simple effects of Lecture on each Presentation type, we still need to include Grade in our analysis—this is to account for Grade’s contribution to our original model. Essentially we conduct a test for Lecture, Grade, and the Lecture by Grade interaction on each level of Presentation type. Using the template from the previous walkthroughs, this can be accomplished by simply telling R to run joint_tests separating the original model by Presentation.\nUsing emmeans::joint_tests():\n\nemmeans::joint_tests(omnibus_aov, by = \"Presentation\")\n\nPresentation = Computer:\n model term    df1 df2 F.ratio p.value\n Lecture         2  60   4.739  0.0123\n Grade           1  60   2.710  0.1049\n Lecture:Grade   2  60   2.823  0.0673\n\nPresentation = Standard:\n model term    df1 df2 F.ratio p.value\n Lecture         2  60  15.715  <.0001\n Grade           1  60   2.937  0.0917\n Lecture:Grade   2  60   2.710  0.0747\n\n\nBoth simple effects ANOVA of Lecture within Presentation were significant, suggesting that we should perform a post-hoc analyses of each:\n\nemmeans(omnibus_aov, by = \"Presentation\", specs=\"Lecture\") %>%\n  pairs(adjust=\"tukey\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\nPresentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -7.92 3.02 60  -2.624  0.0292\n History - Social      -8.17 3.02 60  -2.707  0.0237\n Physical - Social     -0.25 3.02 60  -0.083  0.9962\n\nPresentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 3.02 60  -0.994  0.5833\n History - Social      12.92 3.02 60   4.281  0.0002\n Physical - Social     15.92 3.02 60   5.275  <.0001\n\nResults are averaged over the levels of: Grade \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nThe results of the Tukey post-hoc suggests that History scores are significantly less than the other two groups when considering only the Computer presentation. For the standard presentation, scores in the History and Physical lecture were greater than the Social lecture.\ntesting the Lecture:Grade interaction:\nNow we do the same for the Lecture:Grade interaction. This time removing Presentation from our consideration.\n2-way interaction plot\nYou’ll notice that in this interaction plot, and the plot above, I am using the shape/linetype conventions that I established in my original plot. This will make things much easier if I wind up comparing these plots to my 3-way plot. I know I’ve said this before, but ONE MORE TIME WITH FEELING!\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=Grade)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nsimple effect ANOVAs:\nProvided what we see on this plot, it may make the best sense to examine the pairwise differences in each Grade group by Lecture. Whereas in the previous interaction, the compelling changes occurred across lines, here what is more compelling is the presence/absence of gaps between the lines. In particular, while there are practically no differences due to Grade in the History or Physical Lectures, there is a larger gap in the Social condition.\nRunning these simple effects ANOVAs using emmeans:joint_tests(). Keep in mind, since we are parsing the Lecture:Grade interaction, be should only take a look at the effects of Grade on each of our Presentation levels. We can ignore the other output.\n\nemmeans::joint_tests(omnibus_aov,by = \"Lecture\") \n\nLecture = History:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60   5.255  0.0254\n Grade                1  60   0.001  0.9781\n Presentation:Grade   1  60   0.001  0.9781\n\nLecture = Physical:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60  15.382  0.0002\n Grade                1  60   0.000  1.0000\n Presentation:Grade   1  60   0.003  0.9561\n\nLecture = Social:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60  86.123  <.0001\n Grade                1  60  16.710  0.0001\n Presentation:Grade   1  60   0.000  1.0000\n\n\nAs anticipated from looking at the plot, there was a significant difference between our Grades in the Social group, but not the other two. Since there are only two levels of Grade we don’t deen to run any other post hocs (the \\(F\\) test is our comparison between means).\nMain takeaways / write-up\nIt’s typically best to go back and look at all of your plots.\n\nthe main effect for Presentation is meaningful: Regardless of what plays out on the other factors, students tended to perform better in the computer presentation. Best to report that.\n\nthe Lecture:Presentation interaction resulted from the following:\n\nin the Computer presentations scores were lowest in the History lecture (indifferent in other two)\nin the Standard presentations scores were lowest in the Social lecture (indifferent in the other two)\n\n\nthe Lecture:Grade interaction resulted from the 5th graders performing worse than the eight graders in Social lectures; while performance was not different in the other two lectures.\n\nWith this in mind, an example write-up:\n\nOur results revealed main effects for each of our factors, in addition to Lecture × Presentation \\([F(2,60)=13.37, p<.001, \\eta_p^2=.31]\\) and Lecture × Grade interactions \\([F(2,60)=5.53, p=.006, \\eta_p^2=.16]\\).\n\n\nConsidering the former interaction, students presented material via computer format tended to perform poorest from the History Lecture, compared to Physical and Social (Tukey HSD, p<.05). However, when material was presented in the standard format, students performed poorest in the Social condition (p<.05), while the other two were not different.\n\n\nConsidering the latter interaction, a detailed analysis of performance as a function of lecture revaled that 8th Graders performed better than their 5th grade counterparts only in the Social lecture, \\(F(1,60) = 16.71, p < .001, \\eta_p^2=0.21\\).\n\n\nIn all conditions, students performed better when presented the material via computer compared to the standard presentation, \\([F(2,60)=7.09, p=.002, \\eta_p^2=.19]\\) (see Figure 1)."
  },
  {
    "objectID": "week10/10_4-higher_order_anova.html#example-3-omg-multiple-two-way-interactions-and-a-nasty-three-way",
    "href": "week10/10_4-higher_order_anova.html#example-3-omg-multiple-two-way-interactions-and-a-nasty-three-way",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 3: OMG, multiple two way interactions and a nasty three-way!!!",
    "text": "EXAMPLE 3: OMG, multiple two way interactions and a nasty three-way!!!\nFinally let’s take a look at some data that is all over the place:\n\nhigherEx3 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx3.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPlotting:\n\nggplot(higherEx3,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.5), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.5), aes(linetype=Grade)) + \n  theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.15)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,50)) + \n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nrunning the ANOVA:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx1)\n\nomnibus_aov %>% sjstats::anova_stats()\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\nLecture                    |  2 | 2330.361 | 1165.181 |    21.333 |  < .001 | 0.204 |         0.416 |   0.193 |           0.361 |     0.194 |    0.843 | 1.000\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.382 |         0.572 |   0.376 |           0.523 |     0.377 |    1.155 | 1.000\nGrade                      |  1 |    0.347 |    0.347 |     0.006 |   0.937 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.010 | 0.051\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.128 |         0.308 |   0.118 |           0.256 |     0.118 |    0.667 | 0.998\nLecture:Grade              |  2 |    0.361 |    0.181 |     0.003 |   0.997 | 0.000 |         0.000 |  -0.009 |          -0.028 |    -0.010 |    0.010 | 0.050\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.006 | 0.050\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000 |  -0.009 |          -0.029 |    -0.010 |    0.005 | 0.050\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |               |         |                 |           |          |      \n\n\nO.M.F.G., everything is significant!!! What to do!!!\nRemember, the first thing that we do is tackle the highest-order interaction. In this case we should tease-out the three-way. Again, we should look to our plot to help guide us in what to do. Looking at the plot it appears that different things are happening by Grade. The Presentation:Lecture lines tend to stay parallel for the 5th graders, but not as much for the 8th graders. At the same time the gaps between the two lines are different by grade. So, my advice would be to attack the 3-way interaction by looking at the individual Lecture:Presentation interactions on each Grade.\nFifth Graders, Lecture:Presentation interaction.\n\nemmeans::joint_tests(omnibus_aov, by=\"Grade\") \n\nGrade = 5th:\n model term           df1 df2 F.ratio p.value\n Lecture                2  60  10.930  0.0001\n Presentation           1  60  40.443  <.0001\n Lecture:Presentation   2  60   6.609  0.0025\n\nGrade = 8th:\n model term           df1 df2 F.ratio p.value\n Lecture                2  60  10.406  0.0001\n Presentation           1  60  39.588  <.0001\n Lecture:Presentation   2  60   6.757  0.0023\n\n\nYou’ll note that our results include simple effects for Lecture and Presentation at each Grade for as their interaction. That said, there are no effects when looking at the 5th graders. However, the detailed Lecture:Presentation analysis for the 8th graders revealed both main effects and their interaction. We need to follow-up on this interaction in the 8th-grade data. In this case we would look at the effect of Lecture on each level of Presentation for the eighth graders.\nTo do this we first subset the data further, by both Grade and Presentation:\n\nemmeans::joint_tests(omnibus_aov, by=c(\"Grade\", \"Presentation\")) \n\nGrade = 5th, Presentation = Computer:\n model term df1 df2 F.ratio p.value\n Lecture      2  60   1.904  0.1579\n\nGrade = 8th, Presentation = Computer:\n model term df1 df2 F.ratio p.value\n Lecture      2  60   1.777  0.1779\n\nGrade = 5th, Presentation = Standard:\n model term df1 df2 F.ratio p.value\n Lecture      2  60  15.635  <.0001\n\nGrade = 8th, Presentation = Standard:\n model term df1 df2 F.ratio p.value\n Lecture      2  60  15.386  <.0001\n\n\nBecause there were no effects for 5th graders in the previous analysis, we can ignore that output. Focusing on the 8th grade output, we see that there is no effect for lecture type for 8th graders using the Computer presentation. However, the Standard presentation was significant. Following up on that:\n\nemmeans(omnibus_aov, by=c(\"Grade\", \"Presentation\"), specs = \"Lecture\")  %>% pairs(adjust=\"tukey\")\n\nGrade = 5th, Presentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -8.00 4.27 60  -1.875  0.1548\n History - Social      -2.00 4.27 60  -0.469  0.8862\n Physical - Social      6.00 4.27 60   1.406  0.3442\n\nGrade = 8th, Presentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -7.83 4.27 60  -1.836  0.1668\n History - Social      -2.33 4.27 60  -0.547  0.8485\n Physical - Social      5.50 4.27 60   1.289  0.4069\n\nGrade = 5th, Presentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 4.27 60  -0.703  0.7626\n History - Social      19.00 4.27 60   4.453  0.0001\n Physical - Social     22.00 4.27 60   5.156  <.0001\n\nGrade = 8th, Presentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 4.27 60  -0.703  0.7626\n History - Social      18.83 4.27 60   4.414  0.0001\n Physical - Social     21.83 4.27 60   5.117  <.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nAgain, this output give us a lot of info, BUT all we should focus on is the section of interect, in this case 8th Grade, Standard Presentation or the last section. Here, scores for the Social test were less than the Physical and History.\nConstructing a narrative:\nGiven these results, what narrative do you think you can tell? Remember use the plots to unpack what the results are telling you. Our results focused on differences in the Lecture:Presentation analysis for each grade. I would recommend that your story start there. Something to the effect of Lecture and Presentation interact for 8th graders but not 5th graders.\nTo remind ourselves:\n\nMain effects for Lecture, Presentation, and Grade\nTwo way interactions\nThree-way interaction that we focus on\n\nThe results of the 3-way interaction, by Grade:\n\n5th graders = no effects\n8th graders = Lecture × Presentation interaction, where there was a null effect for Lecture on the Computer presentation, but an effect for Lecture on the Standard Presentation.\n\n\n\nNow the narrative:\n… to answer this question we conducted a 2 (Grade) × 2 (Presentation) × 3 (Lecture) between effects ANOVA. Our ANOVA revealed a three-way, Grade × Presentation × Lecture type interaction, \\(F\\)(2, 60) = 3.87, \\(p\\) = .03, \\(\\eta_p^2\\) = .11. To address this interaction we conducted separate Presentation × Lecture ANOVA for each Grade. Our results for 5th graders showed no effects nor an interaction (\\(p\\) > .05). For 8th graders, we found an Presentation × Lecture interaction, \\(F\\)(2, 60) = 8.61, \\(p\\) < .001. While there were no differences due to Lecture type for 8th graders presented information via computer (\\(p\\) > .05), 8th graders in the Standard presentation, \\(F\\)(2, 60) = 19.61, \\(p\\) < .001 tended to perform worse for the Social lecture (\\(M\\) ± \\(SD\\) = 12.33 ± 3.72) than for the History (31.17 ± 9.87) and Physical (34.17 ± 10.98) lectures (Tukey HSD, \\(p\\) < .05).\nNow imagine trying to deal with a FOUR-WAY INTERACTION!!!! SHEESH!!!\nOn to the next one!"
  },
  {
    "objectID": "week01/1_4-loading_data.html",
    "href": "week01/1_4-loading_data.html",
    "title": "Loading in Data",
    "section": "",
    "text": "Typically the file types that are used by beginners in R are plain text and delimited. They may have the extension “txt”, “csv”, or “dat” for example. These may become more sophisticated you progress, for example you can load in proprietary types like SPSS and STATA, but for this course we will mostly use plain text files (although later in the course I will show you how to load in Excel files and SPSS files).\n\nAs with loading packages, you can also load in a file containing data using the RStudio GUI. See this video.\nAgain, this is only preferred if you are not sharing your analysis. If you are sharing your analysis (as in this class) you need to do the command line. Fortunately, RStudio creates the appropriate command-line for you to copy and paste. For example, loading one of your homework data sets can be accomplished by:\n\nlibrary(tidyverse)\nLexicalDescisionData <- read_table(\"path/to/LexicalDescisionData.txt\")\n\nwhere path/to/ is the path to the folder containing the file LexicalDescisionData.txt. For example, on my computer it might be:\n\n“/Users/tehrandav/Documents/psyc7014/LexicalDescisionData.txt”\n\nI’ve uploaded this file to OneDrive in the walkthroughs and examples folder. Please feel free to download the file and follow along is you wish. Note that if you do elect to load in via the GUI you need to be sure to copy the output to your Rmd source. Otherwise, I will not be able to run it on my computer.\n\nYou might be saying to yourself, “but Tehran the entire reason you’ve got us learning R is for transparency and openness with our data. How would I be able to share in my code a data file that resides on my hard drive?!?””\nCorrect, you can’t, but you can upload it to the internet and someone can access it from an online repository. Personally, I like to use http://www.github.com, but we’ll save that for some advanced stuff later in the semester for those so inclined. Another alternative is to upload your entire folder to a project in http://www.rstudio.cloud.\nIf the data is uploaded directly from the web, we can load it in using the read_delim() function from above. This is some reaction time data taken from a website. Let’s assign it to an object RxData\n\nlibrary(tidyverse) # no need to ask if already loaded\nalcohol_use_data <- read_csv(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/alcuseN6.csv\", col_names = T)\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 18 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): id, Age, Alc.use\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTo see what’s going on with the additional calls in this line, run the following line to get help:\n\n? read_csv\n\nA document file should show up in your help tab, containing examples and describing what different arguments are doing. Search for col_names and try to figure out what’s going on.\n\nThis is probably a good place to stop for now. In the meantime try running the following 4 commands (assuming that you have imported alcohol_use_data) and think about what they are returning:\n\nclass(alcohol_use_data)\nnames(alcohol_use_data)\nhead(alcohol_use_data)\nsummary(alcohol_use_data)"
  },
  {
    "objectID": "week11/11_1-interactions.html",
    "href": "week11/11_1-interactions.html",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "",
    "text": "This walkthrough is a continuation of our focus on Factorial ANOVA. Here we’re asking the question “what to do if you have an interaction”. As we have discussed when running a factorial ANOVA, your first question should be “do I have an interaction”. If you do have an interaction then you need to examine that interaction in detail. How do we do this? Well, let’s think about what that interaction means. As an example, let’s revisit some of the data (or situations) from the previous walkthrough. We’ll also progressively ramp-up the complexity of our designs.\nThis write-up requires the following packages:"
  },
  {
    "objectID": "week11/11_1-interactions.html#interaction-plots",
    "href": "week11/11_1-interactions.html#interaction-plots",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Interaction plots",
    "text": "Interaction plots\nInteraction plots take into consideration the influence of each of the IVs on one another—in this case the mean and CI of each smoking group (Active v. Nonsmoking) as a function of Task (Driving Simulation v. Pattern Recognition). For example, a line plot might look like this:\n\n# line plot\nggplot(data = dataset_2by2, mapping=aes(x=Smkgrp,\n                                        y=score,\n                                        group=Task)) + # grouping the data by levels of Task\n  stat_summary(geom=\"pointrange\",\n               fun.data = \"mean_cl_normal\", \n               position=position_dodge(.5)) + # dodging position so points do not overlap with one another\n  stat_summary(geom = \"line\", \n               fun = \"mean\", \n               position=position_dodge(.5), \n               aes(linetype=Task)) + # each level of Task gets its own linetype\n  theme_cowplot()"
  },
  {
    "objectID": "week11/11_1-interactions.html#running-the-anova-lm-method",
    "href": "week11/11_1-interactions.html#running-the-anova-lm-method",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Running the ANOVA lm() method",
    "text": "Running the ANOVA lm() method\nNow we can run the ANOVA using the lm() method. The new wrinkle from last week is that we are adding our interaction terms the formula equation the structural equation:\n\\[y=IV_1+IV_2+(IV_1*IV_2)\\] where the first and second terms capture our main effects and the third is our interaction.\nLast week you only focused on the main effects so our model is what we would call additive:\n\nlm(score~Smkgrp+Task,data = dataset_2by2)\n\nThis week we are including the interaction term. In R this formula now becomes:\n\nlm(score~Smkgrp + Task + Smkgrp*Task,data = dataset_2by2)\n\nThe operator * may be understood here as “crossed-by” or “interaction between”. Depending on your reference, you may also see : which means the same thing.\nNote that we can write this same equation in shorthand:\n\nlm(score~Smkgrp*Task,data = dataset_2by2)\n\nwhere the * operator tells R to examine all related main effects and interactions. This is usually the best way to code this, as the long-form becomes unwieldy as we increase IVs and combinations of interactions. However, note that if you have planned comparisons you may elect to only specify certain main effects and interactions in long-form. This may become increasing important when you start to deal with more complex models. I think I’ll do a brief write up about this one day (before the end of the semester) by for now…\nBefore continuing, let’s compare the outputs of the additive model and the interaction model:\n\nlm(score~Smkgrp + Task,data = dataset_2by2) %>% anova()\n\nAnalysis of Variance Table\n\nResponse: score\n          Df  Sum Sq Mean Sq F value   Pr(>F)   \nSmkgrp     1  248.07 248.067  10.187 0.002302 **\nTask       1  187.27 187.267   7.690 0.007491 **\nResiduals 57 1388.07  24.352                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlm(score~Smkgrp * Task,data = dataset_2by2) %>% anova()\n\nAnalysis of Variance Table\n\nResponse: score\n            Df  Sum Sq Mean Sq F value   Pr(>F)   \nSmkgrp       1  248.07 248.067 11.5687 0.001244 **\nTask         1  187.27 187.267  8.7333 0.004564 **\nSmkgrp:Task  1  187.27 187.267  8.7333 0.004564 **\nResiduals   56 1200.80  21.443                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNotice that adding the interaction terms does not affect our analysis of the main effects, both models have identical Mean Square and F values for the main effects. This is what we mean when we say that the tests within ANOVA are orthogonal to one another (independent of one another).\nAnother thing to note here are that the apparent equal F-values in our Task effect and Interaction is due to rounding. This is simply an anomaly, and is not to be expected in most cases. Even here, they are different, but only nearly identical. As a thought experiment, can we think of why they are nearly identical in this case (Hint: can you see in the plot what might be causing the interaction)?\nChecking assumptions\nOkay let’s save our model and proceed to do the requisite assumptions checks:\n\n\n\n\naov_model %>% performance::check_model(panel=F)\n\n\naov_model %>% performance::check_normality() # shapiro test from performance\n\nOK: residuals appear as normally distributed (p = 0.074).\n\naov_model %>% car::leveneTest()\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value   Pr(>F)   \ngroup  3     6.1 0.001149 **\n      56                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs in the last walkthrough we’ll ignore the issues with homogeneity. Let’s run our ANOVA:\n\nsjstats::anova_stats(aov_model)[1:8]\n\nterm        | df |    sumsq |  meansq | statistic | p.value | etasq | partial.etasq\n-----------------------------------------------------------------------------------\nSmkgrp      |  1 |  248.067 | 248.067 |    11.569 |   0.001 | 0.136 |         0.171\nTask        |  1 |  187.267 | 187.267 |     8.733 |   0.005 | 0.103 |         0.135\nSmkgrp:Task |  1 |  187.267 | 187.267 |     8.733 |   0.005 | 0.103 |         0.135\nResiduals   | 56 | 1200.800 |  21.443 |           |         |       |"
  },
  {
    "objectID": "week11/11_1-interactions.html#adressing-the-interaction",
    "href": "week11/11_1-interactions.html#adressing-the-interaction",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Adressing the interaction",
    "text": "Adressing the interaction\nThis model yields a Smoking group by task interaction! Looking at our interaction plot above, we shouldn’t have been too surprised by this. We see that for Non smokers, there is minimal difference between the two cognitive tasks, whereas with the smoking group, the scores of the Driving Simulation group were much lower than the Pattern recognition group. Another, equally valid way of interpreting the data is that while Pattern recognition scores were unaffected by smoking condition, Driving simulation scores were drastically decreased for smokers compared to non-smokers. While both interpretations are equally valid in the neutral sense, one may be more interesting to you the researcher (this is where your a priori hypotheses would come into play). Is it more interesting that Non smokers performed equivalently on both types of cognitive tasks while active smokes performed better on the pattern recognition task than the driving task OR is it more interesting that Pattern recognition scores where unaffected by smoking whereas driving simulation scores were?\nI bring this up, as while it may be appropriate to mention both trends, you typically only TEST for one or the other. Remember, there is a cost for every test that your run—you need to adjust for familywise error.\nIn this case I’m going test the second variant, testing how performance on each cognitive task changes by virtue of smoking group. To run a post-hoc ANOVA. This can be accomplished sending our model to joint_tests(). So the model is saying take a look at how smoking group scores change on each level of task.\n\naov_model %>% emmeans::joint_tests(by = \"Task\")\n\nTask = Pattern Recognition:\n model term df1 df2 F.ratio p.value\n Smkgrp       1  56   0.099  0.7536\n\nTask = Driving Simulation:\n model term df1 df2 F.ratio p.value\n Smkgrp       1  56  20.203  <.0001\n\n\nSince smoking group only has 2 groups, I could stop here and report my obtained \\(F\\) tests. If you prefer to report the pairwise \\(t\\) test you can simply specify your pairwise comparisons for Smkgrp, by each level of Task using emmeans().\n\naov_model %>% \n  emmeans::emmeans(spec = \"Smkgrp\", by = \"Task\") %>%\n  pairs(adjust=\"tukey\")\n\nTask = Pattern Recognition:\n contrast            estimate   SE df t.ratio p.value\n Nonsmoking - Active    0.533 1.69 56   0.315  0.7536\n\nTask = Driving Simulation:\n contrast            estimate   SE df t.ratio p.value\n Nonsmoking - Active    7.600 1.69 56   4.495  <.0001\n\n\nThe output above shows what we expect, that for Pattern recognition groups, scores are indifferent to whether participants are smokers or not, where with the Driving simulation groups, Nonsmokers performed much better."
  },
  {
    "objectID": "week11/11_1-interactions.html#anova",
    "href": "week11/11_1-interactions.html#anova",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "2 × 3 ANOVA",
    "text": "2 × 3 ANOVA\nThings become slightly more complex when on of our factors has 3 or more levels. To see this let’s revisit the second example from the previous walkthrough:\n\nBackground: Given the ease of access for new technologies and increasing enrollment demands, many university are advocating that departments switch over to E-courses, where students view an online, pre-recorded lecture on the course topic in lieu of sitting in a classroom in a live lecture. Given this push, a critical question remains regarding the impact of E-courses on student outcomes. More it may be the case that certain subject content more readily lends itself to E-course presentations than other subjects. To address this question we tested students performance on a test one week after participating in the related lecture. Lectures were either experienced via online (Computer) or in a live classroom (Standard). In addition, the lecture content varied in topic (Physical science, Social science, History)\n\nHere’s the data, where Score represents performance:\n\ndataset <- read_csv(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/factorial_AOV_data.csv\")\n\nRows: 36 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Lecture, Presentation\ndbl (2): subID, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "week11/11_1-interactions.html#plotting-the-data-and-descriptive-stats",
    "href": "week11/11_1-interactions.html#plotting-the-data-and-descriptive-stats",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Plotting the data and descriptive stats",
    "text": "Plotting the data and descriptive stats\nHere’s what our results look like. I’ll revisit the particulars on constructing this sort of plot in the next walkthrough. For now, all we are doing is extending the plotting methods that you have been using for the past few weeks. The important addition here is the addition of group = in the first line the ggplot.\nFor example:\n\nggplot(data = dataset, mapping=aes(x=Lecture,\n                                   y=Score,\n                                   group=Presentation))\n\nindicates that we are:\n\nusing the dataset data set\nputting first IV, Lecture, on the x-axis\nputting our dv, Score on the y-axis\nand grouping our data by our other IV, Presentation\n\nThis last bit is important as it makes clear that the resulting mean plots should be of the cell means related to Lecture x Presentation. Note that in the plot below, I am also adjusting the shape of the data points by Presentation (done in stat_summary .\n\nggplot(dataset,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = \"mean_se\",\n               position = position_dodge(.25), # dodge to prevent overlap\n               aes(shape=Presentation)) + # each level of presentation gets a shape\n  stat_summary(geom = \"line\", fun.y=\"mean\", position = position_dodge(.25)) +\n  theme_cowplot() +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\"))\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nAnd now getting the cell means and marginal means. Remember that analysis of the marginal means is what is tested in the main effects. The test for an interaction focuses on the cell means. Here we are using the summarySE function from the Rmisc package. I find it to be more efficient than psych::describeBy() and its useful next week when we do Repeated Measures ANOVA\n\n# cell means:\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = c(\"Presentation\",\"Lecture\"))\n\n  Presentation  Lecture N Score        sd       se        ci\n1     Computer  History 6    38  4.381780 1.788854  4.598397\n2     Computer Physical 6    46  6.985700 2.851900  7.331042\n3     Computer   Social 6    40  4.816638 1.966384  5.054751\n4     Standard  History 6    31 10.315038 4.211096 10.824968\n5     Standard Physical 6    34 11.009087 4.494441 11.553328\n6     Standard   Social 6    12  3.847077 1.570563  4.037260\n\n# marginal means\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = \"Lecture\")\n\n   Lecture  N Score        sd       se       ci\n1  History 12  34.5  8.393721 2.423058 5.333116\n2 Physical 12  40.0 10.795622 3.116428 6.859211\n3   Social 12  26.0 15.201675 4.388345 9.658683\n\nsummarySE(data = dataset,measurevar = \"Score\", groupvars = \"Presentation\")\n\n  Presentation  N    Score        sd       se       ci\n1     Computer 18 41.33333  6.249706 1.473070 3.107906\n2     Standard 18 25.66667 13.105903 3.089091 6.517412"
  },
  {
    "objectID": "week11/11_1-interactions.html#the-omnibus-anova-and-assumption-tests",
    "href": "week11/11_1-interactions.html#the-omnibus-anova-and-assumption-tests",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "the Omnibus ANOVA (and assumption tests)",
    "text": "the Omnibus ANOVA (and assumption tests)\nThe very first ANOVA model that we build crosses all of our independent variables. This is the omnibus ANOVA. Let’s build this model and run our assumption checks\n\nomnibus_aov <- lm(Score~Lecture*Presentation, dataset)\n\nI’m going to skip the assumption checks (bad professor!) and go straight to our results:\n\nsjstats::anova_stats(omnibus_aov)[1:8]\n\nterm                 | df | sumsq |   meansq | statistic | p.value | etasq | partial.etasq\n------------------------------------------------------------------------------------------\nLecture              |  2 |  1194 |  597.000 |    10.737 |  < .001 | 0.206 |         0.417\nPresentation         |  1 |  2209 | 2209.000 |    39.730 |  < .001 | 0.381 |         0.570\nLecture:Presentation |  2 |   722 |  361.000 |     6.493 |   0.005 | 0.125 |         0.302\nResiduals            | 30 |  1668 |   55.600 |           |         |       |              \n\n\nLooking at the ANOVA: Our ANOVA reveals two main effects and in interaction. Looking back at the plot (always, always plot before you think about doing any sort of follow-ups!!) it is fairly apparent what is happening—when moving from one lecture to the next, we see a much more dramatic decrease in score for the Social group in the Standard presentation group compared to the Computer presentation. That is, moving from left to right the pattern of change is different for the Standard group, compared to the Computer group. This is what our eyeball test is telling us—we need to confirm it with some stats! There are two ways to address this interaction, each involves sub-setting the data for further analysis.\nAs mentioned above, when you have an interaction, you proceed by testing for differences between means for one condition, on each individual level of the other. For example, we can test for and effect of Lecture Type when the Presentation is Computer, and effect of Lecture Type when the Presentation is Standard. In this case you would run two separate simple effects ANOVAs, each taking a look at changes for each line in the plot above.\n–OR–\nYou could check for difference between Presentations on each Lecture type. Here you would be comparing Computer v Standard in each of the Lecture conditions. This would involve running three ANOVAs each checking for the Presentation differences (circle v. triangle) present at History, Physical, and Social.\nWhich you choose, ultimately depends on which narrative you are trying to convey in your data. Here it may make sense to do the former. That is eyeballing the data it looks like the means in the Computer presentation level are not as different from one another as the Standard presentation."
  },
  {
    "objectID": "week11/11_1-interactions.html#running-the-simple-effects-anova-in-6-steps",
    "href": "week11/11_1-interactions.html#running-the-simple-effects-anova-in-6-steps",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Running the simple effects ANOVA in 6 steps:",
    "text": "Running the simple effects ANOVA in 6 steps:\nGiven that we have elected to take a look at Lecture on each level of Presentation, we would need to run 2 simple effects ANOVAs. This is because breaking the omnibus in this way still leaves in each subsequent analysis a comparison of the 3 levels of Lecture. Basically we are running 2 separate One-way ANOVAs:\n\nthe first looks at Scores~Lecture when Presentation = Computer\nthe second looks at Scores~Lecture when Presentation = Standard\n\nThere is, however, one major caveat. When you run the follow-up ANOVA you need to use the error terms from your omnibus ANOVA. That is your simple effects ANOVA calls for the omnibus ANOVA errors: Sum of Squares, Mean Square Error, and denominator degrees of freedom.\nWhat this means is that if you were to actually run this data as two distinct One-Way ANOVAs, the F-value (and subsequent p-values) that you get would be WRONG. For example simply running a filter and then ANOVA like this will not work:\n\n# this is wrong... don't do this!!!\nlm(Score~Lecture, dataset %>% filter(Presentation==\"Computer\")) %>%\n  sjstats::anova_stats() %>% dplyr::select(1:8)\n\nterm      | df | sumsq |  meansq | statistic | p.value | etasq | partial.etasq\n------------------------------------------------------------------------------\nLecture   |  2 |   208 | 104.000 |     3.421 |   0.060 | 0.313 |         0.313\nResiduals | 15 |   456 |  30.400 |           |         |       |              \n\n\nA quick glance at the table above reveals the error. You’ll notice that the denominator df are 15 where in the omnibus ANOVA they were 30. Fixing this isn’t as simple as adjusting the denominator df and looking it up on the F-table. This involves a series of calculations that results in a different F-ratio as well. For the sake of clarity I’m going to show you how to do this “by hand” and then show you how you’ll never need to do it “by hand”\nThere are several steps that need to be run for each simple effects ANOVA:\nstep 1: get the omnibus ANOVA:\nAssuming you haven’t already we need to run the omnibus ANOVA. Let’s get this again\n\nomnibus_aov <- lm(Score~Lecture*Presentation, dataset)\n\nstep 2: get the MSError, Error df, and Error SS from omnibus ANOVA\nWe can pull these values directly from the sjstats::anova_stats() output. It easier to just save this output to an object first. We can then check its attributes()\n\nomnibus_values <- sjstats::anova_stats(omnibus_aov)\nattributes(omnibus_values)\n\n$names\n [1] \"term\"            \"df\"              \"sumsq\"           \"meansq\"         \n [5] \"statistic\"       \"p.value\"         \"etasq\"           \"partial.etasq\"  \n [9] \"omegasq\"         \"partial.omegasq\" \"epsilonsq\"       \"cohens.f\"       \n[13] \"power\"          \n\n$class\n[1] \"sj_anova_stat\" \"data.frame\"   \n\n$row.names\n[1] \"Lecture\"              \"Presentation\"         \"Lecture:Presentation\"\n[4] \"...4\"                \n\n\nIn the above list, we are interested in sumsq and df. We need to index each by number. In this case residuals are on the 4th line:\n\nomnibus_df <- omnibus_values$df[4]\nomnibus_mse <- omnibus_values$meansq[4]\nomnibus_ss_error <- omnibus_values$sumsq[4]\n\nstep 3: subset your data accordingly\nIn order to do this we will need to subset the data. For example I am interested in running my follow-ups on Computer data and Standard data separately, so my first move is to perform this subset:\n\ncomputer_data <- filter(dataset, Presentation==\"Computer\")\nstandard_data <- filter(dataset, Presentation==\"Standard\")\n\n(FWIW you could also do the subsetting in the lm() call)\nstep 4: run your One-way simple effects ANOVA(s)\nHere I’m focusing on the computer_data for my example. You can return to the standard_data later.\n\ncomputer_aov_values <- lm(Score~Lecture, dataset %>% filter(Presentation==\"Computer\")) %>%\n  sjstats::anova_stats()\ncomputer_aov_values\n\nterm      | df | sumsq |  meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n-----------------------------------------------------------------------------------------------------------------------------------------\nLecture   |  2 |   208 | 104.000 |     3.421 |   0.060 | 0.313 |         0.313 |   0.212 |           0.212 |     0.222 |    0.675 | 0.635\nResiduals | 15 |   456 |  30.400 |           |         |       |               |         |                 |           |          |      \n\n\nstep 5: get the treatment MS, df, SS, and F-value from your simple ANOVA\nAs before, this can be done by calling attributes from our simple ANOVA, computer_aov. We need to grab the following values related to the treatment:\n\n# treatment df\nsimple_df <- computer_aov_values$df[1]\n# treatment MS\nsimple_ms <- computer_aov_values$meansq[1]\n# and the simple treatment SS:\nsimple_ss <- computer_aov_values$sumsq[1]\n\nstep 6: make our corrections\nAs I noted above the F-value, p-value, and effect size (pes, \\(\\eta_p^2\\)) that you originally obtained in the simple effects computer_aov are not correct. We need to make the appropriate corrections. This can be done my hand, using the values we’ve extracted and calculated above:\n\n# calculate F using simple treatment  MS and omnibus MSE\ncorrected_f <- simple_ms/omnibus_mse\n\n# the pf function calculates the cummulative p.value using the corrected_f and appropriate degrees of freedom. Since its cumulative we subtract this result from 1:\n\ncorrected_p <- (1-pf(corrected_f,df1 = simple_df,df2 = omnibus_df))\n\n# calculate the pes by using simple treatment SS and omnibus MSE:\ncorrected_pes <- (simple_ss/(simple_ss+omnibus_ss_error))\n\nCongrats!! You have made the appropriate corrections! Taking a look at your corrected result it appears that we should accept the null hypothesis of no difference in means on the computer data. As with posthoc comparisons, effect sizes for simple effects ANOVA are somewhat debatable, but this might be the most appropriate way to do this.\n\ntibble(corrected_f, corrected_p, corrected_pes)\n\n# A tibble: 1 × 3\n  corrected_f corrected_p corrected_pes\n        <dbl>       <dbl>         <dbl>\n1        1.87       0.172         0.111"
  },
  {
    "objectID": "week11/11_1-interactions.html#the-emmeans-way",
    "href": "week11/11_1-interactions.html#the-emmeans-way",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "the emmeans() way",
    "text": "the emmeans() way\nthe simple effects ANOVA\nIn years past, I would have shown you how to create your own function to do this, but instead we can also use the emmeans package to conduct simple effects follow-ups. In class I introduced you to the function joint_test() which can be used to conduct a simple effects ANOVA. [NOTE: I show you an alternative method using emmeans::emeans() at the end of this walkthough. Both are equivalent].\nIn this case we need to tell joint_test how to parse our omnibus_aov model. Here we are telling it to look at the effects of Lecture by each level of Presentation.\n\nsimple_effects_by_presentation <- joint_tests(omnibus_aov, by = \"Presentation\")\n\nsimple_effects_by_presentation\n\nPresentation = Computer:\n model term df1 df2 F.ratio p.value\n Lecture      2  30   1.871  0.1716\n\nPresentation = Standard:\n model term df1 df2 F.ratio p.value\n Lecture      2  30  15.360  <.0001\n\n\nBased on this output we have a simple effect for standard but not computer.\neffects size (partial eta sq) for the ANOVA\nInstead of calculating partial eta squared for the simple effects ANOVA by hand, we can use the F_to_eta2 function from the effectsize package. FWIW the effectsize package has a host of other functions for calculating effect sizes. Here, F_to_eta2 takes three arguments, the f value of the (simple effects) ANOVA, and its numerator (treatment) and denominator (error) dfs. Looking at the output from the last section, these values are f = 15.36, df = 2, df_error = 30:\n\npacman::p_load(effectsize)\nF_to_eta2(f = 15.36, df = 2, df_error = 30)\n\nEta2 (partial) |       95% CI\n-----------------------------\n0.51           | [0.27, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\npost-hoc analyses on the simple effects ANOVA\nGiven that we have a simple effect for standard, we need to run pairwise posthoc analyses to test the effect of Lecture on each presentation thype. However, given that our test suggested no simple effect on Computer, we can just ignore that part of the output.\nWe can do so using emmeans() and specifying that we want to break our pairwise comparisons up by Presentation.\n\npairwise_comps <- emmeans::emmeans(omnibus_aov, by = \"Presentation\", specs = pairwise~Lecture)\n\npairwise_comps %>% pairs()\n\nWarning in class(rtn) <- c(\"summary_emm\", \"data.frame\"): Setting class(x) to\nmultiple strings (\"summary_emm\", \"data.frame\", ...); result will no longer be\nan S4 object\n\n\n[1] x\n<0 rows> (or 0-length row.names)\n\n\nGiven our latter result above we see that in the Standard presentation, scores based on Social lectures were significantly less than the other two.\nIf we wanted to calculate any effect sizes for the pairwise comparisons (corrected Cohen’s D) we could use the function we learned last week. Again, ignore Computer as it was non-significant.\n\nemmeans::eff_size(object = pairwise_comps,\n         sigma = sigma(omnibus_aov),\n         edf = df.residual(omnibus_aov))\n\nSince 'object' is a list, we are using the contrasts already present.\n\n\nPresentation = Computer:\n contrast             effect.size    SE df lower.CL upper.CL\n (History - Physical)      -1.073 0.594 30   -2.285    0.140\n (History - Social)        -0.268 0.578 30   -1.449    0.913\n (Physical - Social)        0.805 0.587 30   -0.393    2.003\n\nPresentation = Standard:\n contrast             effect.size    SE df lower.CL upper.CL\n (History - Physical)      -0.402 0.580 30   -1.586    0.782\n (History - Social)         2.548 0.664 30    1.191    3.905\n (Physical - Social)        2.950 0.692 30    1.538    4.363\n\nsigma used for effect sizes: 7.457 \nConfidence level used: 0.95"
  },
  {
    "objectID": "week11/11_1-interactions.html#interpreting-these-results",
    "href": "week11/11_1-interactions.html#interpreting-these-results",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Interpreting these results:",
    "text": "Interpreting these results:\nGiven everything above, there are several things that this data are telling us:\n\n\nMain effect for computer: on average people tended to perform better in the Computer presentation\n\nMain effect for Lecture: this main effect is not as clear. Overall, people may have performed worst on the Social lecture content, it’s quite apparent that the presence of this effect is muddled by presentation type. This is what the presence of our interaction is telling us.\n\nSimple effect of lecture type via computer: No differences in means suggests that people perform equally well on all lecture content types when administered via computer\n\nSimple effect of lecture type via standard lecture: significant simple effect and subsequent posthocs demonstrate that while students perform equally as well on Physical Science and History content via standard lectures, they perform worse on tests of Social science content.\n\nGiven this pattern of results two major conclusions become apparent:\n\nFirst, students overall perform better via Computer. This was the case for all three lecture types. True, how much better varies by condition, but in all cases scores were higher.\nSecond, while performance via Computer was indifferent to Lecture type (all lecture content scores were nearly equal) there was an attrition for Social science content when provided via standard lecture.\n\nFrom this one might conclude that administering content via E-course is better for student outcomes, especially if the subject content is in the Social Sciences! Also, I think that one of the lessons of 2020 is that this result is demonstrably FALSE ;)."
  },
  {
    "objectID": "week11/11_1-interactions.html#example-write-up",
    "href": "week11/11_1-interactions.html#example-write-up",
    "title": "Analysis of Variance: the Factorial ANOVA - Interactions & Simple Effects ANOVA",
    "section": "Example write-up:",
    "text": "Example write-up:\nFirst my camera ready plot:\n\nggplot(dataset,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = \"mean_se\",\n               position = position_dodge(.25), # dodge to prevent overlap\n               aes(shape=Presentation)) + # each level of presentation gets a shape\n  stat_summary(geom = \"line\", fun =\"mean\", position = position_dodge(.25)) +\n  theme_cowplot() +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\"))\n\n\n\n\nFigure 1 Scores as a function of Lecture type and Presentation style. Error bars represent standard error.\nTo test for the effects of Presentation style (Standard, Computer) and Lecture Type (Physics, History, Social) we ran a 2 × 3 factorial ANOVA. This ANOVA revealed main effects for both Presentation style, \\(F(1,30)=39.73, p<.001, \\eta_p^2=.57\\), and Lecture type, \\(F(2,30)=10.74, p<.001, \\eta_p^2=.42\\).\nAs shown in Figure 1, these effects we qualified by a Presentation style × Lecture type interaction, \\(F(2,30)=6.49, p=.005, \\eta_p^2=.30\\). Differences in Lecture type were only observed when material was presented in the Standard presentation, \\(F(2,30)=15.36, p<.001, \\eta_p^2=.51\\), where scores from the Social lecture were significantly different from the remaining two (Tukey HSD, p< .05). No differences were observed when the material was presented via computer (p>.05). Overall, participants performed better when the material was presented via computer (M±SD: 41.33 ± 6.25) compared to standard presentations (25.67 ± 13.11).\n(One thing you may notice is that I still stressed the main effect. This is to stress to the reader that presentation type did make a difference overall.)\nOne to the next one!!!"
  },
  {
    "objectID": "week11/11_3-simple_effects_SPSS.html",
    "href": "week11/11_3-simple_effects_SPSS.html",
    "title": "Simple Effects in SPSS",
    "section": "",
    "text": "As I mentioned in class, given that we are doing our analyses via programming, we have the luxury of have a function in emmeans that can make all of our simple effects adjustments for us. If you are using the GUI method in SPSS, you don’t have this luxury (although you can certainly create a similar function in SPSS!). Fear not, here I walk you through how to do this in SPSS, assuming you have Microsoft Excel."
  },
  {
    "objectID": "week11/11_2-higher_order_anova.html",
    "href": "week11/11_2-higher_order_anova.html",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "",
    "text": "This walk-through is a continuation of our previous work with factorial ANOVA. If you haven’t already, please check the factorial ANOVA and Interaction vignettes. In truth, nothing terribly new is being introduced here; we are just ramping up the complexity of our ANOVA models. Whereas before we considered a scenario with just 2 factors, here we will consider a 3 factor ANOVA. For all practical purposes you typically do not want to go higher than a 3 or 4 factor ANOVA, simply because of the exponential increase in complexity. For example, consider below where each letter is an IV and the resulting tests in the full factorial omnibus ANOVA:\nIncreasing the number of factors not only increases the practical difficulty of analysis, but more importantly, makes it more difficult to interpret your results. The primary culprit here is the potential presence of multiple interactions.\nWhen dealing with interactions in a higher order factorial design you always start off with the highest order interaction. For example in the 3 factor case, if you have a 3-way interaction, that supersedes any other effects and interactions, and must be dealt with first. If there is no three-way interaction, then you can co about the business of addressing any two way interactions that are present."
  },
  {
    "objectID": "week11/11_2-higher_order_anova.html#packages-and-data",
    "href": "week11/11_2-higher_order_anova.html#packages-and-data",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "Packages and data",
    "text": "Packages and data\nLet’s load in our necessary packages, scripts and some data and try some examples. This write-up requires the following packages:\n\n# required packages:\npacman::p_load(tidyverse, \n               cowplot, \n               emmeans)\n\nAnd now let’s re-acquaint ourselves with our familar example dataset, but with one new twist…\n\nBackground: Given the ease of access for new technologies and increasing enrollment demands, many grade schools are advocating that teachers switch over to E-courses, where students view an online, pre-recorded lecture on the course topic in lieu of sitting in a classroom in a live lecture. Given this push, a critical question remains regarding the impact of E-courses on primary school student outcomes. More it may be the case that certain subject content more readily lends itself to E-course presentations than other subjects. To address this question we tested students performance on a test one week after listening to the related lecture. Lectures were either experienced via online (Computer) or in a live classroom (Standard). In addition, the lecture content varied in topic (Physical science, Social science, History). Finally, to assess whether age had an impact on expected outcomes we assessed students in 5th and 8th grades.\n\nLooking at the above we have a 2 (Grade: 5th, 8th) × 2 (Presentation: Computer, Standard) × 3 (Lecture: Physical, Social, History) design. Our omnibus ANOVA therefore will test for the following effects:\n\nMain Effects: Grade, Presentation, Lecture\n2-way interactions: Grade × Presentation, Grade × Lecture, Lecture × Presentation\n3-way interaction: Grade × Presentation × Lecture"
  },
  {
    "objectID": "week11/11_2-higher_order_anova.html#example-1-no-three-way-interaction-single-two-way-interaction",
    "href": "week11/11_2-higher_order_anova.html#example-1-no-three-way-interaction-single-two-way-interaction",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 1: no three-way interaction, single two way interaction",
    "text": "EXAMPLE 1: no three-way interaction, single two way interaction\nLet’s load in this data:\n\nhigherEx1 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx1.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nshow(higherEx1)\n\n# A tibble: 72 × 5\n   Subject Grade Lecture  Presentation Score\n     <dbl> <chr> <chr>    <chr>        <dbl>\n 1       1 5th   Physical Computer        53\n 2       2 5th   Physical Computer        49\n 3       3 5th   Physical Computer        47\n 4       4 5th   Physical Computer        42\n 5       5 5th   Physical Computer        51\n 6       6 5th   Physical Computer        34\n 7       7 5th   Physical Standard        44\n 8       8 5th   Physical Standard        48\n 9       9 5th   Physical Standard        35\n10      10 5th   Physical Standard        18\n# ℹ 62 more rows\n\n\nFirst plot: 3 way interaction plot\nOne thing you may notice is since we have a more complex ANOVA, we have a more complex design with three factors we also have to construct a more complex plot. Whereas in the 2 factor case we could place one factor on the x-axis and group the other factor by line or shape or color; in the three factor case things become slightly more tricky.\nOne thing to consider is the logic of what we are doing with our plots. When we have two factors, say A & B, we are distinguishing between each level of B (by lines, shapes, colors) at each level of A (on the x-axis). In the 3 factor case where we have A,B, & C, we are distinguishing the B×C interaction (through the combination of shapes, lines, colors) on each level of A.\nIn the following plot, let’s place Lecture type along the x-axis. From here, we can create 2 groups of lines (each with 2 levels) representing the Grade × Presentation interaction. We note this by specifying the interaction in group of our baseline ggplot call:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade)))\n\nFrom here, we can proceed as before. Note, however, depending on the complexity of your plot you may also need to specify the interaction in each stat_summary::aes() as necessary.\nBelow I am changing the shape by Presentation and the linetype by Grade. The entire call, including the line above is:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  # adjusting the legend\n  theme(\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.1,.25))\n\n\n\n\nOK, not exactly the best plot. Let’s see if we can create some more space to work with by forcing the y-axis to go to 0, instead of cutting off at 10. There’s also a trick that we can use to stack our legend keys horizontally, rather than vertically\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  \n  # new additions / changes\n  coord_cartesian(ylim=c(0,50)) + \n  \n  # direction to stack legend keys\n  theme(legend.direction = \"horizontal\", \n        legend.position = c(.1,.25))\n\n\n\n\nalternatively, we could also just stack the legend boxes side by side:\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +  \n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + \n  theme_cowplot() + \n  # renaming axies\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  # adding whitespace around plot (optional)\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) +\n  \n  # new additions / changes\n  coord_cartesian(ylim=c(0,50)) + \n  \n  # direction to stack legend boxes instead of keys\n  theme(legend.box = \"horizontal\", \n        legend.position = c(.1,.25))\n\n\n\n\nNOTE: FWIW, we could also obviate the need for this complex of a plot, and just plot a two way interaction plot using Presentation and Lecture and then facet_wrap() by our third factor. For practice try taking the code above and faceting by ~Grade.\nrunning the ANOVA:\nFrom here we run the omnibus as usual:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx1)\n\nomnibus_aov %>% sjstats::anova_stats() %>% dplyr::select(1:8)\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq\n---------------------------------------------------------------------------------------------------\nLecture                    |  2 | 2330.361 | 1165.181 |    21.333 |  < .001 | 0.204 |         0.416\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.382 |         0.572\nGrade                      |  1 |    0.347 |    0.347 |     0.006 |   0.937 | 0.000 |         0.000\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.128 |         0.308\nLecture:Grade              |  2 |    0.361 |    0.181 |     0.003 |   0.997 | 0.000 |         0.000\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |              \n\n\nIn this case we only have Main effects for Lecture and Presentation, and a Lecture × Presentation interaction. Given this we can disregard Grade as its not contributing to any effects.\nReplotting the 2-way interaction\nIn some cases it is advisable to re-plot the data factoring out Grade by removing Grade from baseline group= as well as any summary_stat::aes(), (essentially treating this if it was a 2 factorial design like last week). For the sake of your sanity, and your readers’ sanity) I would also suggest being consistent with how you present your conditions. For example, in the original plot, Presentation was differentiated by shape. To be consistent, we need to do the same here).\n(You’ll note in the example below I’m also customizing font size and weight purely for personal aesthetics):\n\nggplot(higherEx1,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(shape=Presentation)) + theme_cowplot() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,50)) + \n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\nWarning in stat_summary(geom = \"line\", fun = \"mean\", position =\nposition_dodge(0.15), : Ignoring unknown aesthetics: shape\n\n\n\n\n\nFrom here I would deal with the follow-ups as we did in our 2×3 example from the last write-up: Run the simple effects and any necessary posthocs, being sure to correct using the error terms from the omnibus ANOVA."
  },
  {
    "objectID": "week11/11_2-higher_order_anova.html#example-2-no-three-way-interaction-multiple-main-effects-multiple-2-way-interactions",
    "href": "week11/11_2-higher_order_anova.html#example-2-no-three-way-interaction-multiple-main-effects-multiple-2-way-interactions",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 2: No three-way interaction, multiple main effects, multiple 2 way interactions:",
    "text": "EXAMPLE 2: No three-way interaction, multiple main effects, multiple 2 way interactions:\nLet’s load in a data set that is a little more complicated:\n\nhigherEx2 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx2.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nplotting the data\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nLooking at this plot its quite apparent that the pattern of results is different from Example 1. Perhaps most simply, there is a general shared pattern of effects for each of the shapes (Presentation) with the exception of the 8th Grade-Computer condition. For the remainder there is a dip for Social lectures, but in this one condition Social actually increases. Let’s run our ANOVA.\nrunning the omnibus ANOVA:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx2)\n\nomnibus_aov %>% sjstats::anova_stats() %>% dplyr::select(1:8)\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq\n---------------------------------------------------------------------------------------------------\nLecture                    |  2 |  774.361 |  387.181 |     7.089 |   0.002 | 0.072 |         0.191\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.405 |         0.572\nGrade                      |  1 |  308.347 |  308.347 |     5.645 |   0.021 | 0.029 |         0.086\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.135 |         0.308\nLecture:Grade              |  2 |  604.361 |  302.181 |     5.532 |   0.006 | 0.056 |         0.156\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |              \n\n\nOur ANOVA reveals an abundance of results. There are main effects for each of our IVs. In addition there are two interaction effects: Lecture:Presentation and Lecture:Grade. Unless there is a strong theoretical reason not to (which I see none) we will need to examine each of these interactions in further detail.\ntesting the Lecture:Presentation interaction:\n2-way interaction plot\nWe can begin by recreating our interaction plot, this time only focusing on the IVs that are of interest (those that are interacting). In this first case, they are Lecture and Presentation.\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=Presentation)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_cl_normal\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15)) + \n  theme_cowplot() + \n  theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)\n    ) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nsimple effect ANOVAs:\nProvided what we see on this plot, it may make sense to first run a simple effects ANOVA for each Presentation and then run the appropriate follow-ups. I say this because the more obvious, and potentially easily interpret-able effects occur moving across the line series (i.e., lines trend up or down).\nWhen testing for simple effects of Lecture on each Presentation type, we still need to include Grade in our analysis—this is to account for Grade’s contribution to our original model. Essentially we conduct a test for Lecture, Grade, and the Lecture by Grade interaction on each level of Presentation type. Using the template from the previous walkthroughs, this can be accomplished by simply telling R to run joint_tests separating the original model by Presentation.\nUsing emmeans::joint_tests():\n\nemmeans::joint_tests(omnibus_aov, by = \"Presentation\")\n\nPresentation = Computer:\n model term    df1 df2 F.ratio p.value\n Lecture         2  60   4.739  0.0123\n Grade           1  60   2.710  0.1049\n Lecture:Grade   2  60   2.823  0.0673\n\nPresentation = Standard:\n model term    df1 df2 F.ratio p.value\n Lecture         2  60  15.715  <.0001\n Grade           1  60   2.937  0.0917\n Lecture:Grade   2  60   2.710  0.0747\n\n\nBoth simple effects ANOVA of Lecture within Presentation were significant, suggesting that we should perform a post-hoc analyses of each:\n\nemmeans(omnibus_aov, by = \"Presentation\", specs=\"Lecture\") %>%\n  pairs(adjust=\"tukey\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\nPresentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -7.92 3.02 60  -2.624  0.0292\n History - Social      -8.17 3.02 60  -2.707  0.0237\n Physical - Social     -0.25 3.02 60  -0.083  0.9962\n\nPresentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 3.02 60  -0.994  0.5833\n History - Social      12.92 3.02 60   4.281  0.0002\n Physical - Social     15.92 3.02 60   5.275  <.0001\n\nResults are averaged over the levels of: Grade \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nThe results of the Tukey post-hoc suggests that History scores are significantly less than the other two groups when considering only the Computer presentation. For the standard presentation, scores in the History and Physical lecture were greater than the Social lecture.\ntesting the Lecture:Grade interaction:\nNow we do the same for the Lecture:Grade interaction. This time removing Presentation from our consideration.\n2-way interaction plot\nYou’ll notice that in this interaction plot, and the plot above, I am using the shape/linetype conventions that I established in my original plot. This will make things much easier if I wind up comparing these plots to my 3-way plot. I know I’ve said this before, but ONE MORE TIME WITH FEELING!\n\nggplot(higherEx2,mapping = aes(x = Lecture,y = Score, group=Grade)) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.15), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.15), aes(linetype=Grade)) + theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.25)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,60)) +\n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nsimple effect ANOVAs:\nProvided what we see on this plot, it may make the best sense to examine the pairwise differences in each Grade group by Lecture. Whereas in the previous interaction, the compelling changes occurred across lines, here what is more compelling is the presence/absence of gaps between the lines. In particular, while there are practically no differences due to Grade in the History or Physical Lectures, there is a larger gap in the Social condition.\nRunning these simple effects ANOVAs using emmeans:joint_tests(). Keep in mind, since we are parsing the Lecture:Grade interaction, be should only take a look at the effects of Grade on each of our Presentation levels. We can ignore the other output.\n\nemmeans::joint_tests(omnibus_aov,by = \"Lecture\") \n\nLecture = History:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60   5.255  0.0254\n Grade                1  60   0.001  0.9781\n Presentation:Grade   1  60   0.001  0.9781\n\nLecture = Physical:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60  15.382  0.0002\n Grade                1  60   0.000  1.0000\n Presentation:Grade   1  60   0.003  0.9561\n\nLecture = Social:\n model term         df1 df2 F.ratio p.value\n Presentation         1  60  86.123  <.0001\n Grade                1  60  16.710  0.0001\n Presentation:Grade   1  60   0.000  1.0000\n\n\nAs anticipated from looking at the plot, there was a significant difference between our Grades in the Social group, but not the other two. Since there are only two levels of Grade we don’t deen to run any other post hocs (the \\(F\\) test is our comparison between means).\nMain takeaways / write-up\nIt’s typically best to go back and look at all of your plots.\n\nthe main effect for Presentation is meaningful: Regardless of what plays out on the other factors, students tended to perform better in the computer presentation. Best to report that.\n\nthe Lecture:Presentation interaction resulted from the following:\n\nin the Computer presentations scores were lowest in the History lecture (indifferent in other two)\nin the Standard presentations scores were lowest in the Social lecture (indifferent in the other two)\n\n\nthe Lecture:Grade interaction resulted from the 5th graders performing worse than the eight graders in Social lectures; while performance was not different in the other two lectures.\n\nWith this in mind, an example write-up:\n\nOur results revealed main effects for each of our factors, in addition to Lecture × Presentation \\([F(2,60)=13.37, p<.001, \\eta_p^2=.31]\\) and Lecture × Grade interactions \\([F(2,60)=5.53, p=.006, \\eta_p^2=.16]\\).\n\n\nConsidering the former interaction, students presented material via computer format tended to perform poorest from the History Lecture, compared to Physical and Social (Tukey HSD, p<.05). However, when material was presented in the standard format, students performed poorest in the Social condition (p<.05), while the other two were not different.\n\n\nConsidering the latter interaction, a detailed analysis of performance as a function of lecture revaled that 8th Graders performed better than their 5th grade counterparts only in the Social lecture, \\(F(1,60) = 16.71, p < .001, \\eta_p^2=0.21\\).\n\n\nIn all conditions, students performed better when presented the material via computer compared to the standard presentation, \\([F(2,60)=7.09, p=.002, \\eta_p^2=.19]\\) (see Figure 1)."
  },
  {
    "objectID": "week11/11_2-higher_order_anova.html#example-3-omg-multiple-two-way-interactions-and-a-nasty-three-way",
    "href": "week11/11_2-higher_order_anova.html#example-3-omg-multiple-two-way-interactions-and-a-nasty-three-way",
    "title": "Dealing with Higher Order Factorial ANOVA",
    "section": "EXAMPLE 3: OMG, multiple two way interactions and a nasty three-way!!!",
    "text": "EXAMPLE 3: OMG, multiple two way interactions and a nasty three-way!!!\nFinally let’s take a look at some data that is all over the place:\n\nhigherEx3 <- read_delim(\"https://raw.githubusercontent.com/tehrandavis/graduate_statistics/main/practice_datasets/ANOVA5_higherEx3.txt\", delim = \"\\t\")\n\nRows: 72 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Grade, Lecture, Presentation\ndbl (2): Subject, Score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPlotting:\n\nggplot(higherEx3,mapping = aes(x = Lecture,y = Score, group=interaction(Presentation,Grade))) +\n  stat_summary(geom = \"pointrange\",fun.data = \"mean_se\",position = position_dodge(.5), aes(shape=Presentation)) + \n  stat_summary(geom = \"line\", fun=\"mean\", position = position_dodge(.5), aes(linetype=Grade)) + \n  theme_classic() + theme(\n    axis.title = element_text(size = 16, face = \"bold\", lineheight = .55),\n    axis.text = element_text(size = 12),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.position = c(.25,.15)) +\n\n  xlab(\"Lecture\") + \n  ylab (\"Score\") +\n  theme(plot.margin=unit(c(.25,.25,.25,.25),\"in\")) + \n  coord_cartesian(ylim=c(0,50)) + \n  \n  # stack legend boxes horizontally:\n  theme(legend.box = \"horizontal\")\n\n\n\n\nrunning the ANOVA:\n\nomnibus_aov <- lm(Score~Lecture*Presentation*Grade, data = higherEx1)\n\nomnibus_aov %>% sjstats::anova_stats()\n\nterm                       | df |    sumsq |   meansq | statistic | p.value | etasq | partial.etasq | omegasq | partial.omegasq | epsilonsq | cohens.f | power\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\nLecture                    |  2 | 2330.361 | 1165.181 |    21.333 |  < .001 | 0.204 |         0.416 |   0.193 |           0.361 |     0.194 |    0.843 | 1.000\nPresentation               |  1 | 4371.125 | 4371.125 |    80.029 |  < .001 | 0.382 |         0.572 |   0.376 |           0.523 |     0.377 |    1.155 | 1.000\nGrade                      |  1 |    0.347 |    0.347 |     0.006 |   0.937 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.010 | 0.051\nLecture:Presentation       |  2 | 1460.083 |  730.042 |    13.366 |  < .001 | 0.128 |         0.308 |   0.118 |           0.256 |     0.118 |    0.667 | 0.998\nLecture:Grade              |  2 |    0.361 |    0.181 |     0.003 |   0.997 | 0.000 |         0.000 |  -0.009 |          -0.028 |    -0.010 |    0.010 | 0.050\nPresentation:Grade         |  1 |    0.125 |    0.125 |     0.002 |   0.962 | 0.000 |         0.000 |  -0.005 |          -0.014 |    -0.005 |    0.006 | 0.050\nLecture:Presentation:Grade |  2 |    0.083 |    0.042 |     0.001 |   0.999 | 0.000 |         0.000 |  -0.009 |          -0.029 |    -0.010 |    0.005 | 0.050\nResiduals                  | 60 | 3277.167 |   54.619 |           |         |       |               |         |                 |           |          |      \n\n\nO.M.F.G., everything is significant!!! What to do!!!\nRemember, the first thing that we do is tackle the highest-order interaction. In this case we should tease-out the three-way. Again, we should look to our plot to help guide us in what to do. Looking at the plot it appears that different things are happening by Grade. The Presentation:Lecture lines tend to stay parallel for the 5th graders, but not as much for the 8th graders. At the same time the gaps between the two lines are different by grade. So, my advice would be to attack the 3-way interaction by looking at the individual Lecture:Presentation interactions on each Grade.\nFifth Graders, Lecture:Presentation interaction.\n\nemmeans::joint_tests(omnibus_aov, by=\"Grade\") \n\nGrade = 5th:\n model term           df1 df2 F.ratio p.value\n Lecture                2  60  10.930  0.0001\n Presentation           1  60  40.443  <.0001\n Lecture:Presentation   2  60   6.609  0.0025\n\nGrade = 8th:\n model term           df1 df2 F.ratio p.value\n Lecture                2  60  10.406  0.0001\n Presentation           1  60  39.588  <.0001\n Lecture:Presentation   2  60   6.757  0.0023\n\n\nYou’ll note that our results include simple effects for Lecture and Presentation at each Grade for as their interaction. That said, there are no effects when looking at the 5th graders. However, the detailed Lecture:Presentation analysis for the 8th graders revealed both main effects and their interaction. We need to follow-up on this interaction in the 8th-grade data. In this case we would look at the effect of Lecture on each level of Presentation for the eighth graders.\nTo do this we first subset the data further, by both Grade and Presentation:\n\nemmeans::joint_tests(omnibus_aov, by=c(\"Grade\", \"Presentation\")) \n\nGrade = 5th, Presentation = Computer:\n model term df1 df2 F.ratio p.value\n Lecture      2  60   1.904  0.1579\n\nGrade = 8th, Presentation = Computer:\n model term df1 df2 F.ratio p.value\n Lecture      2  60   1.777  0.1779\n\nGrade = 5th, Presentation = Standard:\n model term df1 df2 F.ratio p.value\n Lecture      2  60  15.635  <.0001\n\nGrade = 8th, Presentation = Standard:\n model term df1 df2 F.ratio p.value\n Lecture      2  60  15.386  <.0001\n\n\nBecause there were no effects for 5th graders in the previous analysis, we can ignore that output. Focusing on the 8th grade output, we see that there is no effect for lecture type for 8th graders using the Computer presentation. However, the Standard presentation was significant. Following up on that:\n\nemmeans(omnibus_aov, by=c(\"Grade\", \"Presentation\"), specs = \"Lecture\")  %>% pairs(adjust=\"tukey\")\n\nGrade = 5th, Presentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -8.00 4.27 60  -1.875  0.1548\n History - Social      -2.00 4.27 60  -0.469  0.8862\n Physical - Social      6.00 4.27 60   1.406  0.3442\n\nGrade = 8th, Presentation = Computer:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -7.83 4.27 60  -1.836  0.1668\n History - Social      -2.33 4.27 60  -0.547  0.8485\n Physical - Social      5.50 4.27 60   1.289  0.4069\n\nGrade = 5th, Presentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 4.27 60  -0.703  0.7626\n History - Social      19.00 4.27 60   4.453  0.0001\n Physical - Social     22.00 4.27 60   5.156  <.0001\n\nGrade = 8th, Presentation = Standard:\n contrast           estimate   SE df t.ratio p.value\n History - Physical    -3.00 4.27 60  -0.703  0.7626\n History - Social      18.83 4.27 60   4.414  0.0001\n Physical - Social     21.83 4.27 60   5.117  <.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nAgain, this output give us a lot of info, BUT all we should focus on is the section of interect, in this case 8th Grade, Standard Presentation or the last section. Here, scores for the Social test were less than the Physical and History.\nConstructing a narrative:\nGiven these results, what narrative do you think you can tell? Remember use the plots to unpack what the results are telling you. Our results focused on differences in the Lecture:Presentation analysis for each grade. I would recommend that your story start there. Something to the effect of Lecture and Presentation interact for 8th graders but not 5th graders.\nTo remind ourselves:\n\nMain effects for Lecture, Presentation, and Grade\nTwo way interactions\nThree-way interaction that we focus on\n\nThe results of the 3-way interaction, by Grade:\n\n5th graders = no effects\n8th graders = Lecture × Presentation interaction, where there was a null effect for Lecture on the Computer presentation, but an effect for Lecture on the Standard Presentation.\n\n\n\nNow the narrative:\n… to answer this question we conducted a 2 (Grade) × 2 (Presentation) × 3 (Lecture) between effects ANOVA. Our ANOVA revealed a three-way, Grade × Presentation × Lecture type interaction, \\(F\\)(2, 60) = 3.87, \\(p\\) = .03, \\(\\eta_p^2\\) = .11. To address this interaction we conducted separate Presentation × Lecture ANOVA for each Grade. Our results for 5th graders showed no effects nor an interaction (\\(p\\) > .05). For 8th graders, we found an Presentation × Lecture interaction, \\(F\\)(2, 60) = 8.61, \\(p\\) < .001. While there were no differences due to Lecture type for 8th graders presented information via computer (\\(p\\) > .05), 8th graders in the Standard presentation, \\(F\\)(2, 60) = 19.61, \\(p\\) < .001 tended to perform worse for the Social lecture (\\(M\\) ± \\(SD\\) = 12.33 ± 3.72) than for the History (31.17 ± 9.87) and Physical (34.17 ± 10.98) lectures (Tukey HSD, \\(p\\) < .05).\nNow imagine trying to deal with a FOUR-WAY INTERACTION!!!! SHEESH!!!\nOn to the next one!"
  },
  {
    "objectID": "week01/1_5-leveling-up.html",
    "href": "week01/1_5-leveling-up.html",
    "title": "Leveling-up",
    "section": "",
    "text": "From time to time, I’ll wrap up these weekly wrap-ups (hah!) with a few Level-Ups. These are bits of info to provide a deeper understanding the week’s concepts and/or how to perform some slightly more advanced programming in R. Level-ups are optional, so don’t get bogged down or freak out if you don’t quite follow what’s going on.\nFWIW, you should only be thinking about going through these extra level-ups if and only if you have a comfortable mastery of the week’s assigned material.\nThat said, I really recommend checking out this week’s level-up below. It has three parts, with the end result being an easy way to install and load multiple packages in R with a few lines of code.\nIt’s not terribly complicated and you’ll see the end result quite often this semester. If you’d rather not bother, then just go to the section HERE’S THE CHEAT CODE!!!. So without further delay, this week’s level-up(s)."
  },
  {
    "objectID": "week01/1_5-leveling-up.html#logical-statements",
    "href": "week01/1_5-leveling-up.html#logical-statements",
    "title": "Leveling-up",
    "section": "Logical statements",
    "text": "Logical statements\n\n\n\n\nWe were introduced to logicals very briefly in this week’s DataCamp assignments. Logicals are operations that may be applied to objects in R that assess their relationship as a truth value. For example:\n\n2+2==5\n\n[1] FALSE\n\n\nThe == (double equal sign) may be understood as posing the question “is equal to?” For example typing 2+2==4 in R will return TRUE. Logicals can be applied to string objects:\n\n\"tehran\"==\"tehran\"\n\n[1] TRUE\n\n\"tehran\"==\"davis\"\n\n[1] FALSE\n\n\nto vectors:\n\ny <- 1:5\ny==3\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\n\nthe third value, where the number 3 resides in vector y is labelled TRUE.\nand can be used to compare assigned objects.\n\nx <- 3\ny <- 4\nx==y\n\n[1] FALSE\n\na <- 1:5\nb <- seq(2,10,2)\na==b/2\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n\nA list of logical operators in R can be found here, including greater-than and less-than. Using logical operators can be a powerful tool in a programmer’s repertoire. For example they can allow you to quickly highlight and select certain instances from large data sets. Below I’m highlighting numbers divisible by 5 in a list running from 1 to 50:\n\nmyList <- 1:50\nmyList[myList %% 5 == 0] # index those numbers divisible by 5\n\n [1]  5 10 15 20 25 30 35 40 45 50\n\n\nHere I’m telling R to print a word based on whether myNumber is greater than 5:\n\nmyNumber <- 4\n\nifelse(test = myNumber>5, yes = \"Yep, great than 5\", no = \"Nunca, nada, NOPE!\")\n\n[1] \"Nunca, nada, NOPE!\"\n\n\nTry re-running the code above in your own console, with a value greater than 5 assigned to myNumber. There’s a little more on ifelse() below."
  },
  {
    "objectID": "week01/1_5-leveling-up.html#loading-packages-with-require",
    "href": "week01/1_5-leveling-up.html#loading-packages-with-require",
    "title": "Leveling-up",
    "section": "Loading packages with require()\n",
    "text": "Loading packages with require()\n\nGiven our brief intro to logicals; there is in fact an alternative to library() for loading a previously installed package. We can use require():\n\nrequire(tidyverse)\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\nrequire() has the additional benfit of returning a FALSE logical output if the requested package hasn’t been installed on your computer. This is in contrast to library() which just freaks out and reports an error (errors are bad as they can stop your execution). For example, let’s save the output of the following actions to an object called myVar.\nFor example running:\n\nmyVar <- library(xkcd)\nmyVar\n\nversus\n\nmyVar <- require(xkcd)\nmyVar\n\nIn both cases xkcd was not installed on your comp and an error was returned. However, with library(), nothing was saved to myVar, but require() returned a FALSE indicating that the requested package was not installed. Why do I bother to even bring this up?"
  },
  {
    "objectID": "week01/1_5-leveling-up.html#installing-and-loading-packages-like-a-pirate-ninja",
    "href": "week01/1_5-leveling-up.html#installing-and-loading-packages-like-a-pirate-ninja",
    "title": "Leveling-up",
    "section": "Installing and loading packages like a Pirate Ninja!",
    "text": "Installing and loading packages like a Pirate Ninja!\nThe central reason that we are using R is to get in the practice of data transparency and replicability. Ultimately, for every analysis that you perform you should be able to provide me with the appropriate syntax in your notebook file and I should be able to re-run each of your analyses step by step on my own computer. One important consideration is that you may be using packages that I don’t have installed and loaded on my computer and vice versa. To deal with this you would need to include two lines for every package:\n\ninstall.packages(\"package\")\nlibrary(package)\n\nIf you use a lot of packages, this can become very repetitive (imagine using 10 packages).\nA much more efficient way of doing things is to take advantage of that FALSE that require() returns. But first we need to install a package called pacman. Before we do this, input the next to lines seperately:\n\nrequire(pacman)\n\nLoading required package: pacman\n\n!require(pacman)\n\n[1] FALSE\n\n\nRecall from above that require() produces a FALSE if the requested package is NOT installed on your computer. So, assuming that pacman is not installed on your computer the first line will produce a FALSE and the second will produce a TRUE.\nSo what is that second line then? NEGATION.\nPlacing an exclamation point in fron of a statement essentially reads as “not true”. For now just understand that using this syntax we can create a line of code that checks to see if pacman is installed on your computer, and if not it installs it:\n\nif (!require(\"pacman\")) \n    install.packages(\"pacman\")\n\nThe above code is a conditional if-statement. It literally reads:\n\nCheck to see if the statement !require(\"pacman\") is TRUE (i.e., TRUE = pacman is not installed on your computer).\nIf the above indeed returns a TRUE, then run install.packages(\"pacman\").\n\nIn theory you could run this line for every package, but that would be tedious as well and is not really a simpler solution. Fortunately pacman contains a function that simplifies this for us, pacman::p_load() function. To get a feel for what this function does run the following line:\n\n? pacman::p_load()\n\nThe ? brings up an online help module for the named function. In this case the function is p_load() from the pacman package.\nYou’ll see that pacman::p_load() checks to see if a package is installed, if not it attempts to install the package from CRAN and/or any other repository. After that it loads all listed packages.\nLet’s try a few packages that you haven’t installed but are going to be useful to us later when we do ANOVA. FWIW I usually have a code chunk at the top of every notebook that uses this template, swapping in the various packages that I intend to use."
  },
  {
    "objectID": "week01/1_5-leveling-up.html#heres-the-cheat-code",
    "href": "week01/1_5-leveling-up.html#heres-the-cheat-code",
    "title": "Leveling-up",
    "section": "HERE’S THE CHEAT CODE!!!",
    "text": "HERE’S THE CHEAT CODE!!!\n\n# 1. check to see if pacman is on your computer and if not, let's \n# install and load it:\nif (!require(\"pacman\")) install.packages(\"pacman\")\nlibrary(pacman)\n\n# 2. install all other packages that we will be using:\npacman::p_load(afex,lmerTest,plyr,car)\n\nThis bit of code installed and loaded the afex, lmerTest, and plyr packages. To test that everything worked, try:\n\ndata(obk.long, package = \"afex\")\nafex::aov_ez(\"id\", \"value\", obk.long, between = c(\"treatment\", \"gender\"),\n             within = c(\"phase\", \"hour\"), observed = \"gender\")\n\nContrasts set to contr.sum for the following variables: treatment, gender\n\n\nAnova Table (Type 3 tests)\n\nResponse: value\n                        Effect          df   MSE         F  ges p.value\n1                    treatment       2, 10 22.81    3.94 + .198    .055\n2                       gender       1, 10 22.81    3.66 + .115    .085\n3             treatment:gender       2, 10 22.81      2.86 .179    .104\n4                        phase 1.60, 15.99  5.02 16.13 *** .151   <.001\n5              treatment:phase 3.20, 15.99  5.02    4.85 * .097    .013\n6                 gender:phase 1.60, 15.99  5.02      0.28 .003    .709\n7       treatment:gender:phase 3.20, 15.99  5.02      0.64 .014    .612\n8                         hour 1.84, 18.41  3.39 16.69 *** .125   <.001\n9               treatment:hour 3.68, 18.41  3.39      0.09 .002    .979\n10                 gender:hour 1.84, 18.41  3.39      0.45 .004    .628\n11       treatment:gender:hour 3.68, 18.41  3.39      0.62 .011    .641\n12                  phase:hour 3.60, 35.96  2.67      1.18 .015    .335\n13        treatment:phase:hour 7.19, 35.96  2.67      0.35 .009    .930\n14           gender:phase:hour 3.60, 35.96  2.67      0.93 .012    .449\n15 treatment:gender:phase:hour 7.19, 35.96  2.67      0.74 .019    .646\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n\n\nCongrats! You’ve just run a 2x2 mixed effects ANOVA! We’ll revisit what exactly is going on here in about 10 weeks."
  },
  {
    "objectID": "week01/1_5-leveling-up.html#downloading-and-saving-data-from-the-web",
    "href": "week01/1_5-leveling-up.html#downloading-and-saving-data-from-the-web",
    "title": "Leveling-up",
    "section": "Downloading and saving data from the web",
    "text": "Downloading and saving data from the web\nThe example above just pulls data directly from a url, what if you want to download the data file directly onto your computer and load it from there?\nWell, there’s a package for that… downloader. Let’s install this package and download the data from above. Also, check out the additional notation in the code below:\n\n# within the R code sections, hashtags create comments, sections of code \n# that are not interpreted by the computer, but may serve to inform others \n# (and typically yourself later in life) about what exactly in the hell is\n# going on here. GET IN THE PRACTICE OF COMMENTING YOUR CODE. You'll thank\n# yourself later. I can't count how many times I've written code only \n# to come back to it months later wondering what in the hell I was \n# doing, thinking!!\n\n# Here I'm using comments to inform you step-by-step \n# what each line is doing:\n\n# install and load \"downloader\" package, this assumes you \n# have \"pacman\" installed and loaded *see section above:\npacman::p_load(downloader)\n\n# get the url of the file you want to download and assign it \n# to an object (\"dataURL\"):\ndataURL <- \"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab2-1.dat\"\n\n# decide on what name you want to give the file. In this case I'm extracting\n# using the basename from the web url: Tab2-1.dat. In truth you \n# can name it whatever you want (see commented example)\n\nfilename <- basename(dataURL)\n#filename <- \"you_can_name_it_what_you_like.txt\"\n\n# download the file to your current R-project folder:\ndownload(url = dataURL, filename)\n\nKeep in mind that objects are just placeholders. So if I was so inclined I could have accomplished all of the above with just one line:\n\ndownload(url = \"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab2-1.dat\", destfile=\"Tab2-1.dat\")\n\n# destfile is a parameter for naming what you download.\n\nFrom here I could just import the Tab2-1.dat file from my computer using the GUI method above."
  },
  {
    "objectID": "week07/7_3-power_es_sig_tests.html",
    "href": "week07/7_3-power_es_sig_tests.html",
    "title": "Power, Effect sizes, and Significance testing",
    "section": "",
    "text": "pacman::p_load(tidyverse, \n               cowplot, \n               glue) # for gluing strings of text together\nBoth power and effect size are defined as related to estimates of \\(\\mu\\) & \\(\\sigma\\)—means and standard deviation units. However, as we saw two weeks ago with our t-test, significance is evaluated in terms of standard error units. As we’ve often noted and reiterated above standard error is influenced by the size of your sample. In comparison, for any given sample the mean and standard deviation that you observe are entirely by chance. Simply put, the values that we use to estimate effect size are independent of the values that we use to test for significance. This is why even though an effect might be statistically significant, it may not be meaningfully / clinically significant. We may have over-amplified a relatively weak original signal by over-powering our study (e.g., getting way more participants than necessary).\nLet’s look at an example assuming a medium effect size. Imagine this is whats going on at the level of the population.\nNow imagine going out an collecting data from this population given samples of different sizes. Note that the width of the curves here capture standard error.\nWhat do you notice about the figures below?"
  },
  {
    "objectID": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-12",
    "href": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-12",
    "title": "Power, Effect sizes, and Significance testing",
    "section": "Significance Test when N = 12",
    "text": "Significance Test when N = 12"
  },
  {
    "objectID": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-24",
    "href": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-24",
    "title": "Power, Effect sizes, and Significance testing",
    "section": "Significance Test when N = 24",
    "text": "Significance Test when N = 24"
  },
  {
    "objectID": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-48",
    "href": "week07/7_3-power_es_sig_tests.html#significance-test-when-n-48",
    "title": "Power, Effect sizes, and Significance testing",
    "section": "Significance Test when N = 48",
    "text": "Significance Test when N = 48\n\n\n\n\n\nYou will notice the area of \\(1-\\beta\\) increases because as we add to the sample size, the curve (noise) gets thinner (SEM), but the distance between them does not change! This effect size is theoretically independent of significance testing as its simply based on the mean difference / standard deviation. If you know the true standard deviation (\\(\\sigma\\)) then this is a true statement. However, we never know the true standard deviation so we approximate it based on sample. So our observed estimate of effect size from experimental data is another guess based on the variation due to chance. Because of this we cannot tie effect size to p-value.\nTo demonstrate this, let’s revisit the Hand et al data this time reducing the size of the effect. Again regarding Hand:\n\nHand, et al., 1994, reported on family therapy as a treatment for anorexia. There were 17 girls in this experiment, and they were weighed before and after treatment. The weights of the girls, in pounds, is provided in the data below:\n\n\nanorexia_data <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Tab7-3.dat\", \n                     \"\\t\", escape_double = FALSE, trim_ws = TRUE)\n\nRows: 17 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): ID\ndbl (2): Before, After\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# reducing the effect (minimizing difference)\nanorexia_data <- anorexia_data %>% \n  mutate(After = After - 6) \n\n# putting in long format\nanorexia_data <- pivot_longer(data = anorexia_data,cols = c(Before,After),names_to = \"Treatment\",values_to = \"Weight\")\n\nSo what is known: we have 17 total participants from (hypothetically) the same population that are measured twice (once Before treatment, and once After treatment). Based upon the experimental question we need to run a paired-sample (matched-sample) test.\n\nt.test(Weight~Treatment, data=anorexia_data, paired=T)\n\n\n    Paired t-test\n\ndata:  Weight by Treatment\nt = 0.72773, df = 16, p-value = 0.4773\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.419429  4.948840\nsample estimates:\nmean difference \n       1.264706 \n\npacman::p_load(effectsize)\neffectsize::cohens_d(Weight~Treatment, data=anorexia_data, paired = T,correction = T)\n\nCohen's d |        95% CI\n-------------------------\n0.18      | [-0.31, 0.65]\n\n\nSo on first pass we’ve got a null effect (\\(p>.05\\)) and our effect size is small (0.16). Let’s image that instead of 17 participants we had 170:\n\nanorexia_data_170 <- do.call(\"rbind\", replicate(10, anorexia_data, simplify = FALSE))\n\n\nt.test(Weight~Treatment, data=anorexia_data_170, paired=T)\n\n\n    Paired t-test\n\ndata:  Weight by Treatment\nt = 2.3651, df = 169, p-value = 0.01916\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2090925 2.3203193\nsample estimates:\nmean difference \n       1.264706 \n\npacman::p_load(effectsize)\neffectsize::cohens_d(Weight~Treatment, data=anorexia_data, paired = T,correction = T)\n\nCohen's d |        95% CI\n-------------------------\n0.18      | [-0.31, 0.65]\n\n\nWe see our effect size remains unchanged, but now our test is significant!"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html",
    "href": "week08/8_1-one-way-anova.html",
    "title": "The One-way ANOVA",
    "section": "",
    "text": "This week we covered ANOVA. A major emphasis in the material (especially Winter’s optional text) is that ANOVA (much like many of the other tests that we cover in this course) is an extension of the general linear model. In many respects, ANOVA and regression are conceptually identical—whereas in linear regression our predictor variables are typically continuous (or, in some cases ordinal) we usually reserve the term ANOVA for instances when our predictors are discrete or nominal (although it really need not be). This would be the difference say in predicting weight as a function of height (linear regression) in contrast to weight as function of hometown (Dayton, Youngstown, Cleveland, Cincinnati). Given that the assigned readings (and the optional Winter text) do a wonderful job of explaining the underlying principles of ANOVA, I won’t spend too much time here rehashing what is already available there. Both the Flora text and the Winter text, especially does an excellent job of demonstrating how even though regression and ANOVA are often treated differently in terms of research focus (e.g., observation v. experimentation) and data focus (correlation/goodness of fit v. comparing means) they are indeed one and the same. Here, my goal is to reinforce this idea using examples in R, as well as providing a practical tutorial that will serve as our entry point into ANOVA.\nWe typically understand ANOVA as a method for allowing us to compare means from more than two samples. To see how this connects with what we have learned from regression lets use an example dataset. Before proceeding, this walk-through assumes that you have the following packages installed and loaded in R:\n\npacman::p_load(car,\n               cowplot, \n               tidyverse,\n               psych)"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#the-data",
    "href": "week08/8_1-one-way-anova.html#the-data",
    "title": "The One-way ANOVA",
    "section": "The data",
    "text": "The data\nTo start, lets download Eysenck’s (1974) study on verbal recall and levels of processing. As described in Howell (2012):\n\nCraik and Lockhart (1972) proposed as a model of memory that the degree to which verbal material is remembered by the subject is a function of the degree to which it was processed when it was initially presented. Thus, for example, if you were trying to memorize a list of words, repeating a word to yourself (a low level of processing) would not lead to as good recall as thinking about the word and trying to form associations between that word and some other word. Eysenck (1974) was interested in testing this model and, more important, in looking to see whether it could help to explain reported differences between young and old subjects in their ability to recall verbal material…\nEysenck randomly assigned 50 subjects between the ages of 55 and 65 years to one of five groups—four incidental-learning groups and one intentional-learning group. (Incidental learning is learning in the absence of the expectation that the material will later need to be recalled.) The Counting group was asked to read through a list of words and simply count the number of letters in each word. This involved the lowest level of processing, because subjects did not need to deal with each word as anything more than a collection of letters. The Rhyming group was asked to read each word and think of a word that rhymed with it. This task involved considering the sound of each word, but not its meaning. The Adjective group had to process the words to the extent of giving an adjective that could reasonably be used to modify each word on the list. The Imagery group was instructed to try to form vivid images of each word. This was assumed to require the deepest level of processing of the four incidental conditions. None of these four groups were told that they would later be asked for recall of the items. Finally, the Intentional group was told to read through the list and to memorize the words for later recall. After subjects had gone through the list of 27 items three times, they were given a sheet of paper and asked to write down all of the words they could remember. If learning involves nothing more than being exposed to the material (the way most of us read a newspaper or, heaven forbid, a class assignment), then the five groups should have shown equal recall—after all, they all saw all of the words. If the level of processing of the material is important, then there should have been noticeable differences among the group means.\n\nWe can download this dataset using the following code:\n\ndataset <- read_delim(\"https://www.uvm.edu/~statdhtx/methods8/DataFiles/Ex11-1.dat\", \n                      delim = \"\\t\")\n\nRows: 50 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (2): GROUP, RECALL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nshow(dataset)\n\n# A tibble: 50 × 2\n   GROUP RECALL\n   <dbl>  <dbl>\n 1     1      9\n 2     1      8\n 3     1      6\n 4     1      8\n 5     1     10\n 6     1      4\n 7     1      6\n 8     1      5\n 9     1      7\n10     1      7\n# ℹ 40 more rows"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#getting-the-data-in-order",
    "href": "week08/8_1-one-way-anova.html#getting-the-data-in-order",
    "title": "The One-way ANOVA",
    "section": "Getting the data in order",
    "text": "Getting the data in order\nAlthough the focus for this course is conceptual and applied knowledge of statistics, I again want to be mindful of the practice of data analysis. That is, in the real world, you’ll be asked to do some data wrangling, or getting your data in the right format and containing the right information to properly proceed with analysis. When looking at this data, two important things jump out that we might want to address: (1) there is no column indicating participant ID. and (2) the data is numerically coded. A little bit about each of these points.\nThe importance of a participant ID column\nDepending on what statistical software you use, including a Participant ID column varies in its importance. For building statistical models in R that involve categorical data, including designs that that test within and across subjects making sure that you have Participant IDs coded is vitally important. Ideally this will already be done before you import your data, but on the case that it’s not you need to add a column specifying participant ID. How you do this will depend on what format your data is in (Wide v. Long) and whether you have a repeated-measures design (multiple measures from each participant).\n** I grant that it might be useful to use you Excel ninja skills here and get everything in its right place before importing, but will assume that you want to stay in an R environment.\nIn this case, our data is in long format and we have a between subjects design. That is every line represents a single measure of a participant and every participant is represented only once. In this case we can just assign a unique number to each participant / row. In most cases this is a simple as assigning participant numbers {1,2,3…n}. An easy way to do this is to use the seq_along() function. The seq_along() function simply says to create numbers in sequence that match along a vector. In this case we can seq_along the GROUP column (vector).\n\ndataset <- dataset %>% mutate(PartID = seq_along(dataset$GROUP))\ndataset\n\n# A tibble: 50 × 3\n   GROUP RECALL PartID\n   <dbl>  <dbl>  <int>\n 1     1      9      1\n 2     1      8      2\n 3     1      6      3\n 4     1      8      4\n 5     1     10      5\n 6     1      4      6\n 7     1      6      7\n 8     1      5      8\n 9     1      7      9\n10     1      7     10\n# ℹ 40 more rows\n\n\nFWIW, if you have the same compulsion that I do and insist that your PartID column is first in your dataset this can be solved using select. Here, I’m saying put PartID first and then follow it with everything() else.\n\ndataset <- dataset %>% select(PartID, everything())\n\nOK. That’s addressed. Now onto issue #2.\nRecoding the factors (if number coded)\nAs we can see the data is number coded. In this case,\n\n1 = ‘Counting’,\n2 = ‘Rhyming’,\n3 = ‘Adjective’,\n4 = ‘Imagery’ and\n5 = ‘Intentional’\n\nMy advice for what to do if you get dummy coded data is to create a corresponding column in your data set that contains the factors in nominal (name) format.\nRecall from previous weeks that we can use the recode() and recode_factor()functions to reassign the number variables. Here, we are recoding the levels of a factor, so the preferred function is recode_factor(). When we recode_factor() we have the added benefit of automatically factorizing, telling R to treat the IV as a factor. Let’s create a new column dataset$GROUP_FACTOR that contains this data:\n\n# assigning the appropriate names for the dummy codes\ndataset <- dataset %>% \n  mutate(GROUP_FACTOR = dplyr::recode_factor(GROUP, \n                                             \"1\" = \"Counting\",\n                                             \"2\"=\"Rhyming\",\n                                             \"3\"=\"Adjective\",\n                                             \"4\"=\"Imagery\",\n                                             \"5\"=\"Intentional\"\n                                             )\n  )\n\nRenaming column headers (optional)\nAnd now, just to be clear, let’s rename the original GROUP to GROUP_NUM. This can be accomplished by using the dplyr::rename() function.\n\n# The template is rename(NEW_NAME = OLD_NAME)\ndataset <- dataset %>% dplyr::rename(GROUP_NUM = GROUP)\n\nCheck out this link for info on how to rename multiple columns at once using names() or dplyr::rename() from the tidyverse.\nReordering your levels\nOne important question you should ask before you look at your data is “what is your control (group, condition)”. Proper experimentation requires a proper control in order to properly isolate the influence of the manipulation (that’s a lot of propers). Here, the best candidates for our control group might either be “Counting” or “Intentional”, depending on how the original problem was approached. If the larger comparison involved “Intentional v. incidental” learning for recall, then the “Intentional” group serves best as your control. If the original question involved levels of processing, then “Counting”” (theoretically the lowest level of incidental processing) is best. Here I am assuming the latter (although I believe theoretically Eysenck originally was interested in the former).\nI bring this up, as its typically best to ensure that your control is entered first into the ANOVA model. To check the order of your levels, you may simply:\n\nlevels(dataset$GROUP_FACTOR)\n\n[1] \"Counting\"    \"Rhyming\"     \"Adjective\"   \"Imagery\"     \"Intentional\"\n\n\nHere we see that “Counting” is first and will therefore be entered first into the model.\nAssuming that we wanted to reorder the sequence, say to have Intentional as the control, then we might simply use fct_relevel():\n\ndataset <- dataset %>% \n  mutate(GROUP_FACTOR = fct_relevel(GROUP_FACTOR, \"Intentional\"))\n                              \nlevels(dataset$GROUP_FACTOR)\n\n[1] \"Intentional\" \"Counting\"    \"Rhyming\"     \"Adjective\"   \"Imagery\"    \n\n\nNote that with fct_relevel() whatever level(s) I list get moved to the front of the line. In this case I just bumped Intentional up while keeping the remaining levels ordered the same.\nHowever, I liked the original order, so let’s change it back:\n\ndataset <- dataset %>% \n  mutate(GROUP_FACTOR = fct_relevel(GROUP_FACTOR, \n                                    \"Counting\", \n                                    \"Rhyming\", \n                                    \"Adjective\", \n                                    \"Imagery\", \n                                    \"Intentional\"))\n\nlevels(dataset$GROUP_FACTOR)\n\n[1] \"Counting\"    \"Rhyming\"     \"Adjective\"   \"Imagery\"     \"Intentional\"\n\n\nThat’s better. Why the order is important will be made clear later in this write up. For now, think back to our example in class of running a t-test using lm(). You may recall that the group level that was first entered into the model served as the model intercept where the second group level was expressed in terms of the slope of the line (beta). A similar output will be happening here.\nSo the data structure looks good.\nOne last little bit of ninja-ing. If you wanted to save a particular R object to be used later on you can use the write_rds() function (from tidyverse). I’m going to save dataset as I’ve cleaned it up so that I can use it in the next walkthrough.\n\nwrite_rds(dataset,'clean_dataset.rds')\n\nOnward to the analysis!!!!"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#assumptions-for-anova",
    "href": "week08/8_1-one-way-anova.html#assumptions-for-anova",
    "title": "The One-way ANOVA",
    "section": "Assumptions for ANOVA",
    "text": "Assumptions for ANOVA\nChecking the normality assumption, OPTION 1 raw data by group\nTo check the distribution of outcomes in ANOVA, you have two options. The first would be to check the distribution of outcomes for EACH group/condition independently. In the case of the example dataset we could get info related to the skew and kurtosis of RECALL for each GROUP_FACTOR using describeBy():\n\npsych::describeBy(dataset,group = \"GROUP_FACTOR\")\n\n\n Descriptive statistics by group \nGROUP_FACTOR: Counting\n              vars  n mean   sd median trimmed  mad min max range skew kurtosis\nPartID           1 10  5.5 3.03    5.5     5.5 3.71   1  10     9    0    -1.56\nGROUP_NUM        2 10  1.0 0.00    1.0     1.0 0.00   1   1     0  NaN      NaN\nRECALL           3 10  7.0 1.83    7.0     7.0 1.48   4  10     6    0    -1.22\nGROUP_FACTOR*    4 10  1.0 0.00    1.0     1.0 0.00   1   1     0  NaN      NaN\n                se\nPartID        0.96\nGROUP_NUM     0.00\nRECALL        0.58\nGROUP_FACTOR* 0.00\n------------------------------------------------------------ \nGROUP_FACTOR: Rhyming\n              vars  n mean   sd median trimmed  mad min max range skew kurtosis\nPartID           1 10 15.5 3.03   15.5   15.50 3.71  11  20     9 0.00    -1.56\nGROUP_NUM        2 10  2.0 0.00    2.0    2.00 0.00   2   2     0  NaN      NaN\nRECALL           3 10  6.9 2.13    6.5    6.88 0.74   3  11     8 0.18    -0.40\nGROUP_FACTOR*    4 10  2.0 0.00    2.0    2.00 0.00   2   2     0  NaN      NaN\n                se\nPartID        0.96\nGROUP_NUM     0.00\nRECALL        0.67\nGROUP_FACTOR* 0.00\n------------------------------------------------------------ \nGROUP_FACTOR: Adjective\n              vars  n mean   sd median trimmed  mad min max range  skew\nPartID           1 10 25.5 3.03   25.5   25.50 3.71  21  30     9  0.00\nGROUP_NUM        2 10  3.0 0.00    3.0    3.00 0.00   3   3     0   NaN\nRECALL           3 10 11.0 2.49   11.0   11.25 2.97   6  14     8 -0.66\nGROUP_FACTOR*    4 10  3.0 0.00    3.0    3.00 0.00   3   3     0   NaN\n              kurtosis   se\nPartID           -1.56 0.96\nGROUP_NUM          NaN 0.00\nRECALL           -0.84 0.79\nGROUP_FACTOR*      NaN 0.00\n------------------------------------------------------------ \nGROUP_FACTOR: Imagery\n              vars  n mean   sd median trimmed  mad min max range skew kurtosis\nPartID           1 10 35.5 3.03   35.5   35.50 3.71  31  40     9 0.00    -1.56\nGROUP_NUM        2 10  4.0 0.00    4.0    4.00 0.00   4   4     0  NaN      NaN\nRECALL           3 10 13.4 4.50   11.5   12.75 1.48   9  23    14 0.99    -0.53\nGROUP_FACTOR*    4 10  4.0 0.00    4.0    4.00 0.00   4   4     0  NaN      NaN\n                se\nPartID        0.96\nGROUP_NUM     0.00\nRECALL        1.42\nGROUP_FACTOR* 0.00\n------------------------------------------------------------ \nGROUP_FACTOR: Intentional\n              vars  n mean   sd median trimmed  mad min max range skew kurtosis\nPartID           1 10 45.5 3.03   45.5    45.5 3.71  41  50     9 0.00    -1.56\nGROUP_NUM        2 10  5.0 0.00    5.0     5.0 0.00   5   5     0  NaN      NaN\nRECALL           3 10 12.0 3.74   11.0    12.0 2.97   5  19    14 0.05    -0.47\nGROUP_FACTOR*    4 10  5.0 0.00    5.0     5.0 0.00   5   5     0  NaN      NaN\n                se\nPartID        0.96\nGROUP_NUM     0.00\nRECALL        1.18\nGROUP_FACTOR* 0.00\n\n\nIf we wanted to perform for extensive methods like hist(), qqPlot(), and shapiro.test(), in the past I had you filter be each level (group) and proceed. So for example for Counting:\n\ncountingGroup <- filter(dataset,GROUP_FACTOR==\"Counting\")\n\nhist(countingGroup$RECALL)\n\n\n\nqqPlot(countingGroup$RECALL)\n\n\n\n\n[1] 6 5\n\nshapiro.test(countingGroup$RECALL)\n\n\n    Shapiro-Wilk normality test\n\ndata:  countingGroup$RECALL\nW = 0.98372, p-value = 0.9819\n\n\nIn the past you would have to repeat this for each other level. An alternative to generate an output by each level of a factor is to use the by() function. For example to generate a sequence of qqPlots (for the sake of space I’m not going to execute this code here, but try on your computer)\n\n# by(dependent variable, grouping factor, name of function)\nby(dataset$RECALL,INDICES = dataset$GROUP_FACTOR,qqPlot)\n\nYou can do the same with hist() and shapiro.test()\n\nby(dataset$RECALL,INDICES = dataset$GROUP_FACTOR,hist)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset$GROUP_FACTOR: Counting\n$breaks\n[1]  4  5  6  7  8  9 10\n\n$counts\n[1] 2 2 2 2 1 1\n\n$density\n[1] 0.2 0.2 0.2 0.2 0.1 0.1\n\n$mids\n[1] 4.5 5.5 6.5 7.5 8.5 9.5\n\n$xname\n[1] \"dd[x, ]\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Rhyming\n$breaks\n[1]  2  4  6  8 10 12\n\n$counts\n[1] 1 4 3 1 1\n\n$density\n[1] 0.05 0.20 0.15 0.05 0.05\n\n$mids\n[1]  3  5  7  9 11\n\n$xname\n[1] \"dd[x, ]\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Adjective\n$breaks\n[1]  6  8 10 12 14\n\n$counts\n[1] 2 1 3 4\n\n$density\n[1] 0.10 0.05 0.15 0.20\n\n$mids\n[1]  7  9 11 13\n\n$xname\n[1] \"dd[x, ]\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Imagery\n$breaks\n[1]  8 10 12 14 16 18 20 22 24\n\n$counts\n[1] 2 5 0 1 0 1 0 1\n\n$density\n[1] 0.10 0.25 0.00 0.05 0.00 0.05 0.00 0.05\n\n$mids\n[1]  9 11 13 15 17 19 21 23\n\n$xname\n[1] \"dd[x, ]\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Intentional\n$breaks\n[1]  4  6  8 10 12 14 16 18 20\n\n$counts\n[1] 1 0 2 3 2 1 0 1\n\n$density\n[1] 0.05 0.00 0.10 0.15 0.10 0.05 0.00 0.05\n\n$mids\n[1]  5  7  9 11 13 15 17 19\n\n$xname\n[1] \"dd[x, ]\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\nby(dataset$RECALL,INDICES = dataset$GROUP_FACTOR,shapiro.test)\n\ndataset$GROUP_FACTOR: Counting\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.98372, p-value = 0.9819\n\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Rhyming\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.93024, p-value = 0.4502\n\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Adjective\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.90607, p-value = 0.2551\n\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Imagery\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.81967, p-value = 0.02511\n\n------------------------------------------------------------ \ndataset$GROUP_FACTOR: Intentional\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.94339, p-value = 0.5913\n\n\nand even our custom standardized skew and kurtosis functions.\nChecking the normality assumption, OPTION 2, the better way: Look at the residuals.\nAlthough by() may or may not make life easier for you in this test case, things rapidly become more complicated when attempting to check normality by condition. For example if you’re running a 2×3×3 mixed effect ANOVA, you would need to run through 18 conditions!!! So what to do?!?!?!\nA simpler alternative is to run you model and analyze your residuals. This web link does a nice and quick job of explaining the logic.\nIn this case we would run our ANOVA model using lm (see told you its all the same)\n\ndataset_aov <- lm(RECALL~GROUP_FACTOR, data=dataset)\n\nCongrats, you’ve just run an ANOVA, but for now we aren’t interested in the results from the model. Remember from a few weeks back that many outputs have attributes that may be accessed. In this case, we want the models residuals. These can be accessed by\n\nresid(dataset_aov)\n\n            1             2             3             4             5 \n 2.000000e+00  1.000000e+00 -1.000000e+00  1.000000e+00  3.000000e+00 \n            6             7             8             9            10 \n-3.000000e+00 -1.000000e+00 -2.000000e+00  5.551115e-17  5.551115e-17 \n           11            12            13            14            15 \n 1.000000e-01  2.100000e+00 -9.000000e-01 -9.000000e-01 -9.000000e-01 \n           16            17            18            19            20 \n 4.100000e+00 -9.000000e-01 -3.900000e+00  1.100000e+00  1.000000e-01 \n           21            22            23            24            25 \n 5.551115e-17  2.000000e+00 -3.000000e+00 -5.000000e+00  3.000000e+00 \n           26            27            28            29            30 \n 5.551115e-17  2.000000e+00  2.000000e+00 -1.000000e+00  5.551115e-17 \n           31            32            33            34            35 \n-1.400000e+00 -2.400000e+00  2.600000e+00 -2.400000e+00 -4.400000e+00 \n           36            37            38            39            40 \n 9.600000e+00 -1.400000e+00 -3.400000e+00  5.600000e+00 -2.400000e+00 \n           41            42            43            44            45 \n-2.000000e+00  7.000000e+00  2.000000e+00 -7.000000e+00 -2.000000e+00 \n           46            47            48            49            50 \n-1.000000e+00  2.000000e+00  3.000000e+00 -1.000000e+00 -1.000000e+00 \n\n\nFrom here, we can simply take the residuals (as we did with regression) and submit them to our standard tests for normality. For example, testing skew, and kurtosis:\n\nresid(dataset_aov) %>% skew()\n\n[1] 0.6388343\n\nresid(dataset_aov) %>% kurtosi()\n\n[1] 1.221947\n\n\nor submit the entire model diagnostic plots:\n\npacman::p_load(performance)\n\nperformance::check_model(dataset_aov)\n\n\n\n\nSo, between OPTION 1 and OPTION 2, I’d recommend typically going with OPTION 2. Especially as your ANOVA designs become more complex.\nWALKTHROUGH PROBLEM: Run the requisite tests for normality using the residuals from dataset_aov\n\nHomogeneity of Variance\nAnother assumption of ANOVA is the homogeneity of variance between groups. An easy-way to get an eyeball test of this assumption is two perform a box plot of the data. Here I am performing this plot using ggplot2:\n\nggplot(data =dataset, aes(x=GROUP_FACTOR,y=RECALL)) +\n  geom_boxplot()\n\n\n\n\nHuge differences in the IQR regions may be a clue that the homogeneity assumption is violated. We can run more specific tests in R including the Levene Test and Fligner-Killeen Test of Homogeneity of Variances. You are familiar with the Levene Test from a few weeks ago. The Figner-Killeen Test is offered as an alternative if you are concerned with violations of the normality assumption.\nAs is typically the case \\(p<.05\\) indicates a violation of this assumption:\n\n# Levene Test of Homogeneity of Variances\ncar::leveneTest(RECALL~GROUP_FACTOR, data=dataset)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  4  0.8932 0.4759\n      45               \n\n# Fligner-Killeen Test of Homogeneity of Variances\nfligner.test(RECALL~GROUP_FACTOR, data=dataset)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  RECALL by GROUP_FACTOR\nFligner-Killeen:med chi-squared = 1.9733, df = 4, p-value = 0.7407\n\n\nWhat to do if the assumptions are violated?\nIf either assumption is violated, one option that you have is to transform you data. We’ve talked several times in class about the pros and cons of doing this, and there are several resources that provide examples of how this is done. Another option is to use a non-parametric test such as the Kruskal-Wallis Test if the data is not normal, or Welch’s ANOVA is the variances are not homogeneous. That said, one of reasons that ANOVA is so popular is that it has been demonstrated to be robust in the face of violated assumptions (as long as the sample sizes are equal). For example, in Design and Analysis of Experiments (1999, p. 112) Dean & Voss argue that the maximum group variance may be as high as 3× the minimum group variance without any issue. With this in mind, a question (gray area) before us is how much of a violation is there in the data? And if not so much, you may be fine just running an ANOVA regardless."
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#running-the-anova-in-r-using-aov-or-lm",
    "href": "week08/8_1-one-way-anova.html#running-the-anova-in-r-using-aov-or-lm",
    "title": "The One-way ANOVA",
    "section": "Running the ANOVA in R using aov() or lm()\n",
    "text": "Running the ANOVA in R using aov() or lm()\n\nThere are many, many ways to build an ANOVA model in R. Throughout the semester we will be highlighting three: lm(), aov(), and using the afex package. This week we will concentrate on aov() which is the standard method, as well as the lm() method that you have used before, just to reinforce that ANOVA and regression are one in the same. In fact, SPOILER ALERT, aov() is just a fancy wrapper for lm(), AND FWIW I don’t really like using aov(). I only mention it here as if you go looking for how to run ANOVA in R online, many sites will say use aov().\nLike lm() from weeks past, aov() asks us to enter our dependent and independent variables into the model in the formula format DV ~ IVs. In this case, we only have a single IV, GROUP_FACTOR. Thus our model is:\n\naov.model <- aov(RECALL~GROUP_FACTOR,data = dataset)\n\nFrom here, an anova() of the model gives us our ANOVA table. Note that car::Anova() accomplished the same thing, though gives us a different format. The added benefit is that if we so choose, we can change how our Sums of Squares are calculated. This isn’t important for simple One-way ANOVA, but see the Field text, Jane Superbrain 11.1 for an explanation.\n\nanova(aov.model)\n\nAnalysis of Variance Table\n\nResponse: RECALL\n             Df Sum Sq Mean Sq F value    Pr(>F)    \nGROUP_FACTOR  4 351.52  87.880  9.0848 1.815e-05 ***\nResiduals    45 435.30   9.673                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncar::Anova(aov.model, type=\"3\")\n\nAnova Table (Type III tests)\n\nResponse: RECALL\n             Sum Sq Df F value    Pr(>F)    \n(Intercept)  490.00  1 50.6547 6.831e-09 ***\nGROUP_FACTOR 351.52  4  9.0848 1.815e-05 ***\nResiduals    435.30 45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAlso note that we can get residuals from the aov() output as well. In fact take a look at the object’s $class… see I told you, lm()!!!\n\nresid(aov.model)\n\n            1             2             3             4             5 \n 2.000000e+00  1.000000e+00 -1.000000e+00  1.000000e+00  3.000000e+00 \n            6             7             8             9            10 \n-3.000000e+00 -1.000000e+00 -2.000000e+00  5.551115e-17  5.551115e-17 \n           11            12            13            14            15 \n 1.000000e-01  2.100000e+00 -9.000000e-01 -9.000000e-01 -9.000000e-01 \n           16            17            18            19            20 \n 4.100000e+00 -9.000000e-01 -3.900000e+00  1.100000e+00  1.000000e-01 \n           21            22            23            24            25 \n 5.551115e-17  2.000000e+00 -3.000000e+00 -5.000000e+00  3.000000e+00 \n           26            27            28            29            30 \n 5.551115e-17  2.000000e+00  2.000000e+00 -1.000000e+00  5.551115e-17 \n           31            32            33            34            35 \n-1.400000e+00 -2.400000e+00  2.600000e+00 -2.400000e+00 -4.400000e+00 \n           36            37            38            39            40 \n 9.600000e+00 -1.400000e+00 -3.400000e+00  5.600000e+00 -2.400000e+00 \n           41            42            43            44            45 \n-2.000000e+00  7.000000e+00  2.000000e+00 -7.000000e+00 -2.000000e+00 \n           46            47            48            49            50 \n-1.000000e+00  2.000000e+00  3.000000e+00 -1.000000e+00 -1.000000e+00 \n\n\nEven better, a more comprehensive anova table can be obtained by submitting our aov.model to sjstats::anova_stats(), which gives us our effect sizes as well! This function calculates eta-squared (\\(\\eta^2\\)), partial-eta-squared (\\(\\eta_p^2\\)), omega squared (\\(\\omega^2\\)) and partial omega-squared (\\(\\omega_p^2\\)) as well as Cohen’s f. Typically for One-Way ANOVA psychologists report eta-squared (\\(\\eta^2\\)), though there are arguments that omega squared (\\(\\omega^2\\)) may be the more preferred measure. Note that pander is for web formatting this page.\n\npacman::p_load(pander)\npacman::p_load(sjstats)\nsjstats::anova_stats(aov.model) %>% pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n \nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nGROUP_FACTOR\nGROUP_FACTOR\n4\n351.5\n87.88\n9.085\n0\n\n\n…2\nResiduals\n45\n435.3\n9.673\nNA\nNA\n\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n \netasq\npartial.etasq\nomegasq\npartial.omegasq\n\n\n\nGROUP_FACTOR\n0.447\n0.447\n0.393\n0.393\n\n\n…2\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\n \nepsilonsq\ncohens.f\npower\n\n\n\nGROUP_FACTOR\n0.398\n0.899\n0.999\n\n\n…2\nNA\nNA\nNA"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#plotting-your-data",
    "href": "week08/8_1-one-way-anova.html#plotting-your-data",
    "title": "The One-way ANOVA",
    "section": "Plotting your data",
    "text": "Plotting your data\nFor publication quality ANOVA plots, there are typically three acceptable plots used to convey your results, box plots, bar plots, and line plots. As the ANOVA become more complex, we tend towards using line plots (box plots and bar plots may become very busy in complex designs). Unless there are other compelling reasons we tend to plot the means (although note that box plots usually give you medians). Since you have already produced box plots and barplots, I’ll show examples of how to do a line plot.\nTo create a line plot with points at the means and error lines representing the 95% CI (known as a point range), we can use call that you are familiar with and a new geom pointrange. Whats nice about point range is that it allows you to create your points and the error bars all in a single line.\n\nggplot2::ggplot(data =dataset,mapping = aes(x = GROUP_FACTOR, y = RECALL)) +\n  stat_summary(fun.data = mean_cl_normal, \n               size=1, \n               color=\"black\", \n               geom=\"pointrange\")\n\n\n\n\nNow to add the lines to this plot. For this you will need another stat_summary() line specifying that the vertices of the lines should be the means, fun = mean and a parameter that specifies how the lines should be grouped. Since we have a One-way ANOVA, group=1. When we built to more complex designs you may elect to group=FACTOR_NAME. Something like this is useful to say make some lines dashed and some lines solid according to levels on a factor. More on this in two weeks when we get to factorial ANOVA.\nWhile we’re at it let’s fix those axes titles. We can use the functions xlab() and ylab() to do so.\n\n# this is from before, saving as object \"p\"\np <- ggplot2::ggplot(data =dataset,mapping = aes(x = GROUP_FACTOR, y = RECALL)) +\n  stat_summary(fun.data = mean_cl_normal, \n               size=1, \n               color=\"black\", \n               geom=\"pointrange\") +\n  # adding lines\n  stat_summary(fun = mean, \n               size = 1, \n               color = \"black\", \n               mapping=aes(group=1), \n               geom=\"line\") +\n  # and fixing the axis titles:\n  xlab(\"Group\")+ylab(\"Words recalled\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nshow(p)\n\n\n\n\nFinally, for aesthetic reasons you may elect to expand the y-axis. For example to make the range of y-axis values (0,20):\n\np + expand_limits(y=c(0,20))\n\n\n\n\nThat being said, this data probably lends itself to a bar plot. This is similar to how you built your bar plots from as when doing a t-test. As a matter of fact:\nWALKTHROUGH PROBLEM: Create a bar plot with error bars for our dataset."
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#reporting-your-data-the-write-up",
    "href": "week08/8_1-one-way-anova.html#reporting-your-data-the-write-up",
    "title": "The One-way ANOVA",
    "section": "Reporting your data / the write up",
    "text": "Reporting your data / the write up\nThere are two components to reporting your omnibus ANOVA. First, You need to report your output as related to the test:\n\n\nthe F value,\n\nthe degrees of freedom (between and within),\nthe p-value\n\neffect size: typically with between-effects ANOVA we report eta squared, although note that Howell advocates for omega squared. Recall that submitting the model to sjstats::anova_stats() gives you both.\n\nSecond, as we typically focus on means with ANOVA, it is typically a good idea to report means and some report of of the distribution of each group (typically either standard deviation or standard error; although 95% CI may be useful in certain scenarios).\nSo for example reporting the Rhyming group:\n\n\nM ± SD: 6.90 ± 2.13\n\nM ± SE: 6.90 ± 0.67"
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#what-the-omnibus-anova-tells-you",
    "href": "week08/8_1-one-way-anova.html#what-the-omnibus-anova-tells-you",
    "title": "The One-way ANOVA",
    "section": "What the omnibus ANOVA tells you",
    "text": "What the omnibus ANOVA tells you\nWhile it may be useful to report the means, you need to be mindful of what the omnibus ANOVA tells you. Remember, that the the null hypothesis of the omnibus ANOVA is that “there are no differences between observed means”. Our significant result tells us that there are differences between our means, but does not tell us what those specific differences are. So while it may be useful to report general relationships, e.g., “Recall for people in the Intentional group tended to be greater than for the Counting group” you cannot say definitively “Recall was significantly greater for the Intentional Group”. Typically when you only have tested the omnibus ANOVA, you only speak in generalities (e.g., “Recall tended to increase with level of processing.”)\nAlways be mindful that you don’t over interpret your data."
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#running-an-anova-using-lm-its-a-regression-afterall",
    "href": "week08/8_1-one-way-anova.html#running-an-anova-using-lm-its-a-regression-afterall",
    "title": "The One-way ANOVA",
    "section": "Running an ANOVA using lm() (it’s a regression afterall)",
    "text": "Running an ANOVA using lm() (it’s a regression afterall)\nNow that we’ve got practical matters out of the way, I want to take some time to dig a little deeper into the connections between ANOVA this week and our work on correlations and regressions in the past.\nAs we’ve already mentioned (and spent time discussing in class) ANOVA is just an extension of the simple linear model that we covered last week, where ANOVA is used when our predictors are discrete. In fact aov() is simply a wrapper for the lm() function that we used last week. For example, let’s run our model using lm() and then pipe it into anova() or sjstats::anova_stats().\n\nlm.model <- lm(RECALL~GROUP_FACTOR, data=dataset)\nanova(lm.model)\n\nAnalysis of Variance Table\n\nResponse: RECALL\n             Df Sum Sq Mean Sq F value    Pr(>F)    \nGROUP_FACTOR  4 351.52  87.880  9.0848 1.815e-05 ***\nResiduals    45 435.30   9.673                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsjstats::anova_stats(lm.model) %>% pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n \nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nGROUP_FACTOR\nGROUP_FACTOR\n4\n351.5\n87.88\n9.085\n0\n\n\n…2\nResiduals\n45\n435.3\n9.673\nNA\nNA\n\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n \netasq\npartial.etasq\nomegasq\npartial.omegasq\n\n\n\nGROUP_FACTOR\n0.447\n0.447\n0.393\n0.393\n\n\n…2\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\n \nepsilonsq\ncohens.f\npower\n\n\n\nGROUP_FACTOR\n0.398\n0.899\n0.999\n\n\n…2\nNA\nNA\nNA\n\n\n\n\n\nAll aov() does is take an lm object and produce an ANOVA table from the results. If we were simply to look at the lm() model we see that it gives us the info in our ANOVA table at the end of the summary, including the F-statistic (9.085), the degrees of freedom (4 and 45) and the p-value (1.815e-05):\n\nlm(RECALL~GROUP_FACTOR, data=dataset) %>% summary()\n\n\nCall:\nlm(formula = RECALL ~ GROUP_FACTOR, data = dataset)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7.00  -1.85  -0.45   2.00   9.60 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               7.0000     0.9835   7.117 6.83e-09 ***\nGROUP_FACTORRhyming      -0.1000     1.3909  -0.072 0.943004    \nGROUP_FACTORAdjective     4.0000     1.3909   2.876 0.006138 ** \nGROUP_FACTORImagery       6.4000     1.3909   4.601 3.43e-05 ***\nGROUP_FACTORIntentional   5.0000     1.3909   3.595 0.000802 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.11 on 45 degrees of freedom\nMultiple R-squared:  0.4468,    Adjusted R-squared:  0.3976 \nF-statistic: 9.085 on 4 and 45 DF,  p-value: 1.815e-05\n\n\nTaking a look at this output, we see that the lm() model also gives us a lot of other additional useful info. For example the \\(R^2\\) of the model may be understood as the effect size of the ANOVA. However, when we report it for One-Way ANOVA we express it as… dun, dun, dunnnn… eta-squared!!, or \\(\\eta^2\\).\nOne more time with feeling, for simple oneway ANOVA, \\(R^2\\) and \\(\\eta^2\\) are the same damn thing!!\nZooming in on the coefficients:\n\n\n                        Estimate Std. Error     t value     Pr(>|t|)\n(Intercept)                  7.0  0.9835311  7.11721300 6.830993e-09\nGROUP_FACTORRhyming         -0.1  1.3909230 -0.07189471 9.430043e-01\nGROUP_FACTORAdjective        4.0  1.3909230  2.87578833 6.137702e-03\nGROUP_FACTORImagery          6.4  1.3909230  4.60126133 3.425167e-05\nGROUP_FACTORIntentional      5.0  1.3909230  3.59473541 8.019114e-04\n\n\nWe see information about the means of each group relative to the (Intercept). This is why I stressed earlier that it may be useful to rearrange the order of your levels such that R enters your control group into the model first. In this case, the first predictor entered is assigned to the (Intercept). The remaining predictors in the model are then presented relative to the first. Since we entered “Counting” first, the estimate of the (Intercept) represents its mean. The means for each remaining group are the sum of its estimate coefficient and the (Intercept). So for example the mean of the Rhyming group is \\((-0.1)+(7.0)=6.9\\).\nThe coefficients section also gives us one other useful bit of information, the \\(t\\)-values of the estimate. As we learned a few weeks ago, for a simple regression the beta coefficient gives us information about the slope of the regression line and the corresponding \\(t\\)-value is a test of the null \\(beta=0\\). So for a simple regression this tells us if our slope is significantly different from 0.\nA similar logic applies to the ANOVA model. As I mentioned above, deriving the means of each level of our IV is a matter of summing the (Intercept) and the beta estimate for that level. It should be apparent, then, that the beta estimates here represent the slope of a line that between the intercept and the mean of the level (where the distance between the predictor and coefficient is treated as a unit 1). Therefore, a significant \\(t\\)-value for beta tells us that the slope between the two means is significant, or that those two means are significantly different from one another.\nKeep in mind the only comparisons that are being made here are between the individual levels of our IV and the control (Intercept). So while this output allows us to make a claim about the difference between the means of the Counting (Intercept) group compared to each of the other groups, it does not allow us to make a claim about differences between our other levels. For example no information about a statistical test of differences between the Rhyming and Imagery groups is conveyed here. However, assuming you are interested in deviations from your control, you can get info here quickly. There is a caveat here, in that our alpha criterion will need to be adjusted to be more conservative than .05. More on this next week."
  },
  {
    "objectID": "week08/8_1-one-way-anova.html#reporting-your-results.",
    "href": "week08/8_1-one-way-anova.html#reporting-your-results.",
    "title": "The One-way ANOVA",
    "section": "Reporting your results.",
    "text": "Reporting your results.\nReporting just the ANOVA\nFor this week’s assignment, you are going to be asked to simply report the ANOVA. In future weeks you will see that simply reporting the ANOVA is not the end of your analysis, but only the beginning of additional, necessary follow-ups. But that is for next week, for now let’s take a look at what one might expect to be reported in an ANOVA write-up.\nGiven our example:\n\nwords RECALL is our dependent measure\nGROUP_FACTOR is our independent variable, with five levels (or groups).\n\nUsing sjstats to generate an ANOVA table (pander makes it pretty for this web page:\n\nsjstats::anova_stats(aov.model) %>% pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n \nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nGROUP_FACTOR\nGROUP_FACTOR\n4\n351.5\n87.88\n9.085\n0\n\n\n…2\nResiduals\n45\n435.3\n9.673\nNA\nNA\n\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n \netasq\npartial.etasq\nomegasq\npartial.omegasq\n\n\n\nGROUP_FACTOR\n0.447\n0.447\n0.393\n0.393\n\n\n…2\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\n \nepsilonsq\ncohens.f\npower\n\n\n\nGROUP_FACTOR\n0.398\n0.899\n0.999\n\n\n…2\nNA\nNA\nNA\n\n\n\n\n\nFrom this table, we need our:\n\n\ndf: 4 and 45\n\nF-statistic: 9.085\n\np.value: even though it says zero, its “<.001”\n\netasq: .447; the symbol for etasq is \\(\\eta^2\\)\n\n\nTaking all of this info, and plugging into a write-up template (inserted points in bold):\n“We hypothesized that different types of memorization strategies would result in different levels of memorization between our five groups, as measured by the number of words recalled. To test this hypothesis we conducted a One-way Analysis of Variance. Our analysis revealed a significant effect for Groups, F(4, 45) = 9.08, p < .001, \\(\\eta^2\\) = .45; see Figure 1.”\nFor now, this is all you can say with only running a One-way ANOVA using this method, and that’s all I would want for the homework for this week.\nReporting the ANOVA, lm() output\nLet’s revisit the lm() output. Recall that the lm() method gives us the added benefit of comparing each level of the GROUP_FACTOR to the control level. This is what’s known as treatment contrasts (see Winter, Chapter 7). In this case, our control level is Counting and every other level (group) is compared against Counting and captured in the resulting beta coefficients:\n\naov_model_lm <- lm(RECALL~GROUP_FACTOR, data = dataset)\nsummary(aov_model_lm)\n\n\nCall:\nlm(formula = RECALL ~ GROUP_FACTOR, data = dataset)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7.00  -1.85  -0.45   2.00   9.60 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               7.0000     0.9835   7.117 6.83e-09 ***\nGROUP_FACTORRhyming      -0.1000     1.3909  -0.072 0.943004    \nGROUP_FACTORAdjective     4.0000     1.3909   2.876 0.006138 ** \nGROUP_FACTORImagery       6.4000     1.3909   4.601 3.43e-05 ***\nGROUP_FACTORIntentional   5.0000     1.3909   3.595 0.000802 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.11 on 45 degrees of freedom\nMultiple R-squared:  0.4468,    Adjusted R-squared:  0.3976 \nF-statistic: 9.085 on 4 and 45 DF,  p-value: 1.815e-05\n\n\nFrom this summary output we would not only extract our F-statistic, df, p-value and R-squared (remember that \\(R^2\\) is \\(\\eta^2\\)) as we do for the previous write-up, but now we can talk about differences between the other levels and Counting as expressed as a t value (we are running t-tests). We then combine this info with info related to the means and standard errors (note that I got the means and ses by creating a summary tibble():\n\ndataset %>% \n  group_by(GROUP_FACTOR) %>%\n  summarise(mean = mean(RECALL) %>% round(2),\n            se = sd(RECALL)/sqrt(n()) # ses = sd / sqrt number of participants\n            ) %>% \n  # this bit of code does some rounding (optional)\n  mutate_if(is.numeric,\n            round,\n            digits = 2)\n\n# A tibble: 5 × 3\n  GROUP_FACTOR  mean    se\n  <fct>        <dbl> <dbl>\n1 Counting       7    0.58\n2 Rhyming        6.9  0.67\n3 Adjective     11    0.79\n4 Imagery       13.4  1.42\n5 Intentional   12    1.18\n\n\nPutting all of this info together, we might say:\n\n“We hypothesized that different types of memorization strategies would result in different levels of memorization between our five groups, as measured by the number of words recalled. To test this hypothesis we conducted a One-way Analysis of Variance. Our analysis revealed a significant effect for Groups, F(4, 45) = 9.08, p < .001, \\(\\eta^2\\) = .45. As can be seen in Figure 1, we found that the average number of words recalled for the Adjective (\\(M\\) = 11.0, SE = 0.79; \\(t\\)(45) = 2.88), Imagery (\\(M\\) = 13.4, SE = 1.42; \\(t\\)(45) = 4.60), and Intentional (\\(M\\) = 12.0, SE = 1.18; \\(t\\)(45) = 3.60) memorization groups were all greater than the Counting group (\\(M\\) = 7.0, SE = 0.58); ps < .01”.\n\n\nnote that I find it acceptable to lump the p-values together in this manner when doing multiple comparisons, as we are doing here.\n\nIn both cases BE SURE TO PRODUCE A CAMERA READY FIGURE and REFER TO IT IN THE TEXT!!!"
  },
  {
    "objectID": "week01/1_1-Rmarkdown_basics.html",
    "href": "week01/1_1-Rmarkdown_basics.html",
    "title": "Rmarkdown Basics",
    "section": "",
    "text": "Note that this page is formatted. It might help to download the Rmarkdown file from the </> Code button at the top of this page.\nAnother note… much (but not all) of this is unnecessary assuming you use the Visual option in your source pane. That said you can still type markdown into your visual editor and it will auto-magically format things for you."
  },
  {
    "objectID": "week01/1_1-Rmarkdown_basics.html#header-2",
    "href": "week01/1_1-Rmarkdown_basics.html#header-2",
    "title": "Rmarkdown Basics",
    "section": "Header 2",
    "text": "Header 2\n\n### Header 3\n\nHeader 3\nAlso,\n\n- an unordered list\n-- can be don like this\n\n\nan unordered list\n\ncan be done like this\n\n\n\n\n1. here is an example of\n2. an ordered (numbered) list\n\n\nhere’s and example of\nan ordered (numbered) list\n\nand here is how you\n\n> blockquote some text\n\n\nblockquote some text\n\nare but a few that you may encounter. An expanded list can be found here. Which, by the way, is how you embed weblinks. Heck you can even do mathematical equations. For example, here is the binomial probability.\n\\[f(y|N,p) = \\frac{N!}{y!(N-y)!}\\cdot p^y \\cdot (1-p)^{N-y} = {{N}\\choose{y}} \\cdot p^y \\cdot (1-p)^{N-y}\\]\nand this is how it was created:\n$$f(y|N,p) = \\frac{N!}{y!(N-y)!}\\cdot p^y \\cdot (1-p)^{N-y} = {{N}\\choose{y}} \\cdot p^y \\cdot (1-p)^{N-y}$$\nGranted the syntax for this might seem daunting at first (and isn’t required for this course), but just wanted to show you some of the things you can do. At the very least learning equation syntax might be useful for superscripts\\(^2\\), subscripts\\(_2\\), and mathematical symbols like \\(\\alpha\\), \\(\\chi\\), and \\(\\sum\\). Although you can also do superscripts2 and subscripts2 inline. I suppose fractions are pretty useful too:\n\\[fraction = \\frac{numerator}{denominator}\\]"
  }
]